---
title: "Context Replay"
description: "Debug and replay agent execution traces with token tracking, cost analysis, and duplicate detection"
icon: "rotate-left"
---

## Overview

Context Replay allows you to capture, save, and replay the full execution trace of your agent workflows. This is invaluable for debugging, auditing, and understanding how your agents process tasks.

**Key Features:**
- **Token Tracking** - Monitor prompt and completion tokens per LLM call
- **Cost Analysis** - Track LLM and tool costs per session
- **Duplicate Detection** - Identify redundant content passed between agents
- **Context Efficiency** - Verify optimized context across multi-agent workflows

## Quick Start

### Capture a Trace

Add `--save` to any execution command to capture a replay trace:

```bash
# Workflow execution
praisonai workflow run workflow.yaml --save

# Agents file execution
praisonai agents.yaml --save

# Recipe execution
praisonai recipe run my-recipe --save
```

### List Available Traces

```bash
praisonai replay list
```

Output:
```
                 Available Context Traces                 
┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃ Session ID        ┃ Events ┃ Size   ┃ Modified         ┃
┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ run-4fd4e2426ab9  │ 6      │ 2.7 KB │ 2026-01-22 13:05 │
│ run-e0b117974e6f  │ 10     │ 4.8 KB │ 2026-01-22 13:06 │
└───────────────────┴────────┴────────┴──────────────────┘
```

### View a Trace

```bash
# Basic view
praisonai replay context <session_id> --dump

# Full content (no truncation)
praisonai replay context <session_id> --dump --full

# Session statistics (tokens, costs, duplicates)
praisonai replay context <session_id> --stats

# Cost breakdown only
praisonai replay context <session_id> --cost

# JSON output
praisonai replay context <session_id> --json
```

## Event Types

Context Replay captures the following event types:

| Event Type | Description |
|------------|-------------|
| `SESSION_START` | Workflow/agent execution begins |
| `SESSION_END` | Workflow/agent execution completes |
| `AGENT_START` | Individual agent begins processing |
| `AGENT_END` | Individual agent completes |
| `LLM_REQUEST` | Request sent to LLM (includes full messages) |
| `LLM_RESPONSE` | Response received from LLM |
| `TOOL_CALL_START` | Tool execution begins |
| `TOOL_CALL_END` | Tool execution completes |

## Parallel Execution Tracking

For parallel workflows, each branch is tracked with a unique `branch_id`:

```json
{
  "event_type": "agent_start",
  "agent_name": "analyst",
  "branch_id": "parallel_0"
}
```

This allows you to trace which events belong to which parallel execution branch.

## CLI Reference

### `praisonai replay list`

List all available replay traces.

```bash
praisonai replay list
```

### `praisonai replay context`

View a specific replay trace.

```bash
praisonai replay context <session_id> [OPTIONS]
```

**Options:**
| Option | Description |
|--------|-------------|
| `--dump` / `-d` | Show events in human-readable format |
| `--full` / `-f` | Show full content without truncation |
| `--stats` | Show session statistics (tokens, costs, duplicates) |
| `--cost` | Show cost breakdown only |
| `--json` / `-j` | Output as JSON |
| `--start N` / `-s N` | Start from event number N (1-based) |
| `--no-rich` | Disable Rich formatting |

### `praisonai replay delete`

Delete a replay trace.

```bash
praisonai replay delete <session_id>
```

### `praisonai replay dashboard`

Show context analytics dashboard with usage patterns.

```bash
# Analyze recent sessions
praisonai replay dashboard

# Analyze specific session
praisonai replay dashboard <session_id>

# Limit to N sessions
praisonai replay dashboard --limit 10

# JSON output
praisonai replay dashboard --json
```

**Output:**
```
======================================================================
  CONTEXT ANALYTICS DASHBOARD
======================================================================

  Sessions Analyzed: 5
  Total Tokens:      1,265,736
  Total Cost:        $0.2728

  TOKEN USAGE BY AGENT:
  --------------------------------------------------
    deep_researcher      ██████████████████████████████    956,146 (75.5%)
    content_writer       ███                               113,023 (8.9%)

  COST BY TOOL:
  --------------------------------------------------
    tavily_search             $0.0650
    tavily_extract            $0.0140

  CONTEXT EFFICIENCY:
  --------------------------------------------------
    ⚠️  Duplicates Found:  236
    ⚠️  Wasted Tokens:     135,279 (10.7%)

  RECOMMENDATIONS:
    • Enable session-level deduplication in workflow
    • Consider using context: {strategy: smart} in YAML
======================================================================
```

### `praisonai replay cleanup`

Remove old replay traces.

```bash
praisonai replay cleanup [--days 30]
```

## Example Output

### Session Statistics

```bash
praisonai replay context run-d5d76bcf8cc3 --stats
```

```
============================================================
  SESSION STATISTICS: run-d5d76bcf8cc3
============================================================

  Duration:        26.0 seconds
  Agents:          2 (Keyword Research Specialist, Topic Collector)
  Total Events:    18

  TOKEN USAGE:
    Total Prompt:      22,378 tokens
    Total Completion:  478 tokens
    Total:             22,856 tokens

    By Agent:
      Keyword Research Specialist: 6,774 tokens (prompt: 6,744, completion: 30)
      Topic Collector: 16,082 tokens (prompt: 15,634, completion: 448)

  COST BREAKDOWN:
    LLM Calls:        $0.0607 (2 calls)
    Tool Calls:       $0.0040 (4 calls)
    Total:            $0.0647

    By Tool:
      tavily_search: $0.0040 (4 calls)

  CONTEXT EFFICIENCY:
    Duplicates Found: 0
    Context is optimized!

============================================================
```

### Cost Report

```bash
praisonai replay context run-d5d76bcf8cc3 --cost
```

```
============================================================
  COST REPORT: run-d5d76bcf8cc3
============================================================

  TOTAL COST: $0.0647

  LLM COSTS:
    Calls:  2
    Cost:   $0.0607

    By Agent:
      Keyword Research Specialist: $0.0010
      Topic Collector: $0.0597

  TOOL COSTS (1 credit = $0.001):
    Calls:   4
    Credits: 4
    Cost:    $0.0040

    By Tool:
      tavily_search: 4 credits ($0.0040)

============================================================
```

### Basic Dump

```bash
praisonai replay context run-4fd4e2426ab9 --dump
```

```
============================================================
  CONTEXT REPLAY: run-4fd4e2426ab9
  Total Events: 6
============================================================

--------------------------------------------------
[  1] SESSION_START
  workflow: workflow.yaml
  run_id: run-4fd4e2426ab9

--------------------------------------------------
[  2] AGENT_START (greeter)
  role: Friendly Greeter
  goal: Greet the user warmly

--------------------------------------------------
[  3] LLM_REQUEST (greeter)
  model: gpt-4o-mini
  messages: [{'role': 'system', 'content': 'You are a friendly...

--------------------------------------------------
[  4] LLM_RESPONSE (greeter)
  prompt_tokens: 150
  completion_tokens: 25
  cost: $0.000045
  response_tokens: 25
  duration_ms: 2655.09
  response_content: ChatCompletion(id='chatcmpl-...

--------------------------------------------------
[  5] AGENT_END (greeter)

--------------------------------------------------
[  6] SESSION_END

============================================================
  SESSION SUMMARY
============================================================
  Total Events:       6
  Prompt Tokens:      150
  Completion Tokens:  25
  Total Tokens:       175
  Total Cost:         $0.000045
============================================================
```

### Full Content View

With `--full`, messages are formatted for readability:

```bash
praisonai replay context run-4fd4e2426ab9 --dump --full
```

```
--------------------------------------------------
[  3] LLM_REQUEST (greeter)
  model: gpt-4o-mini
  messages:
    [1] system:
        You are a friendly assistant who greets users.
        
        Your Role: Friendly Greeter
        Your Goal: Greet the user warmly
    [2] user:
        Say hello to the user with this input: Hello World
```

## Storage Location

Replay traces are stored in:

```
~/.praison/replay/
├── run-4fd4e2426ab9.jsonl
├── run-e0b117974e6f.jsonl
└── ...
```

Each trace is a JSONL file (JSON Lines) where each line is a single event.

## Programmatic Access

You can also access replay data programmatically:

```python
from praisonai.replay import ContextTraceReader

# Read a trace
reader = ContextTraceReader("run-4fd4e2426ab9")
events = reader.read_all()

for event in events:
    print(f"{event.event_type}: {event.agent_name}")
```

## Performance

- **Zero overhead** when `--save` is not used
- Traces are written asynchronously with buffering
- Minimal memory footprint during execution

## Use Cases

1. **Debugging** - Understand why an agent produced unexpected output
2. **Auditing** - Review what data was sent to LLMs
3. **Optimization** - Identify slow steps in workflows
4. **Cost Tracking** - Monitor LLM and tool costs per session
5. **Context Efficiency** - Detect duplicate content and optimize token usage
6. **Testing** - Verify agent behavior across runs
7. **Compliance** - Maintain records of AI interactions

## Cost Tracking

Context Replay tracks costs for both LLM calls and tool usage:

### LLM Costs

Costs are calculated based on model pricing (per 1M tokens):

| Model | Input | Output |
|-------|-------|--------|
| gpt-4o | $2.50 | $10.00 |
| gpt-4o-mini | $0.15 | $0.60 |
| claude-3-5-sonnet | $3.00 | $15.00 |
| gemini-1.5-pro | $1.25 | $5.00 |

### Tool Costs

Internet search tools are tracked at **1 credit = $0.001** per call:

- `tavily_search`
- `internet_search`
- `web_search`
- `duckduckgo_search`

## Duplicate Detection

When using `--dump --full`, the analyzer checks for duplicate content:

```
  DUPLICATE CONTENT DETECTED:
    Duplicates Found: 2
    Wasted Tokens:    5,000
    - Hash a3f2b1c4d5e6... (2x, ~5,000 wasted)
```

This helps identify inefficient context passing between agents.

## Related

- [Workflows](/features/workflow) - Learn about workflow execution
- [Agents](/agents) - Agent configuration and usage
- [Tools](/tools) - Tool integration and debugging
