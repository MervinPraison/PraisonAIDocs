---
title: "MCP Integration"
description: "Model Context Protocol (MCP) integration for PraisonAI Agents"
icon: "plug"
---

# MCP Integration

PraisonAI Agents provides seamless integration with the Model Context Protocol (MCP), allowing you to connect to external tools and services through a standardized protocol.

## Overview

MCP (Model Context Protocol) is a standard for connecting AI agents to external tools and data sources. PraisonAI supports multiple MCP transport types:

- **stdio** - Standard input/output (subprocess-based)
- **SSE** - Server-Sent Events (HTTP-based)
- **HTTP Stream** - Streamable HTTP transport
- **WebSocket** - Bidirectional WebSocket connections

## Quick Start

### Basic Usage

```python
from praisonaiagents import Agent, MCP

# Create MCP instance with a server command
mcp = MCP("npx -y @modelcontextprotocol/server-sequential-thinking")

# Create agent with MCP tools
agent = Agent(
    name="ThinkingAgent",
    instructions="You break down complex problems step by step.",
    llm="openai/gpt-4o-mini",
    tools=mcp
)

# Use the agent
response = agent.chat("Break down the process of making tea")
print(response)

# Clean up
mcp.shutdown()
```

### Using uvx (Python-based servers)

```python
from praisonaiagents import Agent, MCP

# Time server
mcp = MCP("uvx mcp-server-time")

agent = Agent(
    name="TimeAgent",
    instructions="You help with time-related queries.",
    tools=mcp
)
```

### SSE Transport

```python
from praisonaiagents import Agent, MCP

# Connect to SSE endpoint
mcp = MCP("http://localhost:8080/sse")

agent = Agent(
    name="SSEAgent",
    tools=mcp
)
```

### WebSocket Transport

```python
from praisonaiagents import Agent, MCP

# Connect via WebSocket
mcp = MCP("ws://localhost:8080/mcp")

agent = Agent(
    name="WebSocketAgent",
    tools=mcp
)
```

## API Reference

### MCP Class

```python
MCP(
    command_or_string: str,  # Command, URL, or full command string
    args: List[str] = None,  # Arguments (if command_or_string is just the command)
    timeout: int = 60,       # Timeout in seconds
    debug: bool = False,     # Enable debug logging
    env: Dict = None,        # Environment variables
)
```

#### Methods

| Method | Description |
|--------|-------------|
| `get_tools()` | Returns list of tool functions |
| `to_openai_tool()` | Converts tools to OpenAI format |
| `shutdown()` | Clean up resources |

#### Properties

| Property | Description |
|----------|-------------|
| `_tools` | List of wrapped tool functions |

### Using as Context Manager

```python
with MCP("uvx mcp-server-time") as mcp:
    agent = Agent(tools=mcp)
    response = agent.chat("What time is it?")
# Automatically cleaned up
```

## CLI Commands

PraisonAI provides CLI commands for managing MCP servers:

```bash
# List configured servers
praisonai mcp list

# Add a server
praisonai mcp add my-server uvx --args "mcp-server-time"

# Test a server
praisonai mcp test my-server

# Sync tools from servers
praisonai mcp sync

# Run a server
praisonai mcp run my-server

# Show server status
praisonai mcp status
```

### Adding Servers

```bash
# Add with arguments
praisonai mcp add time-server uvx --args "mcp-server-time"

# Add with environment variables
praisonai mcp add api-server node --args "server.js" --env "API_KEY=xxx"
```

### Running Servers

```bash
# Run in stdio mode (default)
praisonai mcp run my-server

# Run as SSE server
praisonai mcp run my-server --transport sse --port 8080
```

## Multiple MCP Servers

You can use multiple MCP servers with a single agent:

```python
from praisonaiagents import Agent, MCP

# Create multiple MCP instances
time_mcp = MCP("uvx mcp-server-time")
thinking_mcp = MCP("npx -y @modelcontextprotocol/server-sequential-thinking")

# Use both in an agent
agent = Agent(
    name="MultiToolAgent",
    instructions="You have access to time and thinking tools.",
    tools=[time_mcp, thinking_mcp]
)
```

## Mixing MCP with Regular Tools

```python
from praisonaiagents import Agent, MCP

def calculate(expression: str) -> str:
    """Evaluate a math expression."""
    return str(eval(expression))

mcp = MCP("uvx mcp-server-time")

agent = Agent(
    name="MixedAgent",
    tools=[mcp, calculate]  # Mix MCP and regular functions
)
```

## Exposing Agents as MCP Servers

You can expose PraisonAI agents as MCP servers:

```python
from praisonaiagents import Agent

agent = Agent(
    name="MyAgent",
    instructions="You are a helpful assistant."
)

# Launch as MCP server
agent.launch(protocol="mcp", port=8080)
```

## Troubleshooting

### Server Not Starting

1. Check if the command is installed:
   ```bash
   which npx  # or uvx
   ```

2. Test the server manually:
   ```bash
   praisonai mcp test my-server
   ```

### Timeout Errors

Increase the timeout:
```python
mcp = MCP("npx -y @modelcontextprotocol/server-sequential-thinking", timeout=120)
```

### Debug Mode

Enable debug logging:
```python
mcp = MCP("uvx mcp-server-time", debug=True)
```

## Best Practices

1. **Always clean up**: Use context managers or call `shutdown()` explicitly
2. **Set appropriate timeouts**: Some servers take longer to initialize
3. **Handle errors gracefully**: MCP servers can fail to start
4. **Use thread-safe patterns**: Each MCP instance uses its own event loop

## Examples

See the [examples directory](https://github.com/MervinPraison/PraisonAI/tree/main/examples/mcp) for more examples:

- `sequential_thinking.py` - Using Sequential Thinking MCP
- `multi_server.py` - Multiple MCP servers with mixed tools
