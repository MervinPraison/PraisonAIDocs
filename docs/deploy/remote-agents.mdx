---
title: Remote Agent Deployment
description: Deploy PraisonAI agents as HTTP services and connect to them remotely
---

# Remote Agent Deployment

Deploy your PraisonAI agents as HTTP services to enable distributed architectures, scalable deployments, and remote connectivity.

## Overview

PraisonAI supports deploying agents as HTTP services that can be accessed remotely. This enables:

- Distributed agent architectures
- Scalable microservice deployments
- Cross-network agent communication
- Load balancing and failover
- API gateway integration

## Basic Agent Deployment

### Single Agent Server

Deploy an agent as an HTTP service:

```python
from praisonaiagents import Agent

# Create an agent
agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant.",
    llm="gpt-4o-mini"
)

# Launch as HTTP server
agent.launch(
    path="/agent",
    port=8000,
    host="0.0.0.0"  # Accept connections from any IP
)

# Agent is now accessible at http://localhost:8000/agent
```

### Multiple Agents on Different Endpoints

```python
from praisonaiagents import Agent

# Create specialised agents
math_agent = Agent(
    name="MathExpert",
    instructions="You solve mathematical problems"
)

code_agent = Agent(
    name="CodeExpert", 
    instructions="You help with programming"
)

# Deploy on different endpoints
math_agent.launch(path="/math", port=8000)
code_agent.launch(path="/code", port=8001)
```

## Remote Agent Connectivity

### Connecting to Remote Agents

Use the Session class to connect to remote agents:

```python
from praisonaiagents import Session

# Connect to remote agent
session = Session(agent_url="192.168.1.10:8000/agent")

# Interact with remote agent
response = session.chat("Hello, how are you?")
print(response)

# Send structured messages
result = session.send_message({
    "content": "Analyse this data",
    "data": {"sales": [100, 200, 300]}
})
```

### Error Handling

```python
try:
    session = Session(agent_url="remote-server:8000/agent")
    response = session.chat("Process this request")
except ConnectionError as e:
    print(f"Failed to connect to remote agent: {e}")
    # Fallback to local agent or retry
except TimeoutError as e:
    print(f"Request timed out: {e}")
```

## Advanced Deployment Patterns

### Multi-Agent Server

Deploy multiple agents together:

```python
from praisonaiagents import Agent, Agents

# Create agents
agents = Agents(
    agents=[
        Agent(name="Research", instructions="Research topics"),
        Agent(name="Writer", instructions="Write content"),
        Agent(name="Editor", instructions="Edit and improve text")
    ]
)

# Launch all agents
agents.launch(port=8080)

# Agents accessible at:
# http://localhost:8080/research
# http://localhost:8080/writer
# http://localhost:8080/editor
```

### MCP Protocol Support

Deploy agents with Model Context Protocol:

```python
# Single agent with MCP
agent = Agent(
    name="DataAnalyst",
    instructions="Analyse data and create visualisations"
)

agent.launch(
    port=8080,
    protocol="mcp"  # Enable MCP protocol
)

# Multi-agent MCP server
agents = Agents(agents=[agent1, agent2, agent3])
agents.launch(port=8080, protocol="mcp")
```

### FastAPI Integration

Integrate agents with existing FastAPI applications:

```python
from fastapi import FastAPI, HTTPException
from praisonaiagents import Agent
from pydantic import BaseModel

app = FastAPI()

# Create agent
agent = Agent(
    name="APIAssistant",
    instructions="Process API requests"
)

class ChatRequest(BaseModel):
    message: str
    context: dict = {}

class ChatResponse(BaseModel):
    response: str
    metadata: dict = {}

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    try:
        # Process with agent
        response = agent.chat(
            request.message,
            context=request.context
        )
        
        return ChatResponse(
            response=response,
            metadata={"agent": agent.name}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Additional endpoints
@app.get("/health")
async def health_check():
    return {"status": "healthy", "agent": agent.name}

# Run with: uvicorn main:app --host 0.0.0.0 --port 8000
```

## Production Deployment

### Docker Deployment

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy agent code
COPY agent.py .

# Expose port
EXPOSE 8000

# Run agent server
CMD ["python", "agent.py"]
```

```python
# agent.py
from praisonaiagents import Agent
import os

agent = Agent(
    name="ProductionAgent",
    instructions=os.getenv("AGENT_INSTRUCTIONS", "Default instructions"),
    llm=os.getenv("LLM_MODEL", "gpt-4o-mini")
)

agent.launch(
    port=int(os.getenv("PORT", 8000)),
    host="0.0.0.0"
)
```

### Load Balancing

Deploy multiple instances behind a load balancer:

```yaml
# docker-compose.yml
version: '3.8'

services:
  agent1:
    build: .
    environment:
      - AGENT_INSTRUCTIONS=Process customer queries
      - PORT=8001
    
  agent2:
    build: .
    environment:
      - AGENT_INSTRUCTIONS=Process customer queries
      - PORT=8002
  
  nginx:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agent1
      - agent2
```

## Security Considerations

### Authentication

Add authentication to your agent endpoints:

```python
from fastapi import Depends, HTTPException, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    token = credentials.credentials
    # Verify token logic
    if not is_valid_token(token):
        raise HTTPException(status_code=403, detail="Invalid token")
    return token

@app.post("/chat", dependencies=[Depends(verify_token)])
async def secure_chat(request: ChatRequest):
    # Process request with agent
    pass
```

### HTTPS/TLS

Deploy with SSL certificates:

```python
agent.launch(
    port=8443,
    host="0.0.0.0",
    ssl_keyfile="key.pem",
    ssl_certfile="cert.pem"
)
```

### Rate Limiting

Implement rate limiting for production:

```python
from fastapi_limiter import FastAPILimiter
from fastapi_limiter.depends import RateLimiter

@app.post("/chat", dependencies=[Depends(RateLimiter(times=10, seconds=60))])
async def rate_limited_chat(request: ChatRequest):
    # Process with rate limiting
    pass
```

## Monitoring and Observability

### Health Checks

```python
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "agent": agent.name,
        "uptime": get_uptime(),
        "memory_usage": get_memory_usage()
    }

@app.get("/ready")
async def readiness():
    # Check if agent is ready to serve
    try:
        test_response = agent.chat("test")
        return {"ready": True}
    except Exception:
        return {"ready": False}, 503
```

### Metrics Collection

```python
from prometheus_client import Counter, Histogram, generate_latest

# Metrics
request_count = Counter('agent_requests_total', 'Total requests')
request_duration = Histogram('agent_request_duration_seconds', 'Request duration')

@app.post("/chat")
async def chat_with_metrics(request: ChatRequest):
    request_count.inc()
    
    with request_duration.time():
        response = agent.chat(request.message)
    
    return {"response": response}

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

## Common Patterns

### API Gateway Pattern

```python
# Deploy specialised agents
agents = {
    "billing": Agent(name="Billing", instructions="Handle billing"),
    "support": Agent(name="Support", instructions="Handle support"),
    "sales": Agent(name="Sales", instructions="Handle sales")
}

for name, agent in agents.items():
    agent.launch(path=f"/{name}", port=8000 + len(agents))

# Use API gateway to route requests
```

### Circuit Breaker Pattern

```python
from circuit_breaker import CircuitBreaker

cb = CircuitBreaker(failure_threshold=5, recovery_timeout=30)

@cb
async def call_remote_agent(message):
    session = Session(agent_url="remote:8000/agent")
    return session.chat(message)

# Automatically handles failures and fallbacks
```

### Failover Pattern

```python
primary_url = "primary-server:8000/agent"
backup_url = "backup-server:8000/agent"

try:
    session = Session(agent_url=primary_url)
    response = session.chat(message)
except Exception:
    # Failover to backup
    session = Session(agent_url=backup_url)
    response = session.chat(message)
```

## Best Practices

1. **Use Environment Variables**: Configure agents via environment variables for flexibility
2. **Implement Health Checks**: Always include health and readiness endpoints
3. **Add Monitoring**: Use metrics and logging for observability
4. **Secure Endpoints**: Implement authentication and rate limiting
5. **Handle Errors Gracefully**: Provide meaningful error responses
6. **Document APIs**: Use OpenAPI/Swagger for API documentation
7. **Version Your APIs**: Include version in paths (e.g., `/v1/agent`)