---
title: "Remote Agents"
sidebarTitle: "Remote Agents"
description: "Deploy agents as HTTP services for remote access"
icon: "network-wired"
---

Deploy agents as HTTP services accessible over the network.

## Prerequisites

```bash
pip install "praisonaiagents[api]"
export OPENAI_API_KEY="your-key"
```

## Single Agent Server

```python
from praisonaiagents import Agent

agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant.",
    llm="gpt-4o-mini"
)

agent.launch(path="/agent", port=8000, host="0.0.0.0")
```

**Expected Output:**
```
ðŸš€ Agent 'Assistant' available at http://0.0.0.0:8000
âœ… FastAPI server started at http://0.0.0.0:8000
ðŸ“š API documentation available at http://0.0.0.0:8000/docs
ðŸ”Œ Available endpoints: /agent
```

## Multiple Agents

```python
from praisonaiagents import Agent

math_agent = Agent(name="MathExpert", instructions="Solve math problems", llm="gpt-4o-mini")
code_agent = Agent(name="CodeExpert", instructions="Help with programming", llm="gpt-4o-mini")

math_agent.launch(path="/math", port=8000)
code_agent.launch(path="/code", port=8000)
```

**Endpoints:**
- `POST http://localhost:8000/math`
- `POST http://localhost:8000/code`

## Connect to Remote Agent

```bash
curl -X POST http://192.168.1.10:8000/agent \
  -H "Content-Type: application/json" \
  -d '{"query": "Hello, how are you?"}'
```

## Multi-Agent Server

```python
from praisonaiagents import Agent, Agents

agents = Agents(agents=[
    Agent(name="Research", instructions="Research topics", llm="gpt-4o-mini"),
    Agent(name="Writer", instructions="Write content", llm="gpt-4o-mini")
])

agents.launch(path="/workflow", port=8080)
```

## Docker Deployment

**app.py:**
```python
from praisonaiagents import Agent
import os

agent = Agent(
    name="ProductionAgent",
    instructions=os.getenv("AGENT_INSTRUCTIONS", "You are helpful"),
    llm=os.getenv("LLM_MODEL", "gpt-4o-mini")
)

agent.launch(port=int(os.getenv("PORT", 8000)), host="0.0.0.0")
```

**Dockerfile:**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app.py .
EXPOSE 8000
CMD ["python", "app.py"]
```

**Build and Run:**
```bash
docker build -t remote-agent .
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -e AGENT_INSTRUCTIONS="You are a helpful assistant" \
  remote-agent
```

## Load Balancing

**docker-compose.yml:**
```yaml
version: '3.8'
services:
  agent1:
    build: .
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PORT=8000
    ports:
      - "8001:8000"
  
  agent2:
    build: .
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PORT=8000
    ports:
      - "8002:8000"
```

```bash
docker-compose up -d
```

## Verify Deployment

```bash
# Health check
curl http://localhost:8000/health

# Test endpoint
curl -X POST http://localhost:8000/agent \
  -H "Content-Type: application/json" \
  -d '{"query": "Hello"}'
```

## Troubleshooting

| Issue | Check |
|-------|-------|
| Connection refused | Verify `host="0.0.0.0"` |
| Port in use | `lsof -i :8000` |
| Firewall blocking | Check firewall rules |
| No response | Check logs for errors |