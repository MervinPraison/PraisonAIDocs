---
title: "MCP Server Deploy"
sidebarTitle: "MCP Server"
description: "Deploy agents as Model Context Protocol (MCP) servers"
icon: "server-rack"
---

Deploy agents as MCP servers using `protocol="mcp"`.

## CLI

```bash
pip install praisonai
export OPENAI_API_KEY="your-key"
```

## Python - Single Agent

```python
from praisonaiagents import Agent

agent = Agent(name="TweetAgent", instructions="Create tweets", llm="gpt-4o-mini")
agent.launch(port=8080, protocol="mcp")
```

**Output:**
```
ğŸš€ Agent 'TweetAgent' MCP server starting on http://0.0.0.0:8080
ğŸ“¡ MCP SSE endpoint available at /sse
ğŸ“¢ MCP messages post to /messages/
ğŸ› ï¸ Available MCP tools: execute_tweetagent_task
```

## Python - Multi-Agent

```python
from praisonaiagents import Agent, Agents

researcher = Agent(name="Researcher", instructions="Research topics", llm="gpt-4o-mini")
writer = Agent(name="Writer", instructions="Write content", llm="gpt-4o-mini")

agents = Agents(agents=[researcher, writer])
agents.launch(port=8080, protocol="mcp")
```

**Output:**
```
ğŸš€ PraisonAIAgents MCP Workflow server starting on http://0.0.0.0:8080
ğŸ“¡ MCP SSE endpoint available at /sse
ğŸ“¢ MCP messages post to /messages/
ğŸ› ï¸ Available MCP tools: execute_workflow
ğŸ”„ Agents in MCP workflow: Researcher, Writer
```

## MCP Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/sse` | GET | SSE connection |
| `/messages/` | POST | Send messages |

## Connect MCP Client

```json
{
  "mcpServers": {
    "praisonai": {
      "url": "http://localhost:8080/sse"
    }
  }
}
```

## Docker

**app.py:**
```python
from praisonaiagents import Agent

agent = Agent(instructions="Create tweets", llm="gpt-4o-mini")
agent.launch(port=8080, protocol="mcp")
```

**Dockerfile:**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app.py .
EXPOSE 8080
CMD ["python", "app.py"]
```

**requirements.txt:**
```
praisonaiagents[mcp]
```

**Build and run:**
```bash
docker build -t mcp-server .
docker run -p 8080:8080 -e OPENAI_API_KEY=$OPENAI_API_KEY mcp-server
```

## Verify

```bash
curl http://localhost:8080/sse
```

## Troubleshooting

| Issue | Fix |
|-------|-----|
| Port in use | `lsof -i :8080` |
| Missing deps | `pip install "praisonaiagents[mcp]"` |
| No API key | `export OPENAI_API_KEY="your-key"` |
