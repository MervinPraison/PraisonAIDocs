---
title: "Server: Agents"
sidebarTitle: "Agents"
description: "Deploy agents as HTTP API servers using praisonai --serve or Agent.launch()"
icon: "robot"
---

Deploy single or multi-agent systems as HTTP REST API servers.

## CLI

```bash
pip install "praisonaiagents[api]"
export OPENAI_API_KEY="your-key"

# Initialize agents
praisonai --init "helpful assistant"

# Start server
praisonai --serve --port 8000 --host 127.0.0.1
```

**Expected Output:**
```
ðŸ“„ Loading workflow from: agents.yaml
ðŸš€ Starting PraisonAI API server...
   Host: 127.0.0.1
   Port: 8000
ðŸš€ Multi-Agent HTTP API available at http://127.0.0.1:8000/agents
âœ… FastAPI server started at http://127.0.0.1:8000
ðŸ“š API documentation available at http://127.0.0.1:8000/docs
```

**Verify:**
```bash
curl http://localhost:8000/health
```

## Python - Single Agent

```python
from praisonaiagents import Agent

agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant.",
    llm="gpt-4o-mini"
)
agent.launch(path="/ask", port=8000)
```

**Expected Output:**
```
ðŸš€ Agent 'Assistant' available at http://0.0.0.0:8000
âœ… FastAPI server started at http://0.0.0.0:8000
ðŸ“š API documentation available at http://0.0.0.0:8000/docs
ðŸ”Œ Available endpoints: /ask
```

**Verify:**
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "Hello"}'
```

## Python - Multi-Agent

```python
from praisonaiagents import Agent, Agents

researcher = Agent(name="Researcher", instructions="Research topics", llm="gpt-4o-mini")
writer = Agent(name="Writer", instructions="Write content", llm="gpt-4o-mini")

agents = Agents(agents=[researcher, writer])
agents.launch(path="/content", port=8000)
```

**Expected Output:**
```
ðŸš€ Multi-Agent HTTP API available at http://0.0.0.0:8000/content
ðŸ“Š Available agents for this endpoint (2): Researcher, Writer
ðŸ”— Per-agent endpoints: /content/researcher, /content/writer
âœ… FastAPI server started at http://0.0.0.0:8000
ðŸ“š API documentation available at http://0.0.0.0:8000/docs
```

## agents.yaml

```yaml
framework: praisonai
topic: research and write content
roles:
  researcher:
    role: Researcher
    goal: Research topics thoroughly
    backstory: Expert researcher
    tasks:
      research_task:
        description: Research the topic
        expected_output: Research findings
  writer:
    role: Writer
    goal: Write engaging content
    backstory: Expert writer
    tasks:
      write_task:
        description: Write based on research
        expected_output: Written content
```

```bash
praisonai --serve --port 8000
```

## CLI Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--serve` | - | Start API server |
| `--port` | `8005` | Server port |
| `--host` | `127.0.0.1` | Server host |

## launch() Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `path` | str | `/` | API endpoint path |
| `port` | int | `8000` | Server port |
| `host` | str | `0.0.0.0` | Server host |
| `debug` | bool | `False` | Debug mode |
| `protocol` | str | `http` | `http` or `mcp` |

## Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/{path}` | POST | Send query to agent(s) |
| `/{path}/list` | GET | List available agents |
| `/{path}/{agent_id}` | POST | Call specific agent |
| `/health` | GET | Health check |
| `/docs` | GET | Swagger UI |

## Example Request/Response

**Request:**
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "What is AI?"}'
```

**Response:**
```json
{
  "response": "Artificial intelligence (AI) refers to..."
}
```

## Troubleshooting

| Issue | Fix |
|-------|-----|
| Port in use | `lsof -i :8000` then kill process |
| No agents.yaml | `praisonai --init "topic"` |
| Missing API key | `export OPENAI_API_KEY="your-key"` |
| Missing deps | `pip install "praisonaiagents[api]"` |

## Related

- [Agents API Reference](../api/agents-api) - Full API documentation
- [Tools MCP Server](./tools-mcp) - Deploy tools as MCP server
- [Deploy CLI](../cli/index) - Deploy using praisonai deploy
