---
title: "Server: Agents HTTP"
sidebarTitle: "Agents HTTP"
description: "Deploy agents as HTTP API servers using praisonai --serve or Agent.launch()"
icon: "robot"
---

Deploy single or multi-agent systems as HTTP REST API servers.

## Quick Start

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install "praisonaiagents[api]"
    ```
  </Step>
  <Step title="Set API Key">
    ```bash
    export OPENAI_API_KEY="your-key"
    ```
  </Step>
  <Step title="Initialize Agents">
    ```bash
    praisonai --init "helpful assistant"
    ```
  </Step>
  <Step title="Start Server">
    ```bash
    praisonai serve agents --port 8000 --host 0.0.0.0
    ```
    
    **Expected Output:**
    ```
    ðŸ“„ Loading workflow from: agents.yaml
    ðŸš€ Starting PraisonAI API server...
       Host: 0.0.0.0
       Port: 8000
    ðŸš€ Multi-Agent HTTP API available at http://0.0.0.0:8000/agents
    âœ… FastAPI server started at http://0.0.0.0:8000
    ðŸ“š API documentation available at http://0.0.0.0:8000/docs
    ```
  </Step>
  <Step title="Verify">
    ```bash
    curl http://localhost:8000/health
    ```
  </Step>
</Steps>

## Python - Single Agent

```python
from praisonaiagents import Agent

agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant.",
    llm="gpt-4o-mini"
)
agent.launch(path="/ask", port=8000, host="0.0.0.0")
```

**Expected Output:**
```
ðŸš€ Agent 'Assistant' available at http://0.0.0.0:8000
âœ… FastAPI server started at http://0.0.0.0:8000
ðŸ“š API documentation available at http://0.0.0.0:8000/docs
ðŸ”Œ Available endpoints: /ask
```

## Python - Multi-Agent

```python
from praisonaiagents import Agent, Agents

researcher = Agent(name="Researcher", instructions="Research topics", llm="gpt-4o-mini")
writer = Agent(name="Writer", instructions="Write content", llm="gpt-4o-mini")

agents = Agents(agents=[researcher, writer])
agents.launch(path="/content", port=8000, host="0.0.0.0")
```

**Expected Output:**
```
ðŸš€ Multi-Agent HTTP API available at http://0.0.0.0:8000/content
ðŸ“Š Available agents for this endpoint (2): Researcher, Writer
ðŸ”— Per-agent endpoints: /content/researcher, /content/writer
âœ… FastAPI server started at http://0.0.0.0:8000
ðŸ“š API documentation available at http://0.0.0.0:8000/docs
```

## agents.yaml

```yaml
framework: praisonai
topic: research and write content
roles:
  researcher:
    role: Researcher
    goal: Research topics thoroughly
    backstory: Expert researcher
    tasks:
      research_task:
        description: Research the topic
        expected_output: Research findings
  writer:
    role: Writer
    goal: Write engaging content
    backstory: Expert writer
    tasks:
      write_task:
        description: Write based on research
        expected_output: Written content
```

```bash
praisonai serve agents --port 8000 --host 0.0.0.0
```

## CLI Commands

```bash
# Start agents server
praisonai serve agents --port 8000

# With custom host for remote access
praisonai serve agents --port 8000 --host 0.0.0.0

# With agents file
praisonai serve agents --file agents.yaml --port 8000
```

| Option | Default | Description |
|--------|---------|-------------|
| `--port` | `8000` | Server port |
| `--host` | `127.0.0.1` | Server host (use `0.0.0.0` for remote) |
| `--file` | `agents.yaml` | Agents YAML file |
| `--reload` | `false` | Enable hot reload |
| `--api-key` | - | API key for authentication |

## launch() Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `path` | str | `/` | API endpoint path |
| `port` | int | `8000` | Server port |
| `host` | str | `0.0.0.0` | Server host |
| `debug` | bool | `False` | Debug mode |
| `protocol` | str | `http` | `http` or `mcp` |

## Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/{path}` | POST | Send query to agent(s) |
| `/{path}/list` | GET | List available agents |
| `/{path}/{agent_id}` | POST | Call specific agent |
| `/health` | GET | Health check |
| `/docs` | GET | Swagger UI |

## Example Request/Response

**Request:**
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "What is AI?"}'
```

**Response:**
```json
{
  "response": "Artificial intelligence (AI) refers to..."
}
```

## Remote Access

Use `host="0.0.0.0"` to allow remote connections:

```bash
# CLI
praisonai serve agents --port 8000 --host 0.0.0.0

# Python
agent.launch(path="/ask", port=8000, host="0.0.0.0")
```

Connect from remote:
```bash
curl -X POST http://SERVER_IP:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "Hello"}'
```

## Troubleshooting

| Issue | Fix |
|-------|-----|
| Port in use | `lsof -i :8000` then kill process |
| No agents.yaml | `praisonai --init "topic"` |
| Missing API key | `export OPENAI_API_KEY="your-key"` |
| Missing deps | `pip install "praisonaiagents[api]"` |
| Connection refused | Use `host="0.0.0.0"` for remote |
| Firewall blocking | Open port in firewall |

## Related

- [Agents API Reference](../api/agents-api) - Full API documentation
- [Agents MCP](./agents-mcp) - Deploy agents as MCP server
- [Tools MCP](./tools-mcp) - Deploy tools as MCP server
- [Deploy CLI](../cli/index) - Deploy using praisonai deploy
