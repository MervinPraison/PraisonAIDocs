---
title: "Deploy Overview"
sidebarTitle: "Overview"
description: "Deploy PraisonAI agents as HTTP APIs or MCP servers"
icon: "server"
---

Deploy agents as HTTP APIs using `Agent.launch()` or `Agents.launch()`.

## Prerequisites

```bash
pip install "praisonaiagents[api]"
export OPENAI_API_KEY="your-key"
```

## Quick Start

```python
from praisonaiagents import Agent

agent = Agent(instructions="You are a helpful assistant.", llm="gpt-4o-mini")
agent.launch(path="/ask", port=8000)
```

**Expected Output:**
```
üöÄ Agent 'Agent' available at http://0.0.0.0:8000
‚úÖ FastAPI server started at http://0.0.0.0:8000
üìö API documentation available at http://0.0.0.0:8000/docs
üîå Available endpoints: /ask
```

## Test the API

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "What is AI?"}'
```

**Expected Response:**
```json
{
  "response": "AI (Artificial Intelligence) refers to..."
}
```

## Agent.launch() Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `path` | str | `"/"` | API endpoint path |
| `port` | int | `8000` | Server port |
| `host` | str | `"0.0.0.0"` | Server host |
| `debug` | bool | `False` | Enable debug mode |
| `protocol` | str | `"http"` | `"http"` or `"mcp"` |

## Multi-Agent Deployment

Deploy multiple agents on the same server:

```python
from praisonaiagents import Agent

weather_agent = Agent(instructions="Provide weather information.", llm="gpt-4o-mini")
stock_agent = Agent(instructions="Provide stock market info.", llm="gpt-4o-mini")

weather_agent.launch(path="/weather", port=8000)
stock_agent.launch(path="/stock", port=8000)
```

**Endpoints:**
- `POST http://localhost:8000/weather`
- `POST http://localhost:8000/stock`
- `GET http://localhost:8000/health`
- `GET http://localhost:8000/docs` (Swagger UI)

## MCP Server Deployment

Deploy as Model Context Protocol server:

```python
from praisonaiagents import Agent

agent = Agent(instructions="Create tweets based on topics", llm="gpt-4o-mini")
agent.launch(port=8080, protocol="mcp")
```

**Expected Output:**
```
üöÄ Agent 'Agent' MCP server starting on http://0.0.0.0:8080
üì° MCP SSE endpoint available at /sse
üì¢ MCP messages post to /messages/
üõ†Ô∏è Available MCP tools: execute_agent_task
```

## Docker Deployment

**Dockerfile:**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "app.py"]
```

**requirements.txt:**
```
praisonaiagents[api]
```

**Build and Run:**
```bash
docker build -t praisonai-api .
docker run -p 8000:8000 -e OPENAI_API_KEY=$OPENAI_API_KEY praisonai-api
```

## Verify Deployment

```bash
# Health check
curl http://localhost:8000/health

# Expected response
{"status": "ok", "endpoints": ["/ask"]}
```

## Troubleshooting

| Issue | Check |
|-------|-------|
| Port in use | `lsof -i :8000` |
| Missing deps | `pip install "praisonaiagents[api]"` |
| No API key | `echo $OPENAI_API_KEY` |
| Connection refused | Verify `host="0.0.0.0"` for external access |
