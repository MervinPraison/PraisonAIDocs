---
title: "Messages"
description: "Anthropic-style messages API and token counting"
icon: "comments"
---

## Overview

Create messages using Anthropic-style API and count tokens in messages.

## Python Usage

### Create Message

```python
from praisonai.capabilities import messages_create

result = messages_create(
    messages=[{"role": "user", "content": "What is AI?"}],
    model="gpt-4o-mini",
    max_tokens=100,
    system="You are a helpful assistant."
)

if result.content:
    for block in result.content:
        if block.get("type") == "text":
            print(block.get("text"))

print(f"Usage: {result.usage}")
```

### Count Tokens

```python
from praisonai.capabilities import count_tokens

result = count_tokens(
    messages=[
        {"role": "system", "content": "You are helpful."},
        {"role": "user", "content": "Hello, how are you?"}
    ],
    model="gpt-4o-mini"
)

print(f"Token count: {result.input_tokens}")
```

### Async Usage

```python
import asyncio
from praisonai.capabilities import amessages_create, acount_tokens

async def main():
    result = await amessages_create(
        messages=[{"role": "user", "content": "Hello"}],
        model="gpt-4o-mini"
    )
    print(result.content)

asyncio.run(main())
```

## Parameters

### messages_create

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `messages` | List[Dict] | Required | List of messages |
| `model` | str | "claude-3-5-sonnet-20241022" | Model to use |
| `max_tokens` | int | 1024 | Maximum tokens |
| `system` | str | None | System prompt |
| `temperature` | float | 1.0 | Sampling temperature |
| `tools` | List[Dict] | None | Available tools |

### count_tokens

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `messages` | List[Dict] | Required | Messages to count |
| `model` | str | "gpt-4o-mini" | Model for tokenization |
| `system` | str | None | System prompt |

## Result Objects

### MessageResult

- `id`: Message ID
- `content`: List of content blocks
- `role`: Message role
- `model`: Model used
- `stop_reason`: Why generation stopped
- `usage`: Token usage

### TokenCountResult

- `input_tokens`: Number of tokens
- `model`: Model used
