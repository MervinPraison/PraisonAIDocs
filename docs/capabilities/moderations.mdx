---
title: "Moderations"
description: "Content moderation using PraisonAI capabilities"
icon: "shield-check"
---

## Overview

Check content for policy violations using OpenAI's moderation API.

## Python Usage

### Basic Moderation

```python
from praisonai.capabilities import moderate

result = moderate(
    input="Hello, how are you today?"
)

print(f"Flagged: {result[0].flagged}")  # False
print(f"Categories: {result[0].categories}")
```

### Multiple Texts

```python
from praisonai.capabilities import moderate

result = moderate(
    input=["Hello world", "Have a nice day", "This is a test"]
)

for i, r in enumerate(result):
    print(f"Text {i+1}: Flagged = {r.flagged}")
```

### Async Usage

```python
import asyncio
from praisonai.capabilities import amoderate

async def main():
    result = await amoderate(
        input="Check this content"
    )
    print(f"Flagged: {result[0].flagged}")

asyncio.run(main())
```

## Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `input` | str or List[str] | Required | Text(s) to moderate |
| `model` | str | "omni-moderation-latest" | Moderation model |
| `timeout` | float | 600.0 | Request timeout |
| `api_key` | str | None | API key override |

## Result Object

The `ModerationResult` object contains:

- `flagged`: Whether content was flagged
- `categories`: Dict of category flags
- `category_scores`: Dict of category scores
- `model`: Model used
