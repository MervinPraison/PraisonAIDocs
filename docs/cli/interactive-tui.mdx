---
title: "Interactive TUI"
description: "Rich interactive terminal interface for AI-assisted coding"
icon: "rectangle-terminal"
---

# Interactive TUI

PraisonAI CLI provides a rich interactive terminal user interface (TUI) for seamless AI-assisted coding sessions. Inspired by Gemini CLI, Codex CLI, and Claude Code, it offers streaming responses, built-in tools, and a clean terminal experience.

## Overview

The Interactive TUI provides:
- **Streaming responses** - Real-time text output without boxes
- **Built-in tools** - File operations, shell commands, web search
- **Slash commands** - `/help`, `/model`, `/stats`, `/compact`, `/undo`, `/queue`, and more
- **@file mentions** - Include file content with `@file.txt` syntax
- **Message queuing** - Queue messages while agent is processing
- **Model switching** - Change models on-the-fly with `/model`
- **Token tracking** - Monitor usage and costs with `/stats`
- **Context compression** - Summarize history with `/compact`
- **Undo support** - Revert last turn with `/undo`
- **Queue management** - View and manage queued messages with `/queue`
- **Profiling** - Measure response times with `/profile`
- **Tool status indicators** - See when tools are being used
- **Clean UX** - No cluttered panels, just streaming text

## Quick Start

```bash
# Start interactive mode
praisonai chat

# Or use short flag
praisonai -i

# With a specific model
praisonai chat --llm gpt-4o
```

## Chat Mode (Non-Interactive Testing)

For testing and scripting, use `--chat` (or `praisonai chat`) to run a single prompt with interactive-style output:

```bash
# Single prompt with tools, streaming output, no boxes
praisonai "list files in current folder" --chat

# Test web search
praisonai "search the web for AI news" --chat

# Test file operations
praisonai "read the file README.md" --chat
```

<Note>
`--chat` is different from `praisonai chat` which starts a web-based Chainlit UI. The `praisonai chat` flag is an alias for backward compatibility.
</Note>

## Built-in Tools

Interactive mode comes with 5 built-in tools:

| Tool | Description |
|------|-------------|
| `read_file` | Read contents of a file |
| `write_file` | Write content to a file (requires approval) |
| `list_files` | List files in a directory |
| `execute_command` | Run shell commands (requires approval) |
| `internet_search` | Search the web for information |

```bash
# List available tools
‚ùØ /tools
Available tools: 5
  ‚Ä¢ read_file
  ‚Ä¢ write_file
  ‚Ä¢ list_files
  ‚Ä¢ execute_command
  ‚Ä¢ internet_search
```

## Slash Commands

| Command | Description |
|---------|-------------|
| `/help` | Show available commands |
| `/exit` or `/quit` | Exit interactive mode |
| `/clear` | Clear the screen |
| `/tools` | List available tools |
| `/profile` | Toggle profiling (show timing breakdown) |
| `/model [name]` | Show or change current model |
| `/stats` | Show session statistics (tokens, cost) |
| `/compact` | Compress conversation history |
| `/undo` | Undo last response |
| `/queue` | Show queued messages |
| `/queue clear` | Clear message queue |

```bash
‚ùØ /help

Commands:
  /help          - Show this help
  /exit          - Exit interactive mode
  /clear         - Clear screen
  /tools         - List available tools
  /profile       - Toggle profiling (show timing breakdown)
  /model [name]  - Show or change current model
  /stats         - Show session statistics (tokens, cost)
  /compact       - Compress conversation history
  /undo          - Undo last response
  /queue         - Show queued messages
  /queue clear   - Clear message queue

@ Mentions:
  @file.txt      - Include file content in prompt
  @src/          - Include directory listing

Features:
  ‚Ä¢ File operations (read, write, list)
  ‚Ä¢ Shell command execution
  ‚Ä¢ Web search
  ‚Ä¢ Context compression for long sessions
  ‚Ä¢ Queue messages while agent is processing
```

## @File Mentions

Include file content directly in your prompts using `@` syntax, inspired by Gemini CLI and Claude Code:

```bash
# Include a file in your prompt
‚ùØ what does @README.md say about installation?
üìÑ Included: README.md (2,345 chars)

The README.md file explains that installation can be done via pip...

# Include multiple files
‚ùØ compare @file1.py and @file2.py
üìÑ Included: file1.py (500 chars)
üìÑ Included: file2.py (450 chars)

Here are the key differences between the two files...

# Include directory listing
‚ùØ what files are in @src/
üìÅ Listed: src/ (15 items)

The src/ directory contains the following files...
```

<Note>
- Files larger than 50KB are automatically truncated
- Hidden files and common ignore patterns (node_modules, __pycache__) are filtered from directory listings
- Paths can be relative or absolute
- Use `~` for home directory (e.g., `@~/Documents/file.txt`)
</Note>

## Model Switching

Change models on-the-fly without restarting:

```bash
# Show current model
‚ùØ /model
Current model: gpt-4o-mini

Available models (examples):
  ‚Ä¢ gpt-4o, gpt-4o-mini
  ‚Ä¢ claude-3-5-sonnet, claude-3-haiku
  ‚Ä¢ gemini-2.0-flash, gemini-1.5-pro

Usage: /model <model-name>

# Change to a different model
‚ùØ /model gpt-4o
‚úì Model changed: gpt-4o-mini ‚Üí gpt-4o

# Verify the change
‚ùØ /model
Current model: gpt-4o
```

## Session Statistics

Track token usage and estimated costs:

```bash
‚ùØ /stats

Session Statistics
  Model:          gpt-4o-mini
  Requests:       5
  Input tokens:   1,234
  Output tokens:  2,567
  Total tokens:   3,801
  Estimated cost: $0.0023
  History turns:  10
```

<Tip>
Use `/stats` regularly to monitor your token usage and avoid unexpected costs.
</Tip>

## Context Compression

When conversations get long, use `/compact` to summarize older history:

```bash
‚ùØ /compact
Compacting conversation history...
‚úì Compacted 12 turns ‚Üí 5 turns
Summary: User asked about Python file operations, discussed error handling...
```

This feature is inspired by Claude Code's `/compact` and Gemini CLI's `/compress`. It:
- Keeps the last 2 conversation turns intact
- Summarizes older turns using the LLM
- Reduces token usage for long sessions
- Preserves key context and decisions

## Undo Support

Made a mistake? Use `/undo` to remove the last conversation turn:

```bash
‚ùØ write a function to sort a list
[AI generates sorting function]

‚ùØ /undo
‚úì Undone last turn
Removed: write a function to sort a list...

‚ùØ /stats
Session Statistics
  ...
  History turns:  8  # Reduced from 10
```

## Message Queue

Queue messages while the AI agent is processing. Type new prompts and they'll be executed in order as each task completes.

```bash
# While agent is processing, type more messages
‚ùØ Create a Python function to calculate fibonacci
[Agent processing...]

‚ùØ Add docstrings to the function
‚ùØ Create unit tests

# Check the queue
‚ùØ /queue
‚è≥ Processing...

Queued Messages (2):
  0. ‚Ü≥ Add docstrings to the function
  1. ‚Ü≥ Create unit tests

Use /queue clear to clear, /queue remove N to remove
```

### Queue Commands

| Command | Description |
|---------|-------------|
| `/queue` | Show all queued messages |
| `/queue clear` | Clear the entire queue |
| `/queue remove N` | Remove message at index N |

<Tip>
Messages are processed in FIFO order (First In, First Out). The agent automatically processes the next queued message when the current task completes.
</Tip>

<Card title="Message Queue" icon="layer-group" href="/cli/message-queue">
  See the full Message Queue documentation for programmatic usage and API reference.
</Card>

## Profiling

Enable profiling to see timing breakdown:

```bash
‚ùØ /profile
Profiling enabled

‚ùØ what is 2+2
4

‚îÄ‚îÄ‚îÄ Profiling ‚îÄ‚îÄ‚îÄ
Import:      0.1ms
Agent setup: 0.3ms
LLM call:    1,234.5ms
Display:     15.2ms
Total:       1,250.1ms

‚ùØ /profile
Profiling disabled
```

## Output Comparison

### Interactive Mode (Clean)
```bash
‚ùØ what is 2+2

4
```

### Regular Mode (Verbose)
```bash
‚ï≠‚îÄ Agent Info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ  üë§ Agent: DirectAgent                                   ‚îÇ
‚îÇ  Role: Assistant                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Task ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ what is 2+2                                              ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Response ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ 4                                                        ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

## Features

### Streaming Responses

Responses stream word-by-word for a natural feel, similar to Gemini CLI and Claude Code.

### Tool Status Indicators

When tools are used, you'll see status indicators:

```bash
‚ùØ list files in current folder
‚öô Using list_files...
‚úì list_files complete

Here are the files in the current folder:
- README.md
- main.py
- config.yaml
```

### Security

High-risk tools require approval:
- `write_file` - HIGH risk level
- `execute_command` - CRITICAL risk level

```bash
‚ùØ run the command 'rm -rf /'
‚ï≠‚îÄ üîí Tool Approval Required ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Function: execute_command                                ‚îÇ
‚îÇ Risk Level: CRITICAL                                     ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

## Python API

### Basic Usage

```python
from praisonai.cli.features import InteractiveTUIHandler

# Create handler
handler = InteractiveTUIHandler()

# Define callbacks
def on_input(text):
    """Handle regular input."""
    return f"You said: {text}"

def on_command(cmd):
    """Handle slash commands."""
    if cmd == "/exit":
        return {"type": "exit"}
    return {"type": "command", "message": f"Executed: {cmd}"}

# Initialize and run
session = handler.initialize(
    on_input=on_input,
    on_command=on_command
)

handler.run()
```

### Configuration

```python
from praisonai.cli.features.interactive_tui import (
    InteractiveConfig,
    InteractiveTUIHandler
)

config = InteractiveConfig(
    prompt="ü§ñ >>> ",           # Custom prompt
    multiline=True,             # Enable multi-line input
    history_file="~/.praisonai_history",  # Persistent history
    max_history=1000,           # Max history entries
    enable_completions=True,    # Enable auto-complete
    enable_syntax_highlighting=True,  # Enable highlighting
    vi_mode=False,              # Use emacs keybindings
    auto_suggest=True,          # Show suggestions
    show_status_bar=True,       # Show status bar
    color_scheme="monokai"      # Color theme
)

handler = InteractiveTUIHandler()
session = handler.initialize(config=config)
```

### Custom Completions

```python
from praisonai.cli.features.interactive_tui import InteractiveSession

session = InteractiveSession()

# Add slash commands for completion
# Note: Autocomplete only triggers when you type /
session.add_commands(["help", "exit", "cost", "model", "plan", "queue"])

# Add symbols from your codebase
session.add_symbols(["MyClass", "my_function", "CONFIG"])

# Refresh file completions
session.refresh_files(root=Path("/path/to/project"))
```

### History Management

```python
from praisonai.cli.features.interactive_tui import HistoryManager

# Create history manager
history = HistoryManager(
    history_file="~/.my_history",
    max_entries=500
)

# Add entries
history.add("first command")
history.add("second command")

# Navigate
prev = history.get_previous()  # "second command"
prev = history.get_previous()  # "first command"
next_cmd = history.get_next()  # "second command"

# Search
results = history.search("/help")  # Find commands starting with "/help"

# Clear
history.clear()
```

### Status Display

```python
from praisonai.cli.features.interactive_tui import StatusDisplay

display = StatusDisplay(show_status_bar=True)

# Set status items
display.set_status("model", "gpt-4o")
display.set_status("tokens", "1,234")
display.set_status("cost", "$0.05")

# Print formatted output
display.print_welcome(version="1.0.0")
display.print_response("Here's the solution...", title="AI Response")
display.print_error("Something went wrong")
display.print_info("Processing...")
display.print_success("Done!")
```

## Keyboard Shortcuts

### Navigation

| Shortcut | Action |
|----------|--------|
| `‚Üë` / `‚Üì` | Navigate history |
| `Ctrl+R` | Search history |
| `Ctrl+A` | Move to start of line |
| `Ctrl+E` | Move to end of line |
| `Ctrl+W` | Delete word backward |

### Editing

| Shortcut | Action |
|----------|--------|
| `Tab` | Auto-complete |
| `Ctrl+C` | Cancel current input |
| `Ctrl+D` | Exit (on empty line) |
| `Ctrl+L` | Clear screen |

### Multi-line

| Shortcut | Action |
|----------|--------|
| `Enter` | New line (in multi-line mode) |
| `Enter` on empty | Submit input |
| `Ctrl+Enter` | Submit immediately |

## VI Mode

Enable VI keybindings:

```python
config = InteractiveConfig(vi_mode=True)
```

VI mode shortcuts:
- `Esc` - Enter command mode
- `i` - Insert mode
- `a` - Append mode
- `dd` - Delete line
- `/` - Search

## Customization

### Custom Prompt

```python
config = InteractiveConfig(
    prompt="ü§ñ praisonai> "
)
```

### Dynamic Prompt

```python
def get_prompt():
    branch = get_git_branch()
    return f"({branch}) >>> "

# Update prompt dynamically
session.config.prompt = get_prompt()
```

### Custom Theme

```python
from prompt_toolkit.styles import Style

custom_style = Style.from_dict({
    'prompt': '#00aa00 bold',
    'input': '#ffffff',
    'completion': 'bg:#333333 #ffffff',
})

# Apply to session
session._prompt_session.style = custom_style
```

## Integration

### With Slash Commands

```python
from praisonai.cli.features import (
    InteractiveTUIHandler,
    SlashCommandHandler
)

# Create handlers
tui = InteractiveTUIHandler()
slash = SlashCommandHandler()

def on_command(cmd):
    if slash.is_command(cmd):
        return slash.execute(cmd)
    return None

session = tui.initialize(on_command=on_command)
```

### With Cost Tracking

```python
from praisonai.cli.features import (
    InteractiveTUIHandler,
    CostTrackerHandler
)

tui = InteractiveTUIHandler()
cost = CostTrackerHandler()
cost.initialize()

def on_input(text):
    # Process with AI...
    response = ai.chat(text)
    
    # Track costs
    cost.track_request("gpt-4o", input_tokens, output_tokens)
    
    # Update status
    tui._session.display.set_status("cost", f"${cost.get_cost():.4f}")
    
    return response

session = tui.initialize(on_input=on_input)
```

## Fallback Mode

If prompt_toolkit is not available, a simple fallback is used:

```python
# Without prompt_toolkit
>>> (Enter empty line to submit)
Hello, help me with my code

# Basic input still works, just without advanced features
```

## Best Practices

1. **Use @file mentions** - Include relevant files directly in prompts for context
2. **Monitor with /stats** - Check token usage regularly to avoid surprises
3. **Use /compact** - Compress history when conversations get long
4. **Switch models** - Use `/model gpt-4o-mini` for simple tasks, `/model gpt-4o` for complex ones
5. **Enable profiling** - Use `/profile` to identify slow operations
6. **Use completions** - Press Tab often for faster input
7. **Learn shortcuts** - Ctrl+R for history search is powerful

## Feature Comparison

PraisonAI Interactive Mode compared to other AI CLI tools:

| Feature | PraisonAI | Claude Code | Gemini CLI | Codex CLI |
|---------|-----------|-------------|------------|-----------|
| `/help` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/clear` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/tools` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/model` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/stats` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/compact` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/undo` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `/queue` | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| `@file` mentions | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Message queuing | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Autocomplete | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Profiling | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |
| Streaming | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Tool execution | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |

## Troubleshooting

### Completions Not Working

```bash
# Install prompt_toolkit
pip install prompt_toolkit

# Verify installation
python -c "import prompt_toolkit; print(prompt_toolkit.__version__)"
```

### History Not Persisting

```python
# Ensure history file path is writable
config = InteractiveConfig(
    history_file=os.path.expanduser("~/.praisonai_history")
)
```

### Display Issues

```bash
# Set terminal type
export TERM=xterm-256color

# Or disable colors
config = InteractiveConfig(enable_syntax_highlighting=False)
```

### @File Mentions Not Working

```bash
# Ensure the file exists and is readable
ls -la @yourfile.txt

# Use absolute paths if relative paths don't work
‚ùØ what does @/full/path/to/file.txt say?

# Check for typos in the path
‚ùØ what does @README.md say?  # Correct
‚ùØ what does @readme.md say?  # Case-sensitive on Linux/Mac
```

## Related Features

- [Message Queue](/docs/cli/message-queue) - Queue messages while agent is processing
- [Slash Commands](/docs/cli/slash-commands) - Full slash command reference
- [Cost Tracking](/docs/cli/cost-tracking) - Detailed cost monitoring
- [Session](/docs/cli/session) - Session management
- [Mentions](/docs/cli/mentions) - @file mention syntax
- [Git Integration](/docs/cli/git-integration) - Git workflow support
