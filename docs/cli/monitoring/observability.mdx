---
title: "observability"
description: "Enable observability and monitoring for agent execution"
icon: "eye"
---

# praisonai observability

Enable observability and monitoring for agent execution.

## Usage

```bash
praisonai observability [OPTIONS]
```

## Options

| Option | Short | Description |
|--------|-------|-------------|
| `--provider` | `-p` | Observability provider (langfuse, phoenix, agentops) |
| `--enable` | `-e` | Enable observability |
| `--disable` | `-d` | Disable observability |
| `--config` | `-c` | Path to observability config file |

## Supported Providers

### Langfuse

```bash
praisonai observability --provider langfuse --enable
```

Required environment variables:
```bash
export LANGFUSE_PUBLIC_KEY="pk-..."
export LANGFUSE_SECRET_KEY="sk-..."
export LANGFUSE_HOST="https://cloud.langfuse.com"
```

### Phoenix (Arize)

```bash
praisonai observability --provider phoenix --enable
```

Required environment variables:
```bash
export PHOENIX_API_KEY="..."
```

### AgentOps

```bash
praisonai observability --provider agentops --enable
```

Required environment variables:
```bash
export AGENTOPS_API_KEY="..."
```

## Examples

### Enable Langfuse

```bash
# Set credentials
export LANGFUSE_PUBLIC_KEY="pk-lf-..."
export LANGFUSE_SECRET_KEY="sk-lf-..."

# Enable
praisonai observability --provider langfuse --enable

# Run agents (traces will be sent to Langfuse)
praisonai agents "Research AI trends"
```

### Enable Phoenix

```bash
# Set credentials
export PHOENIX_API_KEY="..."

# Enable
praisonai observability --provider phoenix --enable

# Run agents
praisonai agents "Analyze data"
```

### Disable Observability

```bash
praisonai observability --disable
```

### Check Status

```bash
praisonai observability --status
```

## Configuration File

Create `observability.yaml`:

```yaml
provider: langfuse
enabled: true
config:
  trace_name: "my-app"
  environment: "production"
  sample_rate: 1.0
```

Use with:

```bash
praisonai observability --config observability.yaml
```

## Programmatic Usage

```python
from praisonaiagents import Agent
from praisonaiagents.telemetry import enable_observability

# Enable observability
enable_observability(provider="langfuse")

# Create and run agent
agent = Agent(name="Researcher")
result = agent.start("Research AI trends")
# Traces are automatically sent to Langfuse
```

## What Gets Tracked

- Agent executions
- Tool calls
- LLM requests and responses
- Token usage
- Latency metrics
- Error traces
- Memory operations
- Task completions

## Related

- [Telemetry CLI](/docs/cli/telemetry) - Telemetry commands
- [Metrics CLI](/docs/cli/metrics) - Metrics commands
- [Observability Integrations](/docs/integrations/observability) - Provider setup
