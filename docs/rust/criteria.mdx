---
title: "Criteria"
sidebarTitle: "Criteria"
description: "Evaluate agents against custom criteria"
icon: "list-check"
---

Criteria evaluation measures agent output against custom standards.

```mermaid
graph LR
    subgraph "Criteria Evaluation"
        O[ðŸ“¤ Output] --> E[ðŸ“Š Evaluate]
        E --> C1[âœ“ Clarity]
        E --> C2[âœ“ Accuracy]
        E --> C3[âœ“ Helpfulness]
    end
    
    classDef output fill:#6366F1,stroke:#7C90A0,color:#fff
    classDef criteria fill:#10B981,stroke:#7C90A0,color:#fff
    
    class O output
    class E,C1,C2,C3 criteria
```

## Quick Start

<Steps>
<Step title="Define Criteria">
```rust
use praisonai::CriteriaEvaluator;

let evaluator = CriteriaEvaluator::new()
    .criterion("clarity", "Is the response clear and easy to understand?")
    .criterion("accuracy", "Is the information factually correct?")
    .criterion("completeness", "Does it fully answer the question?")
    .build();

let scores = evaluator.evaluate(&response);
for (name, score) in scores {
    println!("{}: {:.0}%", name, score * 100.0);
}
```
</Step>
</Steps>

---

## Common Criteria

| Criterion | Description |
|-----------|-------------|
| Clarity | Easy to understand |
| Accuracy | Factually correct |
| Completeness | Fully addresses query |
| Conciseness | No unnecessary content |
| Helpfulness | Actionable and useful |

---

## Related

<CardGroup cols={2}>
  <Card title="Evaluation" icon="chart-bar" href="/docs/rust/evaluation">
    Evaluation system
  </Card>
  <Card title="Optimizer" icon="wand-sparkles" href="/docs/rust/optimizer">
    Auto-improvement
  </Card>
</CardGroup>
