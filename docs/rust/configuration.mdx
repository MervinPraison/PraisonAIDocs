---
title: "Configuration"
sidebarTitle: "Configuration"
description: "Configure agent features with typed configuration structs in the PraisonAI Rust SDK"
icon: "gear"
---

# Configuration

The Rust SDK uses typed configuration structs for each feature. All configs follow the pattern: disabled by default, enable with safe defaults, or customize with builder methods.

## Quick Start

```rust
use praisonai::{Agent, MemoryConfig, KnowledgeConfig, PlanningConfig};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let agent = Agent::new("assistant")
        .instructions("You are a helpful assistant")
        .memory(MemoryConfig::new().max_messages(50))
        .knowledge(KnowledgeConfig::new().source("docs/"))
        .planning(PlanningConfig::new().enabled())
        .build()?;
    
    Ok(())
}
```

## MemoryConfig

Configure conversation memory:

```rust
use praisonai::MemoryConfig;

let config = MemoryConfig::new()
    .with_long_term()          // Enable persistent memory
    .provider("sqlite")        // Storage provider
    .max_messages(100);        // Message limit

// Defaults
assert_eq!(MemoryConfig::default().use_short_term, true);
assert_eq!(MemoryConfig::default().use_long_term, false);
assert_eq!(MemoryConfig::default().max_messages, 100);
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `use_short_term` | `bool` | `true` | Enable conversation history |
| `use_long_term` | `bool` | `false` | Enable persistent storage |
| `provider` | `String` | `"memory"` | Storage backend |
| `max_messages` | `usize` | `100` | Maximum messages |

## KnowledgeConfig

Configure RAG and knowledge retrieval:

```rust
use praisonai::{KnowledgeConfig, ChunkingStrategy};

let config = KnowledgeConfig::new()
    .source("docs/")                          // Add source
    .source("https://example.com/guide")      // URL source
    .embedder("openai")                       // Embedding model
    .chunking(ChunkingStrategy::Semantic)     // Chunking strategy
    .chunk_size(1000)                         // Chunk size
    .retrieval_k(5)                           // Top-k results
    .with_rerank();                           // Enable reranking
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `sources` | `Vec<String>` | `[]` | Knowledge sources |
| `embedder` | `String` | `"openai"` | Embedding model |
| `chunking_strategy` | `ChunkingStrategy` | `Semantic` | Chunking method |
| `chunk_size` | `usize` | `1000` | Characters per chunk |
| `chunk_overlap` | `usize` | `200` | Overlap between chunks |
| `retrieval_k` | `usize` | `5` | Results to retrieve |
| `rerank` | `bool` | `false` | Enable reranking |

### ChunkingStrategy

```rust
use praisonai::ChunkingStrategy;

ChunkingStrategy::Fixed      // Fixed-size chunks
ChunkingStrategy::Semantic   // Semantic chunking (default)
ChunkingStrategy::Sentence   // Sentence-based
ChunkingStrategy::Paragraph  // Paragraph-based
```

## PlanningConfig

Configure planning mode:

```rust
use praisonai::PlanningConfig;

let config = PlanningConfig::new()
    .enabled()                  // Enable planning
    .llm("gpt-4")              // Planning LLM
    .with_reasoning()           // Enable reasoning
    .auto_approve()             // Auto-approve plans
    .read_only();               // Read-only mode
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `enabled` | `bool` | `false` | Enable planning |
| `llm` | `Option<String>` | `None` | Planning LLM model |
| `reasoning` | `bool` | `false` | Enable reasoning |
| `auto_approve` | `bool` | `false` | Skip confirmation |
| `read_only` | `bool` | `false` | Read-only operations |

## ReflectionConfig

Configure self-reflection:

```rust
use praisonai::ReflectionConfig;

let config = ReflectionConfig::new()
    .enabled()                  // Enable reflection
    .min_iterations(1)          // Minimum iterations
    .max_iterations(5)          // Maximum iterations
    .llm("gpt-4")              // Reflection LLM
    .prompt("Evaluate your response for accuracy...");
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `enabled` | `bool` | `false` | Enable reflection |
| `min_iterations` | `usize` | `1` | Minimum iterations |
| `max_iterations` | `usize` | `3` | Maximum iterations |
| `llm` | `Option<String>` | `None` | Reflection LLM |
| `prompt` | `Option<String>` | `None` | Custom prompt |

## GuardrailConfig

Configure safety validation:

```rust
use praisonai::{config::GuardrailConfig, config::GuardrailAction};

let config = GuardrailConfig::new()
    .enabled()                                  // Enable guardrails
    .llm_validator("Check for harmful content") // LLM validation
    .max_retries(3)                             // Retry count
    .on_fail(GuardrailAction::Retry)           // Action on failure
    .policy("pii:redact");                      // Add policies
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `enabled` | `bool` | `false` | Enable guardrails |
| `llm_validator` | `Option<String>` | `None` | Validation prompt |
| `max_retries` | `usize` | `3` | Retry attempts |
| `on_fail` | `GuardrailAction` | `Retry` | Failure action |
| `policies` | `Vec<String>` | `[]` | Policy strings |

### GuardrailAction

```rust
use praisonai::config::GuardrailAction;

GuardrailAction::Retry  // Retry the operation (default)
GuardrailAction::Skip   // Skip the operation
GuardrailAction::Raise  // Raise an error
```

## WebConfig

Configure web search and fetch:

```rust
use praisonai::{WebConfig, WebSearchProvider};

let config = WebConfig::new()
    .provider(WebSearchProvider::Google)  // Search provider
    .max_results(10)                       // Result limit
    .no_fetch();                           // Disable page fetching
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `search` | `bool` | `true` | Enable search |
| `fetch` | `bool` | `true` | Enable page fetch |
| `search_provider` | `WebSearchProvider` | `DuckDuckGo` | Provider |
| `max_results` | `usize` | `5` | Maximum results |

### WebSearchProvider

```rust
use praisonai::WebSearchProvider;

WebSearchProvider::DuckDuckGo  // Free, default
WebSearchProvider::Google      // Google search
WebSearchProvider::Bing        // Bing search
WebSearchProvider::Tavily      // Tavily AI search
WebSearchProvider::Serper      // Serper API
```

## CachingConfig

Configure response caching:

```rust
use praisonai::CachingConfig;

let config = CachingConfig::new()
    .with_prompt_caching()  // Enable prompt caching
    .ttl(3600);             // 1 hour TTL

// Disable caching
let no_cache = CachingConfig::new().disabled();
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `enabled` | `bool` | `true` | Enable caching |
| `prompt_caching` | `bool` | `false` | Provider prompt caching |
| `ttl_secs` | `Option<u64>` | `None` | Cache TTL in seconds |

## AutonomyConfig

Configure agent autonomy:

```rust
use praisonai::{AutonomyConfig, AutonomyLevel};

let config = AutonomyConfig::new()
    .level(AutonomyLevel::AutoEdit);
```

### AutonomyLevel

```rust
use praisonai::AutonomyLevel;

AutonomyLevel::Suggest    // Suggest actions, wait for approval (default)
AutonomyLevel::AutoEdit   // Auto-edit with confirmation
AutonomyLevel::FullAuto   // Full autonomous operation
```

## ExecutionConfig

Configure execution parameters:

```rust
use praisonai::ExecutionConfig;

let config = ExecutionConfig::new()
    .max_iterations(20)     // Maximum loop iterations
    .timeout(600)           // 10 minute timeout
    .no_stream();           // Disable streaming
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `max_iterations` | `usize` | `10` | Maximum iterations |
| `timeout_secs` | `u64` | `300` | Timeout in seconds |
| `stream` | `bool` | `true` | Enable streaming |

## OutputConfig

Configure output behavior:

```rust
use praisonai::OutputConfig;

let config = OutputConfig::new()
    .silent()               // Silent mode
    .file("output.log");    // Log to file

// Other modes
OutputConfig::new().verbose();  // Verbose output
OutputConfig::new().json();     // JSON output
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `mode` | `String` | `"verbose"` | Output mode |
| `file` | `Option<String>` | `None` | Output file path |

## Related

<CardGroup cols={2}>
  <Card title="Agent" icon="robot" href="/docs/rust/agent">
    Apply configurations to agents
  </Card>
  <Card title="Memory" icon="brain" href="/docs/rust/memory">
    Memory system details
  </Card>
  <Card title="Knowledge" icon="book" href="/docs/rust/knowledge">
    RAG and knowledge retrieval
  </Card>
  <Card title="Guardrails" icon="shield" href="/docs/rust/guardrails">
    Safety validation
  </Card>
</CardGroup>
