---
title: "Embedding"
sidebarTitle: "Embedding"
description: "Generate text embeddings in the PraisonAI Rust SDK"
icon: "brain"
---

# Embedding

Generate text embeddings for semantic search, similarity calculations, and RAG applications.

## Quick Start

```rust
use praisonai::embedding::{EmbeddingAgent, EmbeddingConfig};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let agent = EmbeddingAgent::new()
        .model("text-embedding-3-small")
        .build()?;
    
    // Single text
    let embedding = agent.embed("Hello, world!").await?;
    println!("Dimensions: {}", embedding.len());
    
    // Calculate similarity
    let score = agent.similarity("cat", "dog").await?;
    println!("Similarity: {:.3}", score);
    
    Ok(())
}
```

## EmbeddingAgent

The main agent for generating embeddings:

```rust
use praisonai::embedding::EmbeddingAgent;

let agent = EmbeddingAgent::new()
    .name("MyEmbedder")
    .model("text-embedding-3-small")
    .api_key("sk-...")
    .api_base("https://api.openai.com/v1")
    .verbose(false)
    .build()?;

// Or use defaults
let simple = EmbeddingAgent::simple()?;
```

### Supported Models

| Provider | Model | Dimensions |
|----------|-------|------------|
| OpenAI | `text-embedding-3-small` | 1536 |
| OpenAI | `text-embedding-3-large` | 3072 |
| OpenAI | `text-embedding-ada-002` | 1536 |
| Cohere | `cohere/embed-english-v3.0` | 1024 |
| Voyage | `voyage/voyage-3` | 1024 |
| Mistral | `mistral/mistral-embed` | 1024 |

## Single Embedding

Generate embedding for one text:

```rust
let embedding = agent.embed("Your text here").await?;

println!("Dimensions: {}", embedding.len());
println!("First values: {:?}", &embedding[..5]);
```

## Batch Embedding

Generate embeddings for multiple texts efficiently:

```rust
let texts = ["First text", "Second text", "Third text"];
let result = agent.embed_batch(&texts).await?;

println!("Embeddings: {}", result.len());
println!("Model: {}", result.model);
println!("Tokens used: {}", result.usage.total_tokens);

for (i, emb) in result.embeddings.iter().enumerate() {
    println!("Text {}: {} dimensions", i, emb.len());
}
```

### EmbeddingResult

Container for batch results:

```rust
use praisonai::embedding::EmbeddingResult;

let result = agent.embed_batch(&["a", "b"]).await?;

println!("Count: {}", result.len());
println!("Empty: {}", result.is_empty());
println!("Dimension: {}", result.dimension());

if let Some(first) = result.first() {
    println!("First embedding: {:?}", &first[..3]);
}
```

## Similarity Calculation

Compare two texts semantically:

```rust
let score = agent.similarity("The cat sat on the mat", "A feline rested on the rug").await?;

println!("Similarity: {:.3}", score);  // Higher = more similar
```

## Find Most Similar

Find texts most similar to a query:

```rust
let query = "machine learning";
let candidates = [
    "artificial intelligence and neural networks",
    "cooking recipes for dinner",
    "deep learning models",
    "sports and athletics",
    "natural language processing",
];

let results = agent.find_most_similar(query, &candidates, 3).await?;

for result in results {
    println!("{:.3}: {}", result.score, result.text);
}
```

### SimilarityResult

Individual similarity match:

```rust
use praisonai::embedding::SimilarityResult;

// result.text   - The matched text
// result.score  - Similarity score (0.0 to 1.0)
// result.index  - Original index in candidates
```

## Configuration

Fine-tune embedding behavior:

```rust
use praisonai::embedding::EmbeddingConfig;

let config = EmbeddingConfig::new()
    .dimensions(1536)             // Override dimensions
    .encoding_format("float")     // or "base64"
    .timeout(30)                  // Seconds
    .api_key("sk-...")
    .api_base("https://api.openai.com/v1");

let agent = EmbeddingAgent::new()
    .config(config)
    .build()?;
```

### Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `dimensions` | Option\<usize\> | None | Override model dimensions |
| `encoding_format` | String | "float" | Response format |
| `timeout` | u64 | 60 | Request timeout (seconds) |
| `api_base` | Option\<String\> | OpenAI | API endpoint |
| `api_key` | Option\<String\> | Env | API key |

## Utility Functions

### Cosine Similarity

Calculate similarity between vectors:

```rust
use praisonai::embedding::cosine_similarity;

let vec1 = vec![1.0, 0.0, 0.0];
let vec2 = vec![0.707, 0.707, 0.0];

let similarity = cosine_similarity(&vec1, &vec2);
println!("Cosine similarity: {:.3}", similarity);
```

### Get Model Dimensions

Look up embedding dimensions for a model:

```rust
use praisonai::embedding::get_dimensions;

let dims = get_dimensions("text-embedding-3-small");
println!("Dimensions: {:?}", dims);  // Some(1536)

let unknown = get_dimensions("unknown-model");
println!("Unknown: {:?}", unknown);  // None
```

## Example: Semantic Search

```rust
use praisonai::embedding::EmbeddingAgent;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let agent = EmbeddingAgent::new()
        .model("text-embedding-3-small")
        .build()?;
    
    // Document corpus
    let documents = [
        "Rust is a systems programming language focused on safety",
        "Python is popular for data science and machine learning",
        "JavaScript runs in web browsers and Node.js",
        "Go is designed for cloud and network services",
        "TypeScript adds static typing to JavaScript",
    ];
    
    // User query
    let query = "What language is best for cloud services?";
    
    // Find most relevant documents
    let results = agent.find_most_similar(query, &documents, 2).await?;
    
    println!("Query: {}", query);
    println!("\nTop matches:");
    for result in results {
        println!("  [{:.3}] {}", result.score, result.text);
    }
    
    Ok(())
}
```

## Example: With Knowledge Base

```rust
use praisonai::embedding::EmbeddingAgent;
use praisonai::knowledge::{Knowledge, VectorRecord, InMemoryVectorStore};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let embedder = EmbeddingAgent::simple()?;
    let mut store = InMemoryVectorStore::new();
    
    // Add documents
    let docs = ["Document 1 content", "Document 2 content"];
    for (i, doc) in docs.iter().enumerate() {
        let embedding = embedder.embed(doc).await?;
        let record = VectorRecord::new(format!("doc-{}", i), *doc, embedding);
        store.add(record).await?;
    }
    
    // Search
    let query_embedding = embedder.embed("search query").await?;
    let results = store.search(&query_embedding, 5).await?;
    
    for result in results {
        println!("{:.3}: {}", result.score, result.text);
    }
    
    Ok(())
}
```

## Related

<CardGroup cols={2}>
  <Card title="Knowledge" icon="book-open-reader" href="/docs/rust/knowledge">
    RAG knowledge base
  </Card>
  <Card title="Agent" icon="robot" href="/docs/rust/agent">
    Agent API
  </Card>
  <Card title="Memory" icon="brain" href="/docs/rust/memory">
    Conversation memory
  </Card>
  <Card title="RAG Concepts" icon="database" href="/docs/concepts/rag">
    RAG overview
  </Card>
</CardGroup>
