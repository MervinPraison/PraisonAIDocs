---
title: "Guardrails"
sidebarTitle: "Guardrails"
description: "Input/output validation and safety checks"
icon: "shield-check"
---

PraisonAI TypeScript provides guardrails for validating and filtering agent inputs and outputs.

## Installation

```bash
npm install praisonai
```

## Basic Guardrail

```typescript
import { guardrail } from 'praisonai';

const lengthCheck = guardrail({
  name: 'length_check',
  description: 'Ensure content is not too long',
  check: (content) => {
    if (content.length > 1000) {
      return { 
        status: 'failed', 
        message: 'Content too long' 
      };
    }
    return { status: 'passed' };
  }
});

const result = await lengthCheck.run('Hello world');
console.log(result.status); // 'passed'
```

## Built-in Guardrails

```typescript
import { builtinGuardrails } from 'praisonai';

// Maximum length
const maxLen = builtinGuardrails.maxLength(500);

// Minimum length
const minLen = builtinGuardrails.minLength(10);

// Blocked words
const noSwearing = builtinGuardrails.blockedWords(['bad', 'evil']);

// Required words
const mustInclude = builtinGuardrails.requiredWords(['hello', 'please']);

// Regex pattern (must match)
const hasNumbers = builtinGuardrails.pattern(/\d+/, true);

// Regex pattern (must NOT match)
const noEmails = builtinGuardrails.pattern(/\S+@\S+/, false);

// Valid JSON
const jsonCheck = builtinGuardrails.validJson();
```

## Guardrail Manager

```typescript
import { GuardrailManager, builtinGuardrails } from 'praisonai';

const manager = new GuardrailManager();

manager.add(builtinGuardrails.maxLength(1000));
manager.add(builtinGuardrails.blockedWords(['spam', 'scam']));
manager.add(builtinGuardrails.minLength(5));

const { passed, results } = await manager.runAll('Hello world');

if (passed) {
  console.log('All guardrails passed');
} else {
  for (const { name, result } of results) {
    if (result.status === 'failed') {
      console.log(`${name} failed: ${result.message}`);
    }
  }
}
```

## Failure Modes

```typescript
import { guardrail } from 'praisonai';

// Block on failure (default)
const blockGuard = guardrail({
  name: 'blocker',
  onFail: 'block',
  check: (content) => ({ status: 'failed' })
});

// Warn on failure (continue processing)
const warnGuard = guardrail({
  name: 'warner',
  onFail: 'warn',
  check: (content) => ({ status: 'failed' })
});

// Modify content on failure
const modifyGuard = guardrail({
  name: 'modifier',
  onFail: 'modify',
  check: (content) => ({
    status: 'failed',
    modifiedContent: content.replace(/bad/g, '***')
  })
});
```

## Context-Aware Guardrails

```typescript
const contextGuard = guardrail({
  name: 'context_aware',
  check: (content, context) => {
    console.log('Role:', context?.role); // 'input' or 'output'
    console.log('Agent:', context?.agentName);
    console.log('Session:', context?.sessionId);
    
    return { status: 'passed' };
  }
});

await contextGuard.run('test', { 
  role: 'input', 
  agentName: 'MyAgent' 
});
```

## Custom Guardrail with Details

```typescript
const customGuard = guardrail({
  name: 'sentiment_check',
  check: async (content) => {
    const sentiment = await analyzeSentiment(content);
    
    if (sentiment.score < 0) {
      return {
        status: 'failed',
        message: 'Negative sentiment detected',
        details: {
          score: sentiment.score,
          keywords: sentiment.negativeWords
        }
      };
    }
    
    return { 
      status: 'passed',
      details: { score: sentiment.score }
    };
  }
});
```

## Async Guardrails

```typescript
const asyncGuard = guardrail({
  name: 'api_check',
  check: async (content) => {
    const result = await externalModerationAPI(content);
    return {
      status: result.safe ? 'passed' : 'failed',
      message: result.reason
    };
  }
});
```
