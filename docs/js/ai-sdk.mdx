---
title: "AI SDK Backend"
description: "Multi-provider LLM support via Vercel's AI SDK in PraisonAI TypeScript"
icon: "microchip-ai"
---

# AI SDK Backend

The AI SDK Backend provides a unified interface to multiple LLM providers through Vercel's AI SDK. This enables agents to seamlessly switch between providers like OpenAI, Anthropic, Google, and more.

## Why AI SDK?

- **Multi-provider support**: Access 13+ LLM providers with a single API
- **Streaming**: Built-in streaming with backpressure support
- **Tool calling**: Native tool/function calling support
- **Structured output**: Generate typed JSON objects with schemas
- **Attribution**: Multi-agent safety with trace/run/session IDs

## Installation

```bash
npm install praisonai ai @ai-sdk/openai
```

For other providers:
```bash
npm install @ai-sdk/anthropic @ai-sdk/google @ai-sdk/groq
```

## Quick Start

```typescript
import { createAISDKBackend } from 'praisonai';

// Create backend with model string
const backend = createAISDKBackend('openai/gpt-4o-mini');

// Generate text
const result = await backend.generateText({
  messages: [
    { role: 'user', content: 'Hello, how are you?' }
  ]
});

console.log(result.text);
```

## Supported Providers

| Provider | Package | Model Examples |
|----------|---------|----------------|
| OpenAI | `@ai-sdk/openai` | gpt-4o, gpt-4o-mini, o1 |
| Anthropic | `@ai-sdk/anthropic` | claude-3-5-sonnet, claude-3-haiku |
| Google | `@ai-sdk/google` | gemini-2.0-flash, gemini-1.5-pro |
| Groq | `@ai-sdk/groq` | llama-3.3-70b, mixtral-8x7b |
| Mistral | `@ai-sdk/mistral` | mistral-large, codestral |
| Cohere | `@ai-sdk/cohere` | command-r-plus, command-r |
| DeepSeek | `@ai-sdk/deepseek` | deepseek-chat, deepseek-coder |
| xAI | `@ai-sdk/xai` | grok-2, grok-2-mini |

## Model String Format

Use `provider/model` format:

```typescript
// OpenAI
createAISDKBackend('openai/gpt-4o-mini');

// Anthropic
createAISDKBackend('anthropic/claude-3-5-sonnet-latest');

// Google
createAISDKBackend('google/gemini-2.0-flash');

// With alias
createAISDKBackend('claude/claude-3-haiku-20240307'); // claude â†’ anthropic
```

## Streaming

```typescript
const backend = createAISDKBackend('openai/gpt-4o-mini');

const stream = await backend.streamText({
  messages: [{ role: 'user', content: 'Write a poem' }]
});

for await (const chunk of stream) {
  if (chunk.text) {
    process.stdout.write(chunk.text);
  }
}
```

## Tool Calling

AI SDK requires Zod schemas for tools:

```typescript
import { generateText, tool } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const tools = {
  get_weather: tool({
    description: 'Get weather for a city',
    inputSchema: z.object({
      city: z.string().describe('City name'),
    }),
    execute: async ({ city }) => {
      return { city, temperature: 22, condition: 'sunny' };
    },
  }),
};

const result = await generateText({
  model: openai('gpt-4o-mini'),
  messages: [{ role: 'user', content: 'Weather in Paris?' }],
  tools,
});

console.log(result.toolCalls);
```

## Structured Output

Generate typed JSON objects:

```typescript
import { generateObject } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const schema = z.object({
  name: z.string(),
  age: z.number(),
  city: z.string(),
});

const result = await generateObject({
  model: openai('gpt-4o-mini'),
  schema,
  prompt: 'Generate a fictional person profile.',
});

console.log(result.object); // { name: 'Alice', age: 28, city: 'Paris' }
```

## Multi-Agent Attribution

Track requests across agents with attribution context:

```typescript
const backend = createAISDKBackend('openai/gpt-4o-mini', {
  attribution: {
    agentId: 'agent-research',
    runId: 'run-abc123',
    traceId: 'trace-xyz789',
    sessionId: 'session-user1',
  },
});

// Headers are automatically injected:
// X-Agent-Id: agent-research
// X-Run-Id: run-abc123
// X-Trace-Id: trace-xyz789
// X-Session-Id: session-user1
```

## Configuration Options

```typescript
const backend = createAISDKBackend('openai/gpt-4o-mini', {
  // Timeout in milliseconds (default: 60000)
  timeout: 30000,
  
  // Max retries on transient errors (default: 2)
  maxRetries: 3,
  
  // Max output tokens (default: 4096)
  maxOutputTokens: 2048,
  
  // Attribution context
  attribution: {
    agentId: 'my-agent',
    runId: 'run-123',
  },
  
  // Telemetry settings
  telemetry: {
    isEnabled: true,
    functionId: 'my-function',
  },
});
```

## Error Handling

```typescript
import { AISDKError } from 'praisonai';

try {
  const result = await backend.generateText({
    messages: [{ role: 'user', content: 'Hello' }]
  });
} catch (error) {
  if (error instanceof AISDKError) {
    console.error(`Error code: ${error.code}`);
    console.error(`Retryable: ${error.isRetryable}`);
    
    switch (error.code) {
      case 'AUTHENTICATION':
        console.error('Check your API key');
        break;
      case 'RATE_LIMIT':
        console.error('Rate limited, will retry');
        break;
      case 'TIMEOUT':
        console.error('Request timed out');
        break;
    }
  }
}
```

## Environment Variables

Set API keys via environment variables:

```bash
export OPENAI_API_KEY=sk-...
export ANTHROPIC_API_KEY=sk-ant-...
export GOOGLE_API_KEY=AIza...
export GROQ_API_KEY=gsk_...
```

## Examples

See complete examples in the repository:

- [Basic Chat](/docs/js/ai-sdk-cli#basic-usage) - Simple text generation
- [Streaming](/docs/js/ai-sdk-cli#streaming) - Real-time streaming output
- [Tool Calling](https://github.com/MervinPraison/PraisonAI/tree/main/src/praisonai-ts/examples/ai-sdk/tool-calling.ts) - Function calling with tools
- [Multi-Provider](https://github.com/MervinPraison/PraisonAI/tree/main/src/praisonai-ts/examples/ai-sdk/multi-provider.ts) - Using multiple providers
- [Structured Output](https://github.com/MervinPraison/PraisonAI/tree/main/src/praisonai-ts/examples/ai-sdk/structured-output.ts) - JSON schema output
- [Multi-Agent](https://github.com/MervinPraison/PraisonAI/tree/main/src/praisonai-ts/examples/ai-sdk/multi-agent.ts) - Attribution context

## Next Steps

- [AI SDK CLI Commands](/docs/js/ai-sdk-cli) - CLI interface for AI SDK
- [Provider Registry](/docs/js/provider-registry) - Managing LLM providers
- [Streaming](/docs/js/streaming) - Advanced streaming patterns
