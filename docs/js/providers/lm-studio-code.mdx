---
title: "LM Studio Provider"
description: "Use LM Studio local models with PraisonAI TypeScript"
icon: "desktop"
---

# LM Studio Provider

Run models locally with LM Studio.

## Environment Variables

```bash
export LM_STUDIO_BASE_URL=http://localhost:1234/v1
```

## Quick Start

```typescript
import { Agent } from 'praisonai';

const agent = new Agent({
  name: 'LMStudioAgent',
  instructions: 'You are a helpful assistant.',
  llm: 'lm-studio/local-model',
  llmConfig: {
    baseUrl: 'http://localhost:1234/v1'
  }
});

const response = await agent.chat('Hello!');
```

## Related

- [LM Studio CLI Usage](/docs/js/providers/lm-studio-cli)
- [Local Providers](/docs/js/local-providers)
