---
title: "Embedding"
description: "Generate text embeddings for semantic search and similarity"
icon: "vector-square"
---

# Embedding Module

Generate text embeddings with a simple API. Abstracts away the underlying provider (litellm) - users only need `praisonai.embedding()`.

## Quick Start

```python
import praisonai

# Single text
emb = praisonai.embedding("Hello world")
print(len(emb))  # 1536 dimensions
```

## Installation

```bash
pip install praisonai[llm]
```

<Note>
The `[llm]` extra is required for embedding support. It includes litellm for multi-provider compatibility.
</Note>

## Usage Examples

### Single Text

```python
import praisonai

embedding = praisonai.embedding("Hello world")
# Returns: List[float] with 1536 dimensions
```

### Multiple Texts

```python
import praisonai

embeddings = praisonai.embedding(["Hello", "World", "PraisonAI"])
# Returns: List[List[float]] - one vector per text
```

### Custom Model

```python
import praisonai

# Use larger model for higher quality
embedding = praisonai.embedding(
    "Hello world",
    model="text-embedding-3-large"
)
```

### Alternative Import

```python
from praisonai.llm import embedding

emb = embedding("Hello world")
```

## API Reference

### `praisonai.embedding(text, model, **kwargs)`

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `text` | `str` or `List[str]` | Required | Text(s) to embed |
| `model` | `str` | `"text-embedding-3-small"` | Embedding model name |
| `**kwargs` | `dict` | `{}` | Additional arguments passed to litellm |

**Returns:**
- `List[float]` for single text input
- `List[List[float]]` for list input

## Supported Providers

Any provider supported by [litellm embeddings](https://docs.litellm.ai/docs/embedding/supported_embedding):

| Provider | Model Example |
|----------|---------------|
| OpenAI | `text-embedding-3-small`, `text-embedding-3-large` |
| Azure | `azure/text-embedding-ada-002` |
| Cohere | `embed-english-v3.0` |
| Voyage | `voyage-02` |
| Google | `gemini/text-embedding-004` |
| Bedrock | `amazon.titan-embed-text-v1` |

## Use Cases

### Semantic Search

```python
import praisonai

# Index documents
docs = ["AI agents are autonomous", "Machine learning is a subset of AI"]
doc_embeddings = praisonai.embedding(docs)

# Search query
query_emb = praisonai.embedding("What are AI agents?")

# Calculate similarity (cosine)
import numpy as np
similarities = [np.dot(query_emb, doc) for doc in doc_embeddings]
```

### Duplicate Detection

```python
import praisonai

def cosine_similarity(a, b):
    return sum(x*y for x, y in zip(a, b)) / (
        sum(x**2 for x in a)**0.5 * sum(y**2 for y in b)**0.5
    )

text1 = "PraisonAI is an agent framework"
text2 = "PraisonAI provides AI agents"

emb1 = praisonai.embedding(text1)
emb2 = praisonai.embedding(text2)

similarity = cosine_similarity(emb1, emb2)
print(f"Similarity: {similarity:.2%}")  # ~85%
```

### RAG Pipeline

```python
import praisonai

# Store embeddings for retrieval
documents = ["Doc 1 content", "Doc 2 content", "Doc 3 content"]
embeddings = praisonai.embedding(documents)

# Query time
query = "Find relevant docs"
query_emb = praisonai.embedding(query)

# Retrieve top-k similar documents
# ... use with vector store
```

## Performance

| Aspect | Value |
|--------|-------|
| Import overhead | 0ms (lazy loaded) |
| First call | ~200ms (loads litellm) |
| Subsequent calls | <100ms |
| Batch efficiency | âœ… Single API call for lists |

<Tip>
**Performance Tip:** Pass lists to `embedding()` instead of calling it in a loop. This batches requests into a single API call.
</Tip>

## Error Handling

```python
import praisonai

try:
    emb = praisonai.embedding("Hello")
except ImportError:
    print("Install with: pip install praisonai[llm]")
except Exception as e:
    print(f"API error: {e}")
```

## Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | Required for OpenAI models |
| `AZURE_API_KEY` | For Azure OpenAI |
| `COHERE_API_KEY` | For Cohere models |
| `GOOGLE_API_KEY` | For Gemini models |

## Related

- [Vector Store Module](/docs/sdk/praisonai/vector_store) - Store and query embeddings
- [Knowledge Module](/docs/sdk/praisonai/knowledge) - RAG with embeddings
- [Memory Module](/docs/sdk/praisonaiagents/memory/memory) - Agent memory with embeddings
