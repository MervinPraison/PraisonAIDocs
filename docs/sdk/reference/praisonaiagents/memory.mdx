---
title: "Memory Module"
description: "API reference for memory"
icon: "brain"
---

# memory



## Import

```python
from praisonaiagents import memory
```

## Classes

### Memory

A single-file memory manager covering:
- Short-term memory (STM) for ephemeral context
- Long-term memory (LTM) for persistent knowledge
- Entity memory (structured data about named entities)
- User memory (preferences/history for each user)
- Quality score logic for deciding which data to store in LTM
- Context building from multiple memory sources
- Graph memory support for complex relationship storage (via Mem0)

Config example:
{
  "provider": "rag" or "mem0" or "mongodb" or "none",
  "use_embedding": True,
  "short_db": "short_term.db",
  "long_db": "long_term.db",
  "rag_db_path": "rag_db",   # optional path for local embedding store
  "config": {
    "api_key": "...",       # if mem0 usage
    "org_id": "...",
    "project_id": "...",
    
    # MongoDB configuration (if provider is "mongodb")
    "connection_string": "mongodb://localhost:27017/" or "mongodb+srv://user:pass@cluster.mongodb.net/",
    "database": "praisonai",
    "use_vector_search": True,  # Enable Atlas Vector Search
    "max_pool_size": 50,
    "min_pool_size": 10,
    "max_idle_time": 30000,
    "server_selection_timeout": 5000,
    
    # Graph memory configuration (optional)
    "graph_store": {
      "provider": "neo4j" or "memgraph",
      "config": {
        "url": "neo4j+s://xxx" or "bolt://localhost:7687",
        "username": "neo4j" or "memgraph",
        "password": "xxx"
      }
    },
    
    # Optional additional configurations for graph memory
    "vector_store": {
      "provider": "qdrant",
      "config": {"host": "localhost", "port": 6333}
    },
    "llm": {
      "provider": "openai",
      "config": {"model": "gpt-4o-mini", "api_key": "..."}
    },
    "embedder": {
      "provider": "openai",
      "config": {"model": "text-embedding-3-small", "api_key": "..."}
    }
  }
}

Note: Graph memory requires "mem0ai[graph]" installation and works alongside 
vector-based memory for enhanced relationship-aware retrieval.

#### Constructor Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `config` | `Dict[str, Any]` |  |
| `verbose` | `int` |  |

#### Methods

- **compute_quality_score**(`completeness: float, relevance: float, clarity: float, accuracy: float, weights: Dict[str, float]`) → `float`
  Combine multiple sub-metrics into one final score, as an example.

Args:
    completeness (float): 0
- **store_short_term**(`text: str, metadata: Dict[str, Any], completeness: float, relevance: float, clarity: float, accuracy: float, weights: Dict[str, float], evaluator_quality: float`) → `Any`
  Store in short-term memory with optional quality metrics
- **search_short_term**(`query: str, limit: int, min_quality: float, relevance_cutoff: float, rerank: bool`) → `List[Dict[str, Any]]`
  Search short-term memory with optional quality filter
- **reset_short_term**(``) → `Any`
  Completely clears short-term memory.
- **store_long_term**(`text: str, metadata: Dict[str, Any], completeness: float, relevance: float, clarity: float, accuracy: float, weights: Dict[str, float], evaluator_quality: float`) → `Any`
  Store in long-term memory with optional quality metrics
- **search_long_term**(`query: str, limit: int, relevance_cutoff: float, min_quality: float, rerank: bool`) → `List[Dict[str, Any]]`
  Search long-term memory with optional quality filter
- **reset_long_term**(``) → `Any`
  Clear local LTM DB, plus Chroma, MongoDB, or mem0 if in use.
- **delete_short_term**(`memory_id: str`) → `bool`
  Delete a specific short-term memory by ID.

Args:
    memory_id: The unique ID of the memory to dele
- **delete_long_term**(`memory_id: str`) → `bool`
  Delete a specific long-term memory by ID.

Works across all backends: SQLite, ChromaDB, Mem0, and Mo
- **delete_memory**(`memory_id: str, memory_type: Optional[str]`) → `bool`
  Delete a specific memory by ID.

This is the unified deletion method that searches across all memory
- **delete_memories**(`memory_ids: List[str]`) → `int`
  Delete multiple memories by their IDs.

Args:
    memory_ids: List of memory IDs to delete
    
Retu
- **delete_memories_matching**(`query: str, memory_type: Optional[str], limit: int`) → `int`
  Delete memories matching a search query.

Useful for bulk cleanup of related memories, e.g., all ima
- **store_entity**(`name: str, type_: str, desc: str, relations: str`) → `Any`
  Save entity info in LTM (or mem0/rag). 
We'll label the metadata type = entity for easy filtering.
- **search_entity**(`query: str, limit: int`) → `List[Dict[str, Any]]`
  Filter to items that have metadata 'category=entity'.
- **reset_entity_only**(``) → `Any`
  If you only want to drop entity items from LTM, you'd do a custom 
delete from local DB where meta L
- **store_user_memory**(`user_id: str, text: str, extra: Dict[str, Any]`) → `Any`
  If mem0 is used, do user-based addition. Otherwise store in LTM with user in metadata.
- **search_user_memory**(`user_id: str, query: str, limit: int, rerank: bool`) → `List[Dict[str, Any]]`
  If mem0 is used, pass user_id in. Otherwise fallback to local filter on user in metadata.
- **search**(`query: str, user_id: Optional[str], agent_id: Optional[str], run_id: Optional[str], limit: int, rerank: bool`) → `List[Dict[str, Any]]`
  Generic search method that delegates to appropriate specific search methods.
Provides compatibility 
- **reset_user_memory**(``) → `Any`
  Clear all user-based info. For simplicity, we do a full LTM reset. 
Real usage might filter only met
- **finalize_task_output**(`content: str, agent_name: str, quality_score: float, threshold: float, metrics: Dict[str, Any], task_id: str`) → `Any`
  Store task output in memory with appropriate metadata
- **build_context_for_task**(`task_descr: str, user_id: Optional[str], additional: str, max_items: int, include_in_output: Optional[bool]`) → `str`
  Merges relevant short-term, long-term, entity, user memories
into a single text block with deduplica
- **reset_all**(``) → `Any`
  Fully wipes short-term, long-term, and any memory in mem0 or rag.
- **calculate_quality_metrics**(`output: str, expected_output: str, llm: Optional[str], custom_prompt: Optional[str]`) → `Dict[str, float]`
  Calculate quality metrics using LLM
- **store_quality**(`text: str, quality_score: float, task_id: Optional[str], iteration: Optional[int], metrics: Optional[Dict[str, float]], memory_type: Literal['short', 'long']`) → `None`
  Store quality metrics in memory
- **search_with_quality**(`query: str, min_quality: float, memory_type: Literal['short', 'long'], limit: int`) → `List[Dict[str, Any]]`
  Search with quality filter
- **get_all_memories**(``) → `List[Dict[str, Any]]`
  Get all memories from both short-term and long-term storage
- **learn**(``) → `Any`
  Get the LearnManager for continuous learning capabilities.

Returns None if learn is not enabled in 
- **get_learn_context**(``) → `str`
  Get learning context suitable for injection into system prompt.

Returns empty string if learn is no

## Functions

### trace()



```python
def trace(self: Any, message: Any) -> Any
```
