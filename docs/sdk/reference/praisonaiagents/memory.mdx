---
title: "memory"
description: "API reference for memory"
icon: "brain"
---

# memory

<Badge color="blue">Core SDK</Badge>

## Overview

```mermaid
graph TD
    Module["memory"]:::agent
    classDef agent fill:#8B0000,stroke:#8B0000,color:#fff
    Memory["Memory"]:::tool
    classDef tool fill:#189AB4,stroke:#189AB4,color:#fff
    Module --> Memory
```

## Import

```python
from praisonaiagents import memory
```

## Classes

### Memory

A single-file memory manager covering:
- Short-term memory (STM) for ephemeral context
- Long-term memory (LTM) for persistent knowledge
- Entity memory (structured data about named entities)
- User memory (preferences/history for each user)
- Quality score logic for deciding which data to store in LTM
- Context building from multiple memory sources
- Graph memory support for complex relationship storage (via Mem0)

Config example:
&#123;
  "provider": "rag" or "mem0" or "mongodb" or "none",
  "use_embedding": True,
  "short_db": "short_term.db",
  "long_db": "long_term.db",
  "rag_db_path": "rag_db",   # optional path for local embedding store
  "config": &#123;
    "api_key": "...",       # if mem0 usage
    "org_id": "...",
    "project_id": "...",
    
    # MongoDB configuration (if provider is "mongodb")
    "connection_string": "mongodb://localhost:27017/" or "mongodb+srv://user:pass@cluster.mongodb.net/",
    "database": "praisonai",
    "use_vector_search": True,  # Enable Atlas Vector Search
    "max_pool_size": 50,
    "min_pool_size": 10,
    "max_idle_time": 30000,
    "server_selection_timeout": 5000,
    
    # Graph memory configuration (optional)
    "graph_store": &#123;
      "provider": "neo4j" or "memgraph",
      "config": &#123;
        "url": "neo4j+s://xxx" or "bolt://localhost:7687",
        "username": "neo4j" or "memgraph",
        "password": "xxx"
      &#125;
    &#125;,
    
    # Optional additional configurations for graph memory
    "vector_store": &#123;
      "provider": "qdrant",
      "config": &#123;"host": "localhost", "port": 6333&#125;
    &#125;,
    "llm": &#123;
      "provider": "openai",
      "config": &#123;"model": "gpt-4o-mini", "api_key": "..."&#125;
    &#125;,
    "embedder": &#123;
      "provider": "openai",
      "config": &#123;"model": "text-embedding-3-small", "api_key": "..."&#125;
    &#125;
  &#125;
&#125;

Note: Graph memory requires "mem0ai[graph]" installation and works alongside 
vector-based memory for enhanced relationship-aware retrieval.

<Expandable title="Constructor Parameters">

<ParamField query="config" type="Dict">
   (Required)
</ParamField>
<ParamField query="verbose" type="int">
   (default: `0`)
</ParamField>

</Expandable>

#### Methods

##### compute_quality_score(completeness: float, relevance: float, clarity: float, accuracy: float, weights: Dict) -> float

Combine multiple sub-metrics into one final score, as an example.

Args:
    completeness (float): 0-1
    relevance (float): 0-1
    clarity (float): 0-1
    accuracy (float): 0-1
    weights (Dict[str, float]): optional weighting like &#123;"completeness": 0.25, "relevance": 0.3, ...&#125;

Returns:
    float: Weighted average 0-1

---
##### store_short_term(text: str, metadata: Dict) -> Any

Store in short-term memory with optional quality metrics

---
##### search_short_term(query: str, limit: int, min_quality: float, relevance_cutoff: float, rerank: bool) -> List

Search short-term memory with optional quality filter

---
##### reset_short_term() -> Any

Completely clears short-term memory.

---
##### store_long_term(text: str, metadata: Dict) -> Any

Store in long-term memory with optional quality metrics

---
##### search_long_term(query: str, limit: int, relevance_cutoff: float, min_quality: float, rerank: bool) -> List

Search long-term memory with optional quality filter

---
##### reset_long_term() -> Any

Clear local LTM DB, plus Chroma, MongoDB, or mem0 if in use.

---
##### delete_short_term(memory_id: str) -> bool

Delete a specific short-term memory by ID.

Args:
    memory_id: The unique ID of the memory to delete
    
Returns:
    True if memory was found and deleted, False otherwise

---
##### delete_long_term(memory_id: str) -> bool

Delete a specific long-term memory by ID.

Works across all backends: SQLite, ChromaDB, Mem0, and MongoDB.

Args:
    memory_id: The unique ID of the memory to delete
    
Returns:
    True if memory was found and deleted, False otherwise

---
##### delete_memory(memory_id: str, memory_type: Optional) -> bool

Delete a specific memory by ID.

This is the unified deletion method that searches across all memory types
and all backends (SQLite, ChromaDB, Mem0, MongoDB).

Particularly useful for:
- Cleaning up image-based memories after processing to free context window
- Removing outdated or incorrect information
- Privacy compliance (selective erasure)

Args:
    memory_id: The unique ID of the memory to delete
    memory_type: Optional type hint to narrow search:
                'short_term', 'long_term'
                If None, searches all types.
    
Returns:
    True if memory was found and deleted, False otherwise

Example:
    # Delete a specific image analysis memory
    memory.delete_memory("1705123456789")
    
    # Delete with type hint for faster lookup
    memory.delete_memory("1705123456789", memory_type="short_term")

---
##### delete_memories(memory_ids: List) -> int

Delete multiple memories by their IDs.

Args:
    memory_ids: List of memory IDs to delete
    
Returns:
    Number of memories successfully deleted

---
##### delete_memories_matching(query: str, memory_type: Optional) -> int

Delete memories matching a search query.

Useful for bulk cleanup of related memories, e.g., all image-related
context after finishing an image analysis session.

Args:
    query: Search query to match memories
    memory_type: Optional type ('short_term' or 'long_term')
    limit: Maximum number of memories to delete
    
Returns:
    Number of memories deleted

---
##### store_entity(name: str, type_: str, desc: str, relations: str) -> Any

Save entity info in LTM (or mem0/rag). 
We'll label the metadata type = entity for easy filtering.

---
##### search_entity(query: str, limit: int) -> List

Filter to items that have metadata 'category=entity'.

---
##### reset_entity_only() -> Any

If you only want to drop entity items from LTM, you'd do a custom 
delete from local DB where meta LIKE '%category=entity%'. 
For brevity, we do a full LTM reset here.

---
##### store_user_memory(user_id: str, text: str, extra: Dict) -> Any

If mem0 is used, do user-based addition. Otherwise store in LTM with user in metadata.

---
##### search_user_memory(user_id: str, query: str, limit: int, rerank: bool) -> List

If mem0 is used, pass user_id in. Otherwise fallback to local filter on user in metadata.

---
##### search(query: str, user_id: Optional) -> List

Generic search method that delegates to appropriate specific search methods.
Provides compatibility with mem0.Memory interface.

Args:
    query: The search query string
    user_id: Optional user ID for user-specific search
    agent_id: Optional agent ID for agent-specific search  
    run_id: Optional run ID for run-specific search
    limit: Maximum number of results to return
    rerank: Whether to use advanced reranking
    **kwargs: Additional search parameters
    
Returns:
    List of search results

---
##### reset_user_memory() -> Any

Clear all user-based info. For simplicity, we do a full LTM reset. 
Real usage might filter only metadata "user_id".

---
##### finalize_task_output(content: str, agent_name: str, quality_score: float, threshold: float, metrics: Dict) -> Any

Store task output in memory with appropriate metadata

---
##### build_context_for_task(task_descr: str, user_id: Optional) -> str

Merges relevant short-term, long-term, entity, user memories
into a single text block with deduplication and clean formatting.

Args:
    include_in_output: If None, memory content is only included when debug logging is enabled.
                       If True, memory content is always included.
                       If False, memory content is never included (only logged for debugging).

---
##### reset_all() -> Any

Fully wipes short-term, long-term, and any memory in mem0 or rag.

---
##### calculate_quality_metrics(output: str, expected_output: str, llm: Optional) -> Dict

Calculate quality metrics using LLM

---
##### store_quality(text: str, quality_score: float, task_id: Optional) -> None

Store quality metrics in memory

---
##### search_with_quality(query: str, min_quality: float, memory_type: Literal) -> List

Search with quality filter

---
##### get_all_memories() -> List

Get all memories from both short-term and long-term storage

---
##### learn() -> Any

Get the LearnManager for continuous learning capabilities.

Returns None if learn is not enabled in config.

Usage:
    memory = Memory(&#123;"learn": True&#125;)
    memory.learn.capture_persona("User prefers concise responses")
    memory.learn.capture_insight("User works in data science")

---
##### get_learn_context() -> str

Get learning context suitable for injection into system prompt.

Returns empty string if learn is not enabled.

---


## Functions

### trace()

```python
def trace(message: Any) -> Any
```

<Expandable title="Parameters">

<ParamField query="message" type="Any">
</ParamField>

</Expandable>

