---
title: "ocr_agent"
description: "OCRAgent - A specialized agent class for OCR (Optical Character Recognition)."
icon: "scan"
---

# ocr_agent

<Badge color="blue">Core SDK</Badge>

## Overview

```mermaid
graph TD
    Agent["Agent"]:::agent
    classDef agent fill:#8B0000,stroke:#8B0000,color:#fff
```

OCRAgent - A specialized agent class for OCR (Optical Character Recognition).
Extracts text from documents and images using AI models.

Follows the Agent() class patterns:
- Precedence Ladder: Instance &gt; Config &gt; Array &gt; Dict &gt; String &gt; Bool &gt; Default
- Lazy imports for LiteLLM (zero overhead until first use)
- Async-safe with both sync and async methods

## Import

```python
from praisonaiagents import ocr_agent
```

## Classes

### OCRConfig

Configuration for OCR settings.

<Expandable title="Properties">

<ResponseField name="include_image_base64" type="bool">
</ResponseField>
<ResponseField name="pages" type="Optional">
</ResponseField>
<ResponseField name="image_limit" type="Optional">
</ResponseField>
<ResponseField name="timeout" type="int">
</ResponseField>
<ResponseField name="api_base" type="Optional">
</ResponseField>
<ResponseField name="api_key" type="Optional">
</ResponseField>

</Expandable>

#### Methods

##### to_dict() -> Dict

Convert to dictionary for LiteLLM calls.

---

### OCRAgent

A specialized agent for OCR (Optical Character Recognition).

Extracts text from documents (PDFs) and images using AI models.

Supported Providers:
    - Mistral: `mistral/mistral-ocr-latest`

Example:
    ```python
    from praisonaiagents import OCRAgent
    
    agent = OCRAgent(llm="mistral/mistral-ocr-latest")
    
    # Extract from PDF URL
    result = agent.extract("https://example.com/document.pdf")
    print(result.text)
    
    # Extract from image URL
    result = agent.extract("https://example.com/image.png")
    for page in result.pages:
        print(page.markdown)
    ```

<Expandable title="Constructor Parameters">

<ParamField query="name" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="instructions" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="llm" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="model" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="base_url" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="api_key" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="ocr" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="verbose" type="Union">
   (default: `True`)
</ParamField>

</Expandable>

#### Methods

##### console() -> Any

Lazily initialize Rich Console.

---
##### litellm() -> Any

Lazy load litellm module when needed.

---
##### extract(source: str, include_image_base64: Optional) -> Any

Extract text from a document or image.

Args:
    source: URL or path to document/image
    include_image_base64: Include base64 images in response
    pages: Specific pages to extract (for PDFs)
    image_limit: Maximum images per page
    model: Override model for this call
    **kwargs: Additional parameters
    
Returns:
    OCRResponse with pages, markdown content, and metadata
    
Example:
    ```python
    agent = OCRAgent(llm="mistral/mistral-ocr-latest")
    result = agent.extract("https://arxiv.org/pdf/2201.04234")
    for page in result.pages:
        print(f"Page {page.index}: {page.markdown}")
    ```

---
##### async aextract(source: str, include_image_base64: Optional) -> Any

Async version of extract().

---
##### read(source: str) -> str

Quick OCR - extract and return markdown text.

Args:
    source: URL or path to document/image
    
Returns:
    Extracted text as markdown string

---
##### async aread(source: str) -> str

Async version of read().

---

