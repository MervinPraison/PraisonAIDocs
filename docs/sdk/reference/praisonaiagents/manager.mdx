---
title: "Manager Module"
description: "Context Manager Facade for PraisonAI Agents.

Provides a unified interface for context management:
- Budgeting and allocation
- Token estimation with "
icon: "code"
---

# manager

Context Manager Facade for PraisonAI Agents.

Provides a unified interface for context management:
- Budgeting and allocation
- Token estimation with validation
- Composition within limits
- Optimization with benefit checking
- Monitoring with snapshot hooks
- Multi-agent orchestration support
- Optimization history tracking

This is the main entry point for context management in both SDK and CLI.

## Import

```python
from praisonaiagents import manager
```

## Classes

### SessionDeduplicationCache

Thread-safe session-level content deduplication cache.

Tracks content hashes across all agents in a workflow session
to prevent duplicate content from being sent to LLM.

#### Constructor Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `max_size` | `int` |  |

#### Methods

- **check_and_add**(`content_hash: str, agent_name: str, tokens: int`) → `bool`
  Check if content hash exists and add if new.

Args:
    content_hash: Hash of the content
    agent_
- **get_stats**(``) → `Dict[str, int]`
  Get deduplication statistics.
- **clear**(``) → `None`
  Clear the cache.

### EstimationMode

Token estimation modes.

### ContextShareMode

How context is shared between agents.

### ToolShareMode

How tools are shared between agents.

### OptimizationEventType

Types of optimization events.

### ContextPolicy

Policy for context sharing during agent handoffs.

Controls how context is passed between agents in multi-agent scenarios.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`

### OptimizationEvent

Record of an optimization event.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`

### EstimationMetrics

Metrics for token estimation accuracy.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`

### PerToolBudget

Per-tool token budget configuration.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`

### SnapshotHookData

Data captured at LLM call boundary for exact snapshot.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`

### ManagerConfig

Complete configuration for ContextManager.

Consolidates all context management settings with proper precedence.

#### Methods

- **to_dict**(``) → `Dict[str, Any]`
- **from_env**(``) → `ManagerConfig`
  Load config from environment variables.
- **merge**(``) → `ManagerConfig`
  Create new config with overrides applied.

### ContextManager

Unified facade for context management.

Orchestrates budgeting, composition, optimization, and monitoring.
Provides hooks for exact LLM boundary snapshots.
Tracks optimization history for debugging.

Example:
    manager = ContextManager(model="gpt-4o")
    
    # Process messages before LLM call
    result = manager.process(
        messages=messages,
        system_prompt=system_prompt,
        tools=tools,
    )
    
    # Get optimized messages
    optimized_messages = result["messages"]
    
    # Check if optimization occurred
    if result["optimized"]:
        print(f"Saved {result['tokens_saved']} tokens")

#### Constructor Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `model` | `str` |  |
| `config` | `Optional[ManagerConfig]` |  |
| `session_id` | `str` |  |
| `agent_name` | `str` |  |
| `session_cache` | `Optional[SessionDeduplicationCache]` |  |
| `llm_summarize_fn` | `Optional[Callable]` |  |

#### Methods

- **process**(`messages: List[Dict[str, Any]], system_prompt: str, tools: Optional[List[Dict[str, Any]]], trigger: Literal['turn', 'tool_call', 'manual', 'overflow']`) → `Dict[str, Any]`
  Process messages through the context pipeline.

Applies budgeting, optimization, and monitoring.

Ar
- **capture_llm_boundary**(`messages: List[Dict[str, Any]], tools: List[Dict[str, Any]]`) → `SnapshotHookData`
  Capture exact state at LLM call boundary.

Call this immediately before sending to LLM to get exact 
- **register_snapshot_callback**(`callback: Callable[[SnapshotHookData], None]`) → `None`
  Register a callback for LLM boundary snapshots.
- **get_last_snapshot_hook**(``) → `Optional[SnapshotHookData]`
  Get the last LLM boundary snapshot.
- **estimate_tokens**(`text: str, validate: bool`) → `Tuple[int, Optional[EstimationMetrics]]`
  Estimate tokens with optional validation.

Args:
    text: Text to estimate
    validate: Whether to
- **get_tool_budget**(`tool_name: str`) → `int`
  Get token budget for a specific tool.
- **set_tool_budget**(`tool_name: str, max_tokens: int, protected: bool`) → `None`
  Set token budget for a specific tool.
- **truncate_tool_output**(`tool_name: str, output: str`) → `str`
  Truncate tool output according to its budget.
- **get_history**(``) → `List[Dict[str, Any]]`
  Get optimization history.
- **get_stats**(``) → `Dict[str, Any]`
  Get current context statistics.
- **emergency_truncate**(`messages: List[Dict[str, Any]], target_tokens: int`) → `List[Dict[str, Any]]`
  Emergency truncation when optimization isn't enough.

Aggressively removes messages to fit within ta
- **get_resolved_config**(``) → `Dict[str, Any]`
  Get the fully resolved configuration with source info.
- **reset**(``) → `None`
  Reset manager state.

### MultiAgentContextManager

Context manager for multi-agent orchestration.

Provides per-agent isolation with controlled sharing policies.

#### Constructor Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `config` | `Optional[ManagerConfig]` |  |
| `default_policy` | `Optional[ContextPolicy]` |  |
| `session_cache` | `Optional[SessionDeduplicationCache]` |  |

#### Methods

- **get_agent_manager**(`agent_id: str, model: str`) → `ContextManager`
  Get or create context manager for an agent.
- **get_session_cache**(``) → `SessionDeduplicationCache`
  Get the session deduplication cache.
- **set_agent_policy**(`agent_id: str, policy: ContextPolicy`) → `None`
  Set context policy for an agent.
- **get_agent_policy**(`agent_id: str`) → `ContextPolicy`
  Get context policy for an agent.
- **prepare_handoff**(`from_agent: str, to_agent: str, messages: List[Dict[str, Any]], policy: Optional[ContextPolicy]`) → `List[Dict[str, Any]]`
  Prepare context for handoff between agents.

Args:
    from_agent: Source agent ID
    to_agent: Tar
- **get_combined_stats**(``) → `Dict[str, Any]`
  Get combined statistics across all agents.

## Functions

### deduplicate_topics()

Programmatic deduplication of topics/items before agent processing.

This helps prevent duplicate content from being passed to downstream agents,
reducing token waste and improving quality.

Args:
    topics: List of topic dicts or strings
    key: Key to use for comparison if topics are dicts (default: "title")
    similarity_threshold: Similarity threshold for fuzzy matching (0.0-1.0)
    
Returns:
    Deduplicated list of topics

```python
def deduplicate_topics(topics: list, key: str, similarity_threshold: float) -> list
```

### create_context_manager()

Create a context manager with proper config precedence.

Precedence: CLI > ENV > config_file > defaults

Args:
    model: Model name
    session_id: Session ID
    agent_name: Agent name
    config_file: Path to config.yaml
    cli_overrides: CLI argument overrides
    
Returns:
    Configured ContextManager

```python
def create_context_manager(model: str, session_id: str, agent_name: str, config_file: Optional[str], cli_overrides: Optional[Dict[str, Any]]) -> ContextManager
```
