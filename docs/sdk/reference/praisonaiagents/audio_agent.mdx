---
title: "audio_agent"
description: "AudioAgent - A specialized agent class for audio processing using AI models."
icon: "mic"
---

# audio_agent

<Badge color="blue">Core SDK</Badge>

## Overview

```mermaid
graph TD
    Agent["Agent"]:::agent
    classDef agent fill:#8B0000,stroke:#8B0000,color:#fff
```

AudioAgent - A specialized agent class for audio processing using AI models.
Provides Text-to-Speech (TTS) and Speech-to-Text (STT/Transcription) capabilities.

Follows the Agent() class patterns:
- Precedence Ladder: Instance &gt; Config &gt; Array &gt; Dict &gt; String &gt; Bool &gt; Default
- Lazy imports for LiteLLM (zero overhead until first use)
- Async-safe with both sync and async methods

## Import

```python
from praisonaiagents import audio_agent
```

## Classes

<AccordionGroup>
### AudioConfig

Configuration for audio processing settings.

Follows the Precedence Ladder pattern:
- Instance &gt; Config &gt; Array &gt; Dict &gt; String &gt; Bool &gt; Default

<Expandable title="Properties">

<ResponseField name="voice" type="Optional">
</ResponseField>
<ResponseField name="speed" type="float">
</ResponseField>
<ResponseField name="response_format" type="str">
</ResponseField>
<ResponseField name="language" type="Optional">
</ResponseField>
<ResponseField name="temperature" type="float">
</ResponseField>
<ResponseField name="timeout" type="int">
</ResponseField>
<ResponseField name="api_base" type="Optional">
</ResponseField>
<ResponseField name="api_key" type="Optional">
</ResponseField>

</Expandable>

<AccordionGroup>
<Accordion title="to_dict() -> Dict">
  Convert to dictionary for LiteLLM calls.
</Accordion>
</AccordionGroup>

### AudioAgent

A specialized agent for audio processing using AI models.

Provides:
- Text-to-Speech (TTS): Convert text to spoken audio
- Speech-to-Text (STT): Transcribe audio to text

TTS Providers:
    - OpenAI: `openai/tts-1`, `openai/tts-1-hd`
    - Azure: `azure/tts-1`
    - Gemini: `gemini/gemini-2.5-flash-preview-tts`
    - Vertex AI: `vertex_ai/gemini-2.5-flash-preview-tts`
    - ElevenLabs: `elevenlabs/eleven_multilingual_v2`
    - MiniMax: `minimax/speech-01`

STT Providers:
    - OpenAI: `openai/whisper-1`
    - Azure: `azure/whisper`
    - Groq: `groq/whisper-large-v3`
    - Deepgram: `deepgram/nova-2`
    - Gemini: `gemini/gemini-2.0-flash`

Example:
    ```python
    from praisonaiagents import AudioAgent
    
    # Text-to-Speech
    agent = AudioAgent(llm="openai/tts-1")
    agent.speech("Hello world!", output="hello.mp3")
    
    # Speech-to-Text
    agent = AudioAgent(llm="openai/whisper-1")
    text = agent.transcribe("audio.mp3")
    print(text)
    ```

<Expandable title="Constructor Parameters">

<ParamField query="name" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="instructions" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="llm" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="model" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="base_url" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="api_key" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="audio" type="Optional">
   (default: `None`)
</ParamField>
<ParamField query="verbose" type="Union">
   (default: `True`)
</ParamField>

</Expandable>

<AccordionGroup>
<Accordion title="console() -> Any">
  Lazily initialize Rich Console.
</Accordion>
<Accordion title="litellm() -> Any">
  Lazy load litellm module when needed.
</Accordion>
<Accordion title="speech(text: str, output: Optional) -> Any">
  Convert text to speech.

Args:
    text: Text to convert to speech
    output: Path to save audio file (optional)
    voice: Voice to use (e.g., "alloy", "echo", "fable")
    speed: Speech speed (0.25 to 4.0)
    response_format: Audio format (mp3, opus, aac, flac, wav)
    model: Override model for this call
    **kwargs: Additional provider-specific parameters
    
Returns:
    Audio response object with stream_to_file() method
    
Example:
    ```python
    agent = AudioAgent(llm="openai/tts-1")
    agent.speech("Hello world!", output="hello.mp3")
    ```
</Accordion>
<Accordion title="async aspeech(text: str, output: Optional) -> Any">
  Async version of speech().
</Accordion>
<Accordion title="transcribe(file: Union) -> str">
  Transcribe audio to text.

Args:
    file: Path to audio file or file-like object
    language: Language code (e.g., "en", "es", "fr")
    temperature: Sampling temperature (0.0 to 1.0)
    model: Override model for this call
    **kwargs: Additional provider-specific parameters
    
Returns:
    Transcribed text
    
Example:
    ```python
    agent = AudioAgent(llm="openai/whisper-1")
    text = agent.transcribe("audio.mp3")
    print(text)
    ```
</Accordion>
<Accordion title="async atranscribe(file: Union) -> str">
  Async version of transcribe().
</Accordion>
<Accordion title="say(text: str, output: str) -> str">
  Quick TTS - convert text and save to file.

Args:
    text: Text to speak
    output: Output filename (default: output.mp3)
    
Returns:
    Path to saved file
</Accordion>
<Accordion title="async asay(text: str, output: str) -> str">
  Async version of say().
</Accordion>
<Accordion title="listen(file: Union) -> str">
  Quick STT - transcribe audio file.

Args:
    file: Audio file to transcribe
    
Returns:
    Transcribed text
</Accordion>
<Accordion title="async alisten(file: Union) -> str">
  Async version of listen().
</Accordion>
</AccordionGroup>

</AccordionGroup>
