---
title: "Embed Module"
description: "Core embedding functions.

This module provides the main embedding() and aembedding() functions
that wrap LiteLLM's embedding API with a consistent in"
icon: "code"
---

# embed

Core embedding functions.

This module provides the main embedding() and aembedding() functions
that wrap LiteLLM's embedding API with a consistent interface.

## Import

```python
from praisonaiagents import embed
```

## Functions

### embedding()

Generate embeddings for text using LiteLLM.

This is the primary embedding function that supports all LiteLLM
embedding providers (OpenAI, Azure, Cohere, Voyage, etc.).

Args:
    input: Text or list of texts to embed
    model: Model name (e.g., "text-embedding-3-small", "text-embedding-3-large")
    dimensions: Optional output dimensions (for models that support it)
    encoding_format: "float" or "base64"
    timeout: Request timeout in seconds
    api_key: Optional API key override
    api_base: Optional API base URL override
    metadata: Optional metadata for tracing
    **kwargs: Additional arguments passed to litellm.embedding()
    
Returns:
    EmbeddingResult with embeddings list, model, usage, and metadata
    
Example:
    >>> from praisonaiagents import embedding
    >>> result = embedding("Hello, world!")
    >>> print(len(result.embeddings[0]))
    1536
    
    >>> result = embedding(["Hello", "World"], model="text-embedding-3-large")
    >>> print(len(result.embeddings))
    2

```python
def embedding(input: Union[str, List[str]], model: str, dimensions: Optional[int], encoding_format: str, timeout: float, api_key: Optional[str], api_base: Optional[str], metadata: Optional[Dict[str, Any]]) -> EmbeddingResult
```
