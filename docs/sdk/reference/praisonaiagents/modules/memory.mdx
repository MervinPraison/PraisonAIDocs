---
title: "memory"
description: "Module reference for memory"
icon: "brain"
---

# praisonaiagents.memory.memory

<Badge color="blue">Core SDK</Badge>



## Overview
This module provides components for memory.

## Classes

**[Dedicated Page: Memory](../classes/Memory)**

### Memory

A single-file memory manager covering:
- Short-term memory (STM) for ephemeral context
- Long-term memory (LTM) for persistent knowledge
- Entity memory (structured data about named entities)
- User memory (preferences/history for each user)
- Quality score logic for deciding which data to store in LTM
- Context building from multiple memory sources
- Graph memory support for complex relationship storage (via Mem0)

Config example:
&#123;
  "provider": "rag" or "mem0" or "mongodb" or "none",
  "use_embedding": True,
  "short_db": "short_term.db",
  "long_db": "long_term.db",
  "rag_db_path": "rag_db",   # optional path for local embedding store
  "config": &#123;
    "api_key": "...",       # if mem0 usage
    "org_id": "...",
    "project_id": "...",
    
    # MongoDB configuration (if provider is "mongodb")
    "connection_string": "mongodb://localhost:27017/" or "mongodb+srv://user:pass@cluster.mongodb.net/",
    "database": "praisonai",
    "use_vector_search": True,  # Enable Atlas Vector Search
    "max_pool_size": 50,
    "min_pool_size": 10,
    "max_idle_time": 30000,
    "server_selection_timeout": 5000,
    
    # Graph memory configuration (optional)
    "graph_store": &#123;
      "provider": "neo4j" or "memgraph",
      "config": &#123;
        "url": "neo4j+s://xxx" or "bolt://localhost:7687",
        "username": "neo4j" or "memgraph",
        "password": "xxx"
      &#125;
    &#125;,
    
    # Optional additional configurations for graph memory
    "vector_store": &#123;
      "provider": "qdrant",
      "config": &#123;"host": "localhost", "port": 6333&#125;
    &#125;,
    "llm": &#123;
      "provider": "openai",
      "config": &#123;"model": "gpt-4o-mini", "api_key": "..."&#125;
    &#125;,
    "embedder": &#123;
      "provider": "openai",
      "config": &#123;"model": "text-embedding-3-small", "api_key": "..."&#125;
    &#125;
  &#125;
&#125;

Note: Graph memory requires "mem0ai[graph]" installation and works alongside 
vector-based memory for enhanced relationship-aware retrieval.

<Accordion title="Constructor Parameters">

| Parameter | Type | Required | Default |
|-----------|------|----------|---------|
| `config` | `Dict` | Yes | `-` |
| `verbose` | `int` | No | `0` |
</Accordion>

<Accordion title="Methods">
- **compute_quality_score**(`completeness: float, relevance: float, clarity: float, accuracy: float, weights: Dict`) → `float`
  Combine multiple sub-metrics into one final score, as an example.
- **store_short_term**(`text: str, metadata: Dict`) → `Any`
  Store in short-term memory with optional quality metrics
- **search_short_term**(`query: str, limit: int, min_quality: float, relevance_cutoff: float, rerank: bool`) → `List`
  Search short-term memory with optional quality filter
- **reset_short_term**(``) → `Any`
  Completely clears short-term memory.
- **store_long_term**(`text: str, metadata: Dict`) → `Any`
  Store in long-term memory with optional quality metrics
- **search_long_term**(`query: str, limit: int, relevance_cutoff: float, min_quality: float, rerank: bool`) → `List`
  Search long-term memory with optional quality filter
- **reset_long_term**(``) → `Any`
  Clear local LTM DB, plus Chroma, MongoDB, or mem0 if in use.
- **delete_short_term**(`memory_id: str`) → `bool`
  Delete a specific short-term memory by ID.
- **delete_long_term**(`memory_id: str`) → `bool`
  Delete a specific long-term memory by ID.

Works across all backends: SQLite, Ch
- **delete_memory**(`memory_id: str, memory_type: Optional`) → `bool`
  Delete a specific memory by ID.

This is the unified deletion method that search
- **delete_memories**(`memory_ids: List`) → `int`
  Delete multiple memories by their IDs.
- **delete_memories_matching**(`query: str, memory_type: Optional`) → `int`
  Delete memories matching a search query.

Useful for bulk cleanup of related mem
- **store_entity**(`name: str, type_: str, desc: str, relations: str`) → `Any`
  Save entity info in LTM (or mem0/rag). 
We'll label the metadata type = entity f
- **search_entity**(`query: str, limit: int`) → `List`
  Filter to items that have metadata 'category=entity'.
- **reset_entity_only**(``) → `Any`
  If you only want to drop entity items from LTM, you'd do a custom 
delete from l
- **store_user_memory**(`user_id: str, text: str, extra: Dict`) → `Any`
  If mem0 is used, do user-based addition. Otherwise store in LTM with user in met
- **search_user_memory**(`user_id: str, query: str, limit: int, rerank: bool`) → `List`
  If mem0 is used, pass user_id in. Otherwise fallback to local filter on user in 
- **search**(`query: str, user_id: Optional`) → `List`
  Generic search method that delegates to appropriate specific search methods.
Pro
- **reset_user_memory**(``) → `Any`
  Clear all user-based info. For simplicity, we do a full LTM reset. 
Real usage m
- **finalize_task_output**(`content: str, agent_name: str, quality_score: float, threshold: float, metrics: Dict`) → `Any`
  Store task output in memory with appropriate metadata
- **build_context_for_task**(`task_descr: str, user_id: Optional`) → `str`
  Merges relevant short-term, long-term, entity, user memories
into a single text 
- **reset_all**(``) → `Any`
  Fully wipes short-term, long-term, and any memory in mem0 or rag.
- **calculate_quality_metrics**(`output: str, expected_output: str, llm: Optional`) → `Dict`
  Calculate quality metrics using LLM
- **store_quality**(`text: str, quality_score: float, task_id: Optional`) → `None`
  Store quality metrics in memory
- **search_with_quality**(`query: str, min_quality: float, memory_type: Literal`) → `List`
  Search with quality filter
- **get_all_memories**(``) → `List`
  Get all memories from both short-term and long-term storage
- **learn**(``) → `Any`
  Get the LearnManager for continuous learning capabilities.

Returns None if lear
- **get_learn_context**(``) → `str`
  Get learning context suitable for injection into system prompt.

Returns empty s
</Accordion>


## Functions

**[Dedicated Page: trace()](../functions/trace)**

### trace()

```python
def trace(message: Any) -> Any
```

<Expandable title="Parameters">
- **message** (`Any`)
</Expandable>


## Constants

| Name | Value |
|------|-------|
| `TRACE_LEVEL` | `5` |
