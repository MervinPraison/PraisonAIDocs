---
title: "audio_agent"
description: "AudioAgent - A specialized agent class for audio processing using AI models."
icon: "microphone"
---

# praisonaiagents.agent.audio_agent

<Badge color="blue">Core SDK</Badge>

AudioAgent - A specialized agent class for audio processing using AI models.
Provides Text-to-Speech (TTS) and Speech-to-Text (STT/Transcription) capabilities.

Follows the Agent() class patterns:
- Precedence Ladder: Instance &gt; Config &gt; Array &gt; Dict &gt; String &gt; Bool &gt; Default
- Lazy imports for LiteLLM (zero overhead until first use)
- Async-safe with both sync and async methods

## Overview
This module provides components for audio_agent.

## Classes

**[Dedicated Page: AudioConfig](../classes/AudioConfig)**

### AudioConfig

Configuration for audio processing settings.

Follows the Precedence Ladder pattern:
- Instance &gt; Config &gt; Array &gt; Dict &gt; String &gt; Bool &gt; Default

<Accordion title="Properties">

| Property | Type |
|----------|------|
| `voice` | `Optional` |
| `speed` | `float` |
| `response_format` | `str` |
| `language` | `Optional` |
| `temperature` | `float` |
| `timeout` | `int` |
| `api_base` | `Optional` |
| `api_key` | `Optional` |
</Accordion>

<Accordion title="Methods">
- **to_dict**(``) → `Dict`
  Convert to dictionary for LiteLLM calls.
</Accordion>


**[Dedicated Page: AudioAgent](../classes/AudioAgent)**

### AudioAgent

A specialized agent for audio processing using AI models.

Provides:
- Text-to-Speech (TTS): Convert text to spoken audio
- Speech-to-Text (STT): Transcribe audio to text

TTS Providers:
    - OpenAI: `openai/tts-1`, `openai/tts-1-hd`
    - Azure: `azure/tts-1`
    - Gemini: `gemini/gemini-2.5-flash-preview-tts`
    - Vertex AI: `vertex_ai/gemini-2.5-flash-preview-tts`
    - ElevenLabs: `elevenlabs/eleven_multilingual_v2`
    - MiniMax: `minimax/speech-01`

STT Providers:
    - OpenAI: `openai/whisper-1`
    - Azure: `azure/whisper`
    - Groq: `groq/whisper-large-v3`
    - Deepgram: `deepgram/nova-2`
    - Gemini: `gemini/gemini-2.0-flash`

Example:
    ```python
    from praisonaiagents import AudioAgent
    
    # Text-to-Speech
    agent = AudioAgent(llm="openai/tts-1")
    agent.speech("Hello world!", output="hello.mp3")
    
    # Speech-to-Text
    agent = AudioAgent(llm="openai/whisper-1")
    text = agent.transcribe("audio.mp3")
    print(text)
    ```

<Accordion title="Constructor Parameters">

| Parameter | Type | Required | Default |
|-----------|------|----------|---------|
| `name` | `Optional` | No | `None` |
| `instructions` | `Optional` | No | `None` |
| `llm` | `Optional` | No | `None` |
| `model` | `Optional` | No | `None` |
| `base_url` | `Optional` | No | `None` |
| `api_key` | `Optional` | No | `None` |
| `audio` | `Optional` | No | `None` |
| `verbose` | `Union` | No | `True` |
</Accordion>

<Accordion title="Methods">
- **console**(``) → `Any`
  Lazily initialize Rich Console.
- **litellm**(``) → `Any`
  Lazy load litellm module when needed.
- **speech**(`text: str, output: Optional`) → `Any`
  Convert text to speech.

Args:
    text: Text to convert to speech
    output: P
- **async aspeech**(`text: str, output: Optional`) → `Any`
  Async version of speech().
- **transcribe**(`file: Union`) → `str`
  Transcribe audio to text.

Args:
    file: Path to audio file or file-like objec
- **async atranscribe**(`file: Union`) → `str`
  Async version of transcribe().
- **say**(`text: str, output: str`) → `str`
  Quick TTS - convert text and save to file.

Args:
    text: Text to speak
    ou
- **async asay**(`text: str, output: str`) → `str`
  Async version of say().
- **listen**(`file: Union`) → `str`
  Quick STT - transcribe audio file.

Args:
    file: Audio file to transcribe
   
- **async alisten**(`file: Union`) → `str`
  Async version of listen().
</Accordion>

