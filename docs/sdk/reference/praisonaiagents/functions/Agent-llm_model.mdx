---
title: "LLM Model â€¢ AI Agent SDK"
sidebarTitle: "LLM Model"
description: "llm_model: Unified property to get the LLM model regardless of configuration type."
icon: "function"
---

# llm_model

<div className="flex items-center gap-2">
  <Badge color="purple">Method</Badge>
</div>

> This is a method of the [**Agent**](../classes/Agent) class in the [**agent**](../modules/agent) module.

Unified property to get the LLM model regardless of configuration type.

## Signature

```python
def llm_model() -> Any
```

### Returns

<ResponseField name="Returns" type="Any">
  returns the model string (e.g., "gpt-4o-mini")
    - For custom LLM instances: returns the LLM instance object
    - For provider models: returns the LLM instance object
</ResponseField>


## Source

<Card title="View on GitHub" icon="github" href="https://github.com/MervinPraison/PraisonAI/blob/main/src/praisonai-agents/praisonaiagents/agent/agent.py#L2892">
  `praisonaiagents/agent/agent.py` at line 2892
</Card>



---

## Related Documentation

<CardGroup cols={2}>
  <Card title="Models Overview" icon="microchip" href="/docs/models" />
  <Card title="LLM Configuration" icon="gear" href="/docs/configuration/llm-config" />
  <Card title="Model Router" icon="route" href="/docs/features/model-router" />
  <Card title="Model Failover" icon="shield" href="/docs/features/model-failover" />
</CardGroup>
