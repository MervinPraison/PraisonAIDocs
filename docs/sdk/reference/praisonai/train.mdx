---
title: "train"
description: "This script finetunes a model using Unsloth's fast training framework."
icon: "dumbbell"
---

# train

<Badge color="purple">Wrapper</Badge>

## Overview

```mermaid
graph TD
    Module["train"]:::agent
    classDef agent fill:#8B0000,stroke:#8B0000,color:#fff
    TrainModel["TrainModel"]:::tool
    classDef tool fill:#189AB4,stroke:#189AB4,color:#fff
    Module --> TrainModel
```

This script finetunes a model using Unsloth's fast training framework.
It supports both ShareGPT and Alpaca‑style datasets by converting raw conversation
data into plain-text prompts using a chat template, then pre‑tokenizing the prompts.
Extra debug logging is added to help trace the root cause of errors.

## Import

```python
from praisonai import train
```

## Classes

<AccordionGroup>
### TrainModel

<Expandable title="Constructor Parameters">

<ParamField query="config_path" type="Any">
   (default: `'config.yaml'`)
</ParamField>

</Expandable>

<AccordionGroup>
<Accordion title="load_config(path: Any) -> Any">
</Accordion>
<Accordion title="print_system_info() -> Any">
</Accordion>
<Accordion title="check_gpu() -> Any">
</Accordion>
<Accordion title="check_ram() -> Any">
</Accordion>
<Accordion title="prepare_model() -> Any">
</Accordion>
<Accordion title="process_dataset(dataset_info: Any) -> Any">
</Accordion>
<Accordion title="tokenize_dataset(dataset: Any) -> Any">
</Accordion>
<Accordion title="load_datasets() -> Any">
</Accordion>
<Accordion title="train_model() -> Any">
</Accordion>
<Accordion title="inference(instruction: Any, input_text: Any) -> Any">
</Accordion>
<Accordion title="load_model() -> Any">
</Accordion>
<Accordion title="save_model_merged() -> Any">
</Accordion>
<Accordion title="push_model_gguf() -> Any">
</Accordion>
<Accordion title="save_model_gguf() -> Any">
</Accordion>
<Accordion title="prepare_modelfile_content() -> Any">
</Accordion>
<Accordion title="create_and_push_ollama_model() -> Any">
</Accordion>
<Accordion title="run() -> Any">
</Accordion>
</AccordionGroup>

</AccordionGroup>

## Functions

<AccordionGroup>
### formatting_prompts_func()

Converts each example's conversation into a single plain-text prompt.
If the example has a "conversations" field, process it as ShareGPT-style.
Otherwise, assume Alpaca-style data with "instruction", "input", and "output" fields.

```python
def formatting_prompts_func(examples: Any, tokenizer: Any) -> Any
```

<Expandable title="Parameters">

<ParamField query="examples" type="Any">
</ParamField>
<ParamField query="tokenizer" type="Any">
</ParamField>

</Expandable>

### tokenize_function()

Tokenizes a batch of text prompts with padding and truncation enabled.

```python
def tokenize_function(examples: Any, hf_tokenizer: Any, max_length: Any) -> Any
```

<Expandable title="Parameters">

<ParamField query="examples" type="Any">
</ParamField>
<ParamField query="hf_tokenizer" type="Any">
</ParamField>
<ParamField query="max_length" type="Any">
</ParamField>

</Expandable>

### main()

```python
def main() -> Any
```

</AccordionGroup>
