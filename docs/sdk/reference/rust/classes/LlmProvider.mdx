---
title: "LLM Provider â€¢ Rust AI Agent SDK"
sidebarTitle: "LLM Provider"
description: "LlmProvider: Trait for LLM providers"
icon: "brackets-curly"
---

# LlmProvider

> Defined in the [**LLM Providers**](../modules/llm) module.

<Badge color="orange">Rust AI Agent SDK</Badge>

Trait for LLM providers

## Methods

### `chat`

```rust
async fn chat(
        &self,
        messages: &[Message],
        tools: Option<&[ToolDefinition]>,
    ) -> Result<LlmResponse>
```

Send a chat completion request

**Parameters:**

| Name | Type |
|------|------|
| `messages` | `&[Message]` |
| `tools` | `Option&lt;&[ToolDefinition]&gt;` |

### `chat_stream`

```rust
async fn chat_stream(
        &self,
        messages: &[Message],
        tools: Option<&[ToolDefinition]>,
    ) -> Result<Box<dyn futures::Stream<Item = Result<String>> + Send + Unpin>>
```

Stream a chat completion (returns chunks)

**Parameters:**

| Name | Type |
|------|------|
| `messages` | `&[Message]` |
| `tools` | `Option&lt;&[ToolDefinition]&gt;` |

### `model`

```rust
fn model(&self) -> &str
```

Get the model name

