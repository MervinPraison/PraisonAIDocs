---
title: "LLM Protocol â€¢ Rust AI Agent SDK"
sidebarTitle: "LLM Protocol"
description: "LlmProtocol: Protocol for LLM provider implementations."
icon: "brackets-curly"
---

# LlmProtocol

> Defined in the [**protocols**](../modules/protocols) module.

<Badge color="orange">Rust AI Agent SDK</Badge>

Protocol for LLM provider implementations.

## Methods

### `model`

```rust
fn model(&self) -> &str
```

Get the model name

### `chat`

```rust
async fn chat(&self, messages: &[LlmMessage]) -> Result<LlmResponse>
```

Chat with the LLM

**Parameters:**

| Name | Type |
|------|------|
| `messages` | `&[LlmMessage]` |

### `chat_with_tools`

```rust
async fn chat_with_tools(
        &self,
        messages: &[LlmMessage],
        tools: &[ToolSchema],
    ) -> Result<LlmResponse>
```

Chat with tools

**Parameters:**

| Name | Type |
|------|------|
| `messages` | `&[LlmMessage]` |
| `tools` | `&[ToolSchema]` |


## Source

<Card title="View on GitHub" icon="github" href="https://github.com/ARC-Solutions/praisonai-rust/blob/main/praisonai/src/protocols/mod.rs">
  `praisonai/src/protocols/mod.rs` at line 0
</Card>



---

## Related Documentation

<CardGroup cols={2}>
  <Card title="Models Overview" icon="microchip" href="/docs/models" />
  <Card title="LLM Configuration" icon="gear" href="/docs/configuration/llm-config" />
  <Card title="Model Router" icon="route" href="/docs/features/model-router" />
  <Card title="Model Failover" icon="shield" href="/docs/features/model-failover" />
</CardGroup>
