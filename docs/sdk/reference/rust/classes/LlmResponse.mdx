---
title: "LLM Response â€¢ Rust AI Agent SDK"
sidebarTitle: "LLM Response"
description: "LlmResponse: An LLM response."
icon: "brackets-curly"
---

# LlmResponse

> Defined in the [**protocols**](../modules/protocols) module.

<Badge color="orange">Rust AI Agent SDK</Badge>

An LLM response.

## Fields

| Name | Type | Description |
|------|------|-------------|
| `content` | `String` | Response content |
| `tool_calls` | `Vec&lt;ToolCall&gt;` | Tool calls if any |
| `usage` | `Option&lt;TokenUsage&gt;` | Token usage |


## Source

<Card title="View on GitHub" icon="github" href="https://github.com/MervinPraison/PraisonAI/blob/main/src/praisonai-rust/praisonai/src/protocols/mod.rs#L199">
  `praisonai/src/protocols/mod.rs` at line 199
</Card>



---

## Related Documentation

<CardGroup cols={2}>
  <Card title="Rust LLM Providers" icon="microchip" href="/docs/rust/llm-providers" />
</CardGroup>
