---
title: "Chat Stream â€¢ Rust AI Agent SDK"
sidebarTitle: "Chat Stream"
description: "chat_stream: Stream a chat completion (returns chunks)"
icon: "function"
---

# chat_stream

<div className="flex items-center gap-2">
  <Badge color="blue">Async</Badge>
  <Badge color="purple">Method</Badge>
</div>

> This is a method of the [**LlmProvider**](../classes/LlmProvider) class in the [**llm**](../modules/llm) module.

Stream a chat completion (returns chunks)

## Signature

```python
async def chat_stream(
        &self,
        messages: &[Message],
        tools: Option<&[ToolDefinition]>,
    ) -> Result<Box<dyn futures::Stream<Item = Result<String>> + Send + Unpin>>
```

## Parameters

<ParamField query="messages" type="&" required={true}>
  No description available.
</ParamField>

<ParamField query="tools" type="Option&lt;&" required={true}>
  No description available.
</ParamField>

### Returns

<ResponseField name="Returns" type="Result<Box<dyn futures::Stream<Item = Result<String>> + Send + Unpin>>">
  The result of the operation.
</ResponseField>



---

## Related Documentation

<CardGroup cols={2}>
  <Card title="Chat Feature" icon="comments" href="/docs/features/chat" />
  <Card title="Conversation Stores" icon="database" href="/docs/databases/overview" />
</CardGroup>
