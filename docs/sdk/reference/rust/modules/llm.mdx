---
title: "LLM â€¢ Rust AI Agent SDK"
sidebarTitle: "LLM"
description: "LLM Provider abstraction for PraisonAI"
icon: "microchip"
---

# llm

<Badge color="orange">Rust AI Agent SDK</Badge>

LLM Provider abstraction for PraisonAI

This module provides the LLM provider trait and implementations.
Uses rig-core for multi-provider support (OpenAI, Anthropic, Ollama, etc.)

## Import

```rust
use praisonai::llm::*;
```

## Classes

<CardGroup cols={2}>
  <Card title="Message" icon="brackets-curly" href="../classes/Message">
    A message in a conversation
  </Card>
  <Card title="ToolCallFunction" icon="brackets-curly" href="../classes/ToolCallFunction">
    Function details within a tool call
  </Card>
  <Card title="ToolCall" icon="brackets-curly" href="../classes/ToolCall">
    A tool call made by the LLM
  </Card>
  <Card title="LlmResponse" icon="brackets-curly" href="../classes/LlmResponse">
    LLM response
  </Card>
  <Card title="Usage" icon="brackets-curly" href="../classes/Usage">
    Token usage statistics
  </Card>
  <Card title="LlmConfig" icon="brackets-curly" href="../classes/LlmConfig">
    LLM configuration
  </Card>
  <Card title="OpenAiProvider" icon="brackets-curly" href="../classes/OpenAiProvider">
    OpenAI-compatible LLM provider
  </Card>
  <Card title="MockLlmProvider" icon="brackets-curly" href="../classes/MockLlmProvider">
    Mock LLM provider for testing (no API calls)
  </Card>
  <Card title="LlmProvider" icon="brackets-curly" href="../classes/LlmProvider">
    Trait for LLM providers
  </Card>
  <Card title="Role" icon="brackets-curly" href="../classes/Role">
    Message role in a conversation
  </Card>
</CardGroup>



---

## Related Documentation

<CardGroup cols={2}>
  <Card title="Rust LLM" icon="microchip" href="/docs/rust/llm" />
  <Card title="Rust Providers" icon="server" href="/docs/rust/providers" />
  <Card title="Rust Failover" icon="shield" href="/docs/rust/failover" />
</CardGroup>
