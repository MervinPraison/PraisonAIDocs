---
title: "llm"
description: "LLM Provider abstraction for PraisonAI  This module provides the LLM provider trait and implementations. Uses rig-core for multi-provider support (Ope"
icon: "microchip"
---

# praisonai.llm

<Badge color="orange">Rust SDK</Badge>

LLM Provider abstraction for PraisonAI

This module provides the LLM provider trait and implementations.
Uses rig-core for multi-provider support (OpenAI, Anthropic, Ollama, etc.)

## Import

```rust
use praisonai::llm::*;
```

## Types

<CardGroup cols={2}>
  <Card title="Message" icon="brackets-curly" href="../classes/Message">
    A message in a conversation
  </Card>
  <Card title="ToolCall" icon="brackets-curly" href="../classes/ToolCall">
    A tool call made by the LLM
  </Card>
  <Card title="LlmResponse" icon="brackets-curly" href="../classes/LlmResponse">
    LLM response
  </Card>
  <Card title="Usage" icon="brackets-curly" href="../classes/Usage">
    Token usage statistics
  </Card>
  <Card title="LlmConfig" icon="brackets-curly" href="../classes/LlmConfig">
    LLM configuration
  </Card>
  <Card title="OpenAiProvider" icon="brackets-curly" href="../classes/OpenAiProvider">
    OpenAI-compatible LLM provider
  </Card>
  <Card title="LlmProvider" icon="brackets-curly" href="../classes/LlmProvider">
    Trait for LLM providers
  </Card>
  <Card title="Role" icon="brackets-curly" href="../classes/Role">
    Message role in a conversation
  </Card>
</CardGroup>

