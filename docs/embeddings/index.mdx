---
title: "Embedding Providers"
description: "Generate text embeddings using 35+ providers through PraisonAI"
icon: "vector-square"
---

## Overview

PraisonAI supports **35+ embedding providers** through LiteLLM integration, giving you access to hundreds of embedding models with a unified API.

## Quick Start

```python
from praisonaiagents import embedding

# OpenAI (default)
result = embedding("Hello world", model="text-embedding-3-small")

# Cohere
result = embedding("Hello world", model="cohere/embed-english-v3.0")

# Voyage AI
result = embedding("Hello world", model="voyage/voyage-3")

# Azure OpenAI
result = embedding("Hello world", model="azure/text-embedding-ada-002")

print(f"Dimensions: {len(result.embeddings[0])}")
```

## CLI Usage

```bash
# OpenAI
praisonai embed "Hello world" --model text-embedding-3-small

# Cohere
praisonai embed "Hello world" --model cohere/embed-english-v3.0

# Any provider
praisonai embedding "Hello world" --model voyage/voyage-3
```

## Supported Providers

### Tier 1: Major Cloud Providers

| Provider | Prefix | Example Model | Docs |
|----------|--------|---------------|------|
| [OpenAI](/docs/embeddings/providers/openai) | `openai/` or none | `text-embedding-3-small` | [→](/docs/embeddings/providers/openai) |
| [Azure OpenAI](/docs/embeddings/providers/azure) | `azure/` | `azure/text-embedding-ada-002` | [→](/docs/embeddings/providers/azure) |
| [Google Vertex AI](/docs/embeddings/providers/vertex-ai) | `vertex_ai/` | `vertex_ai/textembedding-gecko` | [→](/docs/embeddings/providers/vertex-ai) |
| [Google Gemini](/docs/embeddings/providers/gemini) | `gemini/` | `gemini/text-embedding-004` | [→](/docs/embeddings/providers/gemini) |
| [AWS Bedrock](/docs/embeddings/providers/bedrock) | `bedrock/` | `bedrock/amazon.titan-embed-text-v1` | [→](/docs/embeddings/providers/bedrock) |
| [Azure AI](/docs/embeddings/providers/azure-ai) | `azure_ai/` | `azure_ai/Cohere-embed-v3-english` | [→](/docs/embeddings/providers/azure-ai) |

### Tier 2: Specialized Embedding Providers

| Provider | Prefix | Example Model | Docs |
|----------|--------|---------------|------|
| [Cohere](/docs/embeddings/providers/cohere) | `cohere/` | `cohere/embed-english-v3.0` | [→](/docs/embeddings/providers/cohere) |
| [Voyage AI](/docs/embeddings/providers/voyage) | `voyage/` | `voyage/voyage-3` | [→](/docs/embeddings/providers/voyage) |
| [Jina AI](/docs/embeddings/providers/jina-ai) | `jina_ai/` | `jina_ai/jina-embeddings-v3` | [→](/docs/embeddings/providers/jina-ai) |
| [Mistral](/docs/embeddings/providers/mistral) | `mistral/` | `mistral/mistral-embed` | [→](/docs/embeddings/providers/mistral) |

### Tier 3: Open Source & Self-Hosted

| Provider | Prefix | Example Model | Docs |
|----------|--------|---------------|------|
| [HuggingFace](/docs/embeddings/providers/huggingface) | `huggingface/` | `huggingface/BAAI/bge-large-en-v1.5` | [→](/docs/embeddings/providers/huggingface) |
| [Ollama](/docs/embeddings/providers/ollama) | `ollama/` | `ollama/nomic-embed-text` | [→](/docs/embeddings/providers/ollama) |
| [Infinity](/docs/embeddings/providers/infinity) | `infinity/` | `infinity/BAAI/bge-small-en-v1.5` | [→](/docs/embeddings/providers/infinity) |
| [vLLM](/docs/embeddings/providers/vllm) | `hosted_vllm/` | `hosted_vllm/intfloat/e5-mistral-7b-instruct` | [→](/docs/embeddings/providers/vllm) |
| [LM Studio](/docs/embeddings/providers/lm-studio) | `lm_studio/` | `lm_studio/nomic-embed-text` | [→](/docs/embeddings/providers/lm-studio) |

### Tier 4: Additional Providers

| Provider | Prefix | Example Model | Docs |
|----------|--------|---------------|------|
| [Together AI](/docs/embeddings/providers/together-ai) | `together_ai/` | `together_ai/togethercomputer/m2-bert-80M-8k-retrieval` | [→](/docs/embeddings/providers/together-ai) |
| [Fireworks AI](/docs/embeddings/providers/fireworks-ai) | `fireworks_ai/` | `fireworks_ai/nomic-ai/nomic-embed-text-v1.5` | [→](/docs/embeddings/providers/fireworks-ai) |
| [NVIDIA NIM](/docs/embeddings/providers/nvidia-nim) | `nvidia_nim/` | `nvidia_nim/NV-Embed-QA` | [→](/docs/embeddings/providers/nvidia-nim) |
| [Databricks](/docs/embeddings/providers/databricks) | `databricks/` | `databricks/databricks-bge-large-en` | [→](/docs/embeddings/providers/databricks) |
| [Snowflake](/docs/embeddings/providers/snowflake) | `snowflake/` | `snowflake/snowflake-arctic-embed-m` | [→](/docs/embeddings/providers/snowflake) |
| [Watsonx](/docs/embeddings/providers/watsonx) | `watsonx/` | `watsonx/ibm/slate-125m-english-rtrvr` | [→](/docs/embeddings/providers/watsonx) |
| [SambaNova](/docs/embeddings/providers/sambanova) | `sambanova/` | `sambanova/E5-mistral-7b-instruct` | [→](/docs/embeddings/providers/sambanova) |
| [Nebius](/docs/embeddings/providers/nebius) | `nebius/` | `nebius/BAAI/bge-en-icl` | [→](/docs/embeddings/providers/nebius) |
| [OVHcloud](/docs/embeddings/providers/ovhcloud) | `ovhcloud/` | `ovhcloud/multilingual-e5-base` | [→](/docs/embeddings/providers/ovhcloud) |
| [Volcengine](/docs/embeddings/providers/volcengine) | `volcengine/` | `volcengine/doubao-embedding` | [→](/docs/embeddings/providers/volcengine) |

## Model Selection Guide

### By Use Case

| Use Case | Recommended Model | Dimensions |
|----------|-------------------|------------|
| **General Purpose** | `text-embedding-3-small` | 1536 |
| **High Quality** | `text-embedding-3-large` | 3072 |
| **Multilingual** | `cohere/embed-multilingual-v3.0` | 1024 |
| **Code Search** | `voyage/voyage-code-3` | 1024 |
| **Cost Effective** | `cohere/embed-english-light-v3.0` | 384 |
| **Self-Hosted** | `ollama/nomic-embed-text` | 768 |

### By Dimension Size

| Dimensions | Models |
|------------|--------|
| **256-512** | `cohere/embed-english-light-v3.0`, `jina_ai/jina-embeddings-v2-small-en` |
| **768-1024** | `cohere/embed-english-v3.0`, `voyage/voyage-3`, `mistral/mistral-embed` |
| **1536** | `text-embedding-3-small`, `azure/text-embedding-ada-002` |
| **3072** | `text-embedding-3-large` |

## Environment Variables

Each provider requires specific environment variables:

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."

# Azure OpenAI
export AZURE_API_KEY="..."
export AZURE_API_BASE="https://your-resource.openai.azure.com"

# Cohere
export COHERE_API_KEY="..."

# Voyage AI
export VOYAGE_API_KEY="..."

# Google
export GOOGLE_API_KEY="..."  # or GEMINI_API_KEY

# AWS Bedrock
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."
export AWS_REGION_NAME="us-east-1"
```

## API Reference

### Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `input` | str or List[str] | Required | Text(s) to embed |
| `model` | str | `text-embedding-3-small` | Model identifier with optional provider prefix |
| `dimensions` | int | None | Output dimensions (if supported) |
| `encoding_format` | str | `float` | `float` or `base64` |
| `timeout` | float | 600.0 | Request timeout in seconds |
| `api_key` | str | None | API key override |
| `api_base` | str | None | API base URL override |

### Response

```python
EmbeddingResult(
    embeddings=[[0.1, 0.2, ...]],  # List of embedding vectors
    model="text-embedding-3-small",
    usage={"prompt_tokens": 4, "total_tokens": 4}
)
```

## Related

- [Embeddings API](/docs/capabilities/embeddings) - Core embeddings documentation
- [Embeddings CLI](/docs/capabilities/embeddings-cli) - CLI commands
- [Vector Stores](/docs/databases/overview) - Store and query embeddings
