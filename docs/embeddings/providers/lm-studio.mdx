---
title: "LM Studio Embeddings"
description: "Generate embeddings using locally-hosted LM Studio"
icon: "desktop"
---

## Overview

LM Studio provides a user-friendly interface for running embedding models locally.

## Quick Start

```python
from praisonaiagents import embedding

result = embedding(
    input="Hello world",
    model="lm_studio/nomic-embed-text",
    api_base="http://localhost:1234/v1"
)
print(f"Dimensions: {len(result.embeddings[0])}")
```

## CLI Usage

```bash
praisonai embed "Hello world" --model lm_studio/nomic-embed-text
```

## Setup

1. Download and install LM Studio from https://lmstudio.ai
2. Load an embedding model
3. Start the local server

```bash
export LM_STUDIO_API_BASE="http://localhost:1234/v1"
```

## Related

- [Embedding Providers Overview](/docs/embeddings/index)
- [Ollama Embeddings](/docs/embeddings/providers/ollama)
