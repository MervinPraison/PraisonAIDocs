---
title: "Memory Module"
description: "Documentation for the praisonaiagents.memory module - Multi-tiered memory system with quality scoring"
icon: "memory"
---

# Module praisonaiagents.memory

The memory module provides a sophisticated multi-tiered memory system with short-term, long-term, entity, and user-specific memory capabilities, including graph database support and quality scoring.

## Classes

### MemoryClient
The main class for managing agent memory with multiple storage tiers and quality-based filtering.

#### Parameters
- `config: Optional[Dict[str, Any]] = None` - Memory configuration including provider and storage settings
- `verbose: int = 0` - Verbosity level for debugging (0-5+)

#### Methods
- `create_memory(role, user_id=None)` - Create memory instance for an agent
- `store_in_short_memory(memory, user_id=None, agent_id=None)` - Store in short-term memory
- `store_in_long_memory(memory, user_id=None, agent_id=None, metadata=None, quality_score=None)` - Store in long-term memory with quality filtering
- `store_entity_memory(name, entity_type, desc, relations, user_id=None, agent_id=None)` - Store structured entity information
- `store_user_memory(memory, user_id, agent_id=None)` - Store user-specific memory
- `search_memories(query, user_id=None, agent_id=None, memory_type="all", k=3, rerank=True)` - Search across memory tiers
- `build_context_for_task(task_descr, user_id=None, additional="", max_items=3)` - Build comprehensive context
- `get_short_memories(user_id=None, agent_id=None, k=10)` - Retrieve recent short-term memories
- `get_long_memories(user_id=None, agent_id=None, k=10, min_quality=0.5)` - Retrieve quality-filtered long-term memories
- `clear_short_memory(user_id=None, agent_id=None)` - Clear short-term memory
- `clear_long_memory(user_id=None, agent_id=None)` - Clear long-term memory

### Quality Scoring Functions

#### compute_quality_score
Calculate overall quality score from individual metrics.

```python
def compute_quality_score(
    completeness: float,
    relevance: float,
    clarity: float,
    accuracy: float,
    weights: Optional[Dict[str, float]] = None
) -> float
```

#### calculate_quality_metrics
Use LLM to evaluate output quality against expectations.

```python
def calculate_quality_metrics(
    output: str,
    expected_output: str,
    llm=None,
    custom_prompt: Optional[str] = None
) -> Dict[str, float]
```

## Memory Tiers

### 1. Short-Term Memory (STM)
* **Purpose**: Immediate context and active conversation
* **Storage**: SQLite database (`.praison/short_term.db`)
* **Retention**: Ephemeral, cleared between sessions
* **Use Cases**: Current task context, recent interactions

### 2. Long-Term Memory (LTM)
* **Purpose**: Persistent knowledge across sessions
* **Storage**: SQLite + optional vector store
* **Retention**: Permanent with quality filtering
* **Use Cases**: Learned facts, important outcomes

### 3. Entity Memory
* **Purpose**: Structured information about entities
* **Storage**: Subset of LTM with special formatting
* **Format**: `Entity {name}({type}): {desc} | relationships: {relations}`
* **Use Cases**: People, organizations, locations

### 4. User Memory
* **Purpose**: User-specific preferences and history
* **Storage**: LTM with user_id filtering
* **Isolation**: Strict user separation
* **Use Cases**: Personalization, preferences

## Configuration

### Basic Configuration
```python
config = {
    "provider": "rag",  # Options: rag, mem0, none
    "use_embedding": True,
    "rag_db_path": ".praison/chroma"
}
```

### Advanced Configuration with Graph Support
```python
config = {
    "provider": "mem0",
    "config": {
        "graph_store": {
            "provider": "neo4j",
            "config": {
                "url": "neo4j+s://your-instance.neo4j.io",
                "username": "neo4j",
                "password": "your-password"
            }
        },
        "vector_store": {
            "provider": "chroma",
            "config": {
                "collection_name": "agent_memory"
            }
        },
        "llm": {
            "provider": "openai",
            "config": {
                "model": "gpt-4o-mini"
            }
        }
    }
}
```

### Graph Database Options

#### Neo4j Configuration
```python
"graph_store": {
    "provider": "neo4j",
    "config": {
        "url": "neo4j+s://...",
        "username": "neo4j",
        "password": "..."
    }
}
```

#### Memgraph Configuration
```python
"graph_store": {
    "provider": "memgraph",
    "config": {
        "url": "bolt://localhost:7687",
        "username": "memgraph",
        "password": "..."
    }
}
```

## Usage Examples

### Basic Memory Operations
```python
from praisonaiagents.memory import MemoryClient

# Initialize memory
memory = MemoryClient(verbose=2)

# Store memories
memory.store_in_short_memory("User asked about pricing")
memory.store_in_long_memory(
    "Company pricing: $99/month for pro plan",
    quality_score=0.9
)

# Search memories
results = memory.search_memories("pricing", k=5)
```

### Quality-Based Storage
```python
from praisonaiagents.memory import calculate_quality_metrics, compute_quality_score

# Evaluate output quality
metrics = calculate_quality_metrics(
    output="Generated report content...",
    expected_output="Comprehensive analysis with data"
)

# Calculate overall score
score = compute_quality_score(
    completeness=metrics['completeness'],
    relevance=metrics['relevance'],
    clarity=metrics['clarity'],
    accuracy=metrics['accuracy']
)

# Store only high-quality outputs
if score > 0.7:
    memory.store_in_long_memory(output, quality_score=score)
```

### Entity Memory Management
```python
# Store entity information
memory.store_entity_memory(
    name="Acme Corp",
    entity_type="Company",
    desc="Leading provider of AI solutions",
    relations=["Founded by John Doe", "Partnered with TechCo"],
    user_id="user123"
)

# Retrieve entity context
context = memory.build_context_for_task(
    "Tell me about Acme Corp's partnerships"
)
```

### Agent Integration
```python
from praisonaiagents import Agent

# Agent with memory
agent = Agent(
    name="Assistant",
    role="Helpful AI assistant",
    memory=True,  # Enable memory
    memory_config={
        "provider": "rag",
        "use_embedding": True
    }
)

# Memory is automatically managed during conversations
response = agent.chat("Remember that my favorite color is blue")
```

### Graph-Enhanced Memory
```python
# Configure with Neo4j
memory = MemoryClient({
    "provider": "mem0",
    "config": {
        "graph_store": {
            "provider": "neo4j",
            "config": {...}
        }
    }
})

# Store with relationships
memory.memory.add(
    "John Doe is the CEO of Acme Corp",
    metadata={"entities": ["John Doe", "Acme Corp"]}
)

# Graph-aware search
results = memory.search_memories(
    "Who works at Acme Corp?",
    rerank=True
)
```

## Quality Metrics

### Completeness (0-1)
How thoroughly the content addresses the requirements.

### Relevance (0-1)
How well the content matches the expected output.

### Clarity (0-1)
How clear and well-structured the content is.

### Accuracy (0-1)
Factual correctness of the information.

### Custom Weights
```python
weights = {
    "completeness": 0.3,
    "relevance": 0.4,
    "clarity": 0.2,
    "accuracy": 0.1
}
score = compute_quality_score(**metrics, weights=weights)
```

## Best Practices
1. **Use Quality Filtering** - Set appropriate `min_quality` thresholds
2. **Scope Memories** - Use user_id and agent_id for proper isolation
3. **Regular Cleanup** - Clear short-term memory between sessions
4. **Graph for Relationships** - Use graph stores for complex entity relationships
5. **Monitor Storage** - Check database sizes periodically
6. **Test Retrieval** - Verify context building produces relevant results