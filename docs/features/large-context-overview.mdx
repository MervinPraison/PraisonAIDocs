---
title: "Large Context Knowledge Handling"
description: "Complete guide to handling large knowledge bases efficiently"
icon: "database"
---

# Large Context Knowledge Handling

PraisonAI Agents provides a comprehensive system for handling large knowledge bases efficiently, with automatic strategy selection, token budgeting, and intelligent compression.

## Overview

The large context handling system includes:

| Feature | Description |
|---------|-------------|
| [Token Budgeting](/features/token-budgeting) | Dynamic budget management for context windows |
| [Incremental Indexing](/features/incremental-indexing) | Efficient file tracking and updates |
| [Retrieval Strategies](/features/retrieval-strategies) | Automatic strategy selection by corpus size |
| [Smart Retrieval](/features/smart-retrieval) | Hybrid search with reranking |
| [Context Compression](/features/context-compression) | Intelligent compression to fit budgets |
| [Hierarchical Summaries](/features/hierarchical-summaries) | Multi-level summaries for large corpora |

## Quick Start

```python
from praisonaiagents import Agent

# Create agent with knowledge base
agent = Agent(
    name="KnowledgeAgent",
    instructions="Answer questions using the knowledge base.",
    knowledge={"sources": ["./docs"]},
    memory={"user_id": "my_user"},
)

# Ask questions - system automatically handles:
# - Indexing documents
# - Selecting retrieval strategy
# - Managing token budget
# - Compressing context if needed
response = agent.chat("What are the main features?")
```

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Agent Query                              │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                  Strategy Selection                          │
│  (DIRECT → BASIC → HYBRID → RERANKED → COMPRESSED → HIER)   │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                   Smart Retrieval                            │
│         (Keyword + Semantic + Reranking)                     │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                 Context Compression                          │
│      (Deduplication + Extraction + Truncation)               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                   Token Budgeting                            │
│           (Enforce limits, reserve response)                 │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      LLM Response                            │
└─────────────────────────────────────────────────────────────┘
```

## CLI Commands

```bash
# Index documents
praisonai knowledge index ./docs --user-id myuser

# Get corpus statistics
praisonai knowledge stats ./docs

# Search with options
praisonai knowledge search "query" --strategy hybrid --rerank --compress

# Build hierarchical summaries
praisonai knowledge summarize ./docs --levels 3

# Clear knowledge store
praisonai knowledge clear --yes
```

## Configuration

### RetrievalConfig

```python
from praisonaiagents.rag import RetrievalConfig, RetrievalStrategy

config = RetrievalConfig(
    # Strategy selection
    strategy=RetrievalStrategy.AUTO,
    
    # Retrieval settings
    top_k=10,
    min_score=0.5,
    
    # Token budget
    max_context_tokens=4000,
    reserved_response_tokens=1000,
    
    # Features
    use_hybrid=True,
    use_reranking=True,
    use_compression=True,
    compression_ratio=0.5,
)

agent = Agent(
    name="ConfiguredAgent",
    knowledge={
        "sources": ["./docs"],
        "retrieval_k": 10,
        "retrieval_threshold": 0.5,
        "rerank": True,
    }
)
```

## Examples

### Context-Required Q&A

```python
# Example with unique codes that require retrieval
from praisonaiagents import Agent

agent = Agent(
    name="PolicyExpert",
    instructions="Answer based ONLY on provided knowledge.",
    knowledge={"sources": ["./policies"]},
    memory={"user_id": "demo_user"},
)

# This question requires retrieval - answer cannot be guessed
response = agent.chat("What is the manager approval code?")
# Agent retrieves: "ZEBRA-71" from policy document
```

### Large Corpus Handling

```python
from praisonaiagents import Agent
from praisonaiagents.rag import RetrievalConfig, RetrievalStrategy

# For large corpora, use hierarchical strategy
agent = Agent(
    name="LargeCorpusAgent",
    knowledge={
        "sources": ["./large_docs"],  # 100k+ files
        "retrieval_k": 10,
    }
)
```

### Scope Isolation

```python
# Different users have isolated knowledge
agent_user1 = Agent(
    name="Agent",
    knowledge={"sources": ["./docs"]},
    memory={"user_id": "user1"},
)

agent_user2 = Agent(
    name="Agent",
    knowledge={"sources": ["./docs"]},
    memory={"user_id": "user2"},
)

# Each user's indexed content is isolated
```

## Performance

The system is designed for zero performance impact when not in use:

- **Lazy imports** - Heavy dependencies loaded only when needed
- **Incremental indexing** - Only changed files re-indexed
- **Automatic strategy** - Simpler strategies for smaller corpora
- **Token budgeting** - Prevents context overflow

## Best Practices

1. **Use incremental indexing** for large, frequently updated corpora
2. **Set appropriate token budgets** based on your model
3. **Enable reranking** for improved relevance
4. **Use hierarchical summaries** for very large corpora (100k+ tokens)
5. **Monitor with verbose mode** to understand system behavior

## Related Documentation

- [Token Budgeting](/features/token-budgeting)
- [Incremental Indexing](/features/incremental-indexing)
- [Retrieval Strategies](/features/retrieval-strategies)
- [Smart Retrieval](/features/smart-retrieval)
- [Context Compression](/features/context-compression)
- [Hierarchical Summaries](/features/hierarchical-summaries)
