---
title: "YAML Workflows"
sidebarTitle: "YAML Workflows"
description: "Define and execute complex workflows using YAML configuration files"
icon: "file-code"
---

# YAML Workflows

Define complex multi-agent workflows in YAML files with support for advanced patterns like routing, parallel execution, loops, and more.

```mermaid
graph LR
    subgraph "YAML Definition"
        YAML["ğŸ“„ workflow.yaml"]
    end
    
    subgraph "Patterns"
        SEQ["Sequential"]
        PAR["Parallel"]
        ROUTE["Routing"]
        LOOP["Loop"]
    end
    
    subgraph "Execution"
        PLAN["ğŸ“‹ Planning"]
        EXEC["âš¡ Execute"]
        OUT["âœ… Output"]
    end
    
    YAML --> SEQ
    YAML --> PAR
    YAML --> ROUTE
    YAML --> LOOP
    SEQ --> PLAN
    PAR --> PLAN
    ROUTE --> PLAN
    LOOP --> PLAN
    PLAN --> EXEC
    EXEC --> OUT
    
    classDef yaml fill:#8B0000,stroke:#7C90A0,color:#fff
    classDef pattern fill:#2E8B57,stroke:#7C90A0,color:#fff
    classDef exec fill:#189AB4,stroke:#7C90A0,color:#fff
    
    class YAML yaml
    class SEQ,PAR,ROUTE,LOOP pattern
    class PLAN,EXEC,OUT exec
```

## Minimum Required Fields

The absolute minimum to run a workflow:

```yaml
agents:
  my_agent:
    role: Assistant        # Required: Agent's job title

steps:
  - agent: my_agent        # Required: Which agent executes
```

**Practical minimum** (recommended):

```yaml
name: My Workflow
input: "Your input here"   # The data passed INTO the workflow (accessed via {{input}})

agents:
  my_agent:
    role: Assistant
    goal: Help with the task
    instructions: "You are a helpful assistant"

steps:
  - agent: my_agent
    action: "Process this: {{input}}"
```

| Field | Required | Default | Description |
|-------|:--------:|---------|-------------|
| `agents` | âœ… | - | At least one agent definition |
| `agents.*.role` | âœ… | - | Agent's job title |
| `steps` | âœ… | - | At least one step |
| `steps.*.agent` | âœ… | - | Agent to execute the step |
| `name` | âŒ | "Workflow" | Workflow identifier |
| `input` | âŒ | "" | Data passed INTO the workflow (accessed via `{{input}}`) |
| `goal` | âŒ | "Complete the task" | Agent's objective |
| `instructions` | âŒ | Generic | Agent behavior/persona |
| `action` | âŒ | `{{input}}` | What the step does |

<Note>
**`input` vs `topic`**: Use `input` (canonical) for clarity. `topic` still works for backward compatibility but `input` better conveys that this is the data going INTO your workflow.
</Note>

<Tip>
Use `{{input}}` to reference the workflow input and `{{previous_output}}` to get the result from the previous step.
</Tip>

## Field Names Reference (A-I-G-S)

PraisonAI accepts both old (agents.yaml) and new (workflow.yaml) field names. Use the **canonical names** for new projects:

| Canonical (Recommended) | Alias (Also Works) | Purpose |
|-------------------------|-------------------|---------|
| `agents` | `roles` | Define agent personas |
| `instructions` | `backstory` | Agent behavior/persona |
| `action` | `description` | What the step does |
| `steps` | `tasks` (nested) | Define work items |
| `name` | - | Workflow identifier |
| `input` | `topic` | Data passed INTO the workflow |

**A-I-G-S Mnemonic** - Easy to remember:
- **A**gents - Who does the work
- **I**nstructions - How they behave  
- **G**oal - What they achieve
- **S**teps - What they do

```yaml
# Quick Reference - Canonical Format
name: My Workflow              # Workflow name
input: What to process         # Data going INTO the workflow (not 'topic')
agents:                        # Define agents (not 'roles')
  my_agent:
    role: Job Title            # Agent's role
    goal: What to achieve      # Agent's goal
    instructions: How to act   # Agent's behavior (not 'backstory')
    
steps:                         # Define steps (not 'tasks')
  - agent: my_agent
    action: "Process: {{input}}"  # Step action (not 'description')
```

<Note>
The parser accepts both old and new names. Run `praisonai workflow validate <file.yaml>` to see suggestions for canonical names.
</Note>

## Feature Parity

Both `agents.yaml` and `workflow.yaml` now support the same features:

| Feature | agents.yaml | workflow.yaml |
|---------|:-----------:|:-------------:|
| Workflow patterns (route, parallel, loop, repeat) | âœ… | âœ… |
| All agent fields | âœ… | âœ… |
| All step/task fields | âœ… | âœ… |
| Framework support (praisonai, crewai, autogen) | âœ… | âœ… |
| Process types (sequential, hierarchical, workflow) | âœ… | âœ… |
| Planning & Reasoning | âœ… | âœ… |

## Quick Start

<CodeGroup>
```bash CLI
# Run a YAML workflow
praisonai workflow run research.yaml

# Run with variables
praisonai workflow run research.yaml --var topic="AI trends"

# Validate a workflow
praisonai workflow validate research.yaml

# Create from template
praisonai workflow template routing --output my_workflow.yaml

# Auto-generate a workflow
praisonai workflow auto "Research AI trends" --pattern parallel
```

```python Python
from praisonaiagents import YAMLWorkflowParser, WorkflowManager

# Option 1: Parse and execute
parser = YAMLWorkflowParser()
workflow = parser.parse_file("research.yaml")
result = workflow.start("Research AI trends")

# Option 2: Use WorkflowManager
manager = WorkflowManager()
result = manager.execute_yaml(
    "research.yaml",
    input_data="Research AI trends",
    variables={"topic": "Machine Learning"}
)
```
</CodeGroup>

## Complete workflow.yaml Reference

```yaml
# workflow.yaml - Full feature reference
name: Complete Workflow
description: Demonstrates all workflow.yaml features
framework: praisonai  # praisonai, crewai, autogen
process: workflow     # sequential, hierarchical, workflow
input: "Your input data here"  # Data passed into workflow (accessed via {{input}})

# ============================================================================
# WORKFLOW SETTINGS
# ============================================================================
workflow:
  planning: true                      # Enable planning mode
  planning_llm: gpt-4o                # LLM for planning
  reasoning: true                     # Enable reasoning mode
  verbose: true                       # Verbose output
  router: true                        # Enable model routing
  routing_strategy: cost-optimized    # auto, cost-optimized, performance-optimized
  memory_config:
    provider: chroma
    persist: true

# ============================================================================
# CUSTOM MODELS (Optional - for model routing)
# ============================================================================
models:
  cheap-fast:
    provider: openai
    complexity: [simple]              # simple, moderate, complex, very_complex
    cost_per_1k: 0.0001
    capabilities: [text]
    context_window: 16000
  
  balanced:
    provider: openai
    complexity: [moderate]
    cost_per_1k: 0.001
    capabilities: [text, function-calling]
    context_window: 128000
  
  premium:
    provider: anthropic
    complexity: [complex, very_complex]
    cost_per_1k: 0.015
    capabilities: [text, vision, function-calling]
    context_window: 200000
    supports_tools: true
    supports_streaming: true
    strengths: [reasoning, analysis, code-generation]

# ============================================================================
# VARIABLES
# ============================================================================
variables:
  topic: AI trends
  items: [ML, NLP, Vision]

# ============================================================================
# AGENTS
# ============================================================================
agents:
  researcher:
    name: Researcher                  # Display name
    role: Research Analyst            # Required: Agent's job title
    goal: Research topics thoroughly  # Agent's objective
    instructions: "Provide detailed research findings"  # Agent behavior/persona
    
    # LLM Configuration
    llm: gpt-4o-mini                  # Model to use
    llm_routing: auto                 # Enable auto model selection
    llm_models: [balanced, premium]   # Models for auto-routing
    function_calling_llm: gpt-4o      # Model for tool calls
    reflect_llm: gpt-4o               # Model for self-reflection
    
    # Rate Limiting & Timeouts
    max_rpm: 10                       # Max requests per minute
    max_execution_time: 300           # Timeout in seconds
    
    # Self-Reflection
    min_reflect: 1                    # Minimum reflection iterations
    max_reflect: 3                    # Maximum reflection iterations
    
    # System Prompt
    system_template: "You are a helpful assistant"
    
    # Tools
    tools:
      - tavily_search
      - wikipedia_search

  writer:
    name: Writer
    role: Content Writer
    goal: Write clear content
    instructions: "Write engaging content"
    llm: premium                      # Use premium model for quality

# ============================================================================
# STEPS
# ============================================================================
steps:
  # Basic step
  - name: research_step
    agent: researcher
    action: "Research {{input}}"      # Use {{input}} for workflow input
    expected_output: "Comprehensive research report"
    output_file: "output/research.md"
    create_directory: true
    
  # Step with context dependency
  - name: writing_step
    agent: writer
    action: "Write article based on: {{previous_output}}"
    context:                          # Task dependencies
      - research_step
    output_json:                      # Structured output
      type: object
      properties:
        title: { type: string }
        content: { type: string }
  
  # Parallel step
  - name: parallel_research
    parallel:
      - agent: researcher
        action: "Research market trends"
      - agent: researcher
        action: "Research competitors"
  
  # Routing step
  - name: routing
    route:
      technical: [tech_agent]
      creative: [creative_agent]
      default: [researcher]
  
  # Loop step
  - agent: researcher
    action: "Research {{item}}"
    loop:
      over: items                     # Variable to iterate
  
  # Repeat step (evaluator-optimizer)
  - agent: writer
    action: "Write and improve"
    repeat:
      until: "approved"
      max_iterations: 3

# ============================================================================
# CALLBACKS (Optional)
# ============================================================================
callbacks:
  on_workflow_start: log_start
  on_step_complete: log_step
  on_workflow_complete: log_complete
```

### Agent Fields Reference

| Field | Required | Default | Description |
|-------|:--------:|---------|-------------|
| `role` | âœ… | - | Agent's job title |
| `name` | âŒ | Agent ID | Display name |
| `goal` | âŒ | "Complete the task" | Agent's objective |
| `instructions` | âŒ | Generic | Agent behavior/persona (alias: `backstory`) |
| `llm` | âŒ | `gpt-4o-mini` | Model to use |
| `llm_routing` | âŒ | - | Enable auto model selection (`auto`) |
| `llm_models` | âŒ | - | Models for auto-routing |
| `function_calling_llm` | âŒ | Same as `llm` | Model for tool calls |
| `reflect_llm` | âŒ | Same as `llm` | Model for self-reflection |
| `max_rpm` | âŒ | Unlimited | Max requests per minute |
| `max_execution_time` | âŒ | 300 | Timeout in seconds |
| `min_reflect` | âŒ | 0 | Minimum reflection iterations |
| `max_reflect` | âŒ | 3 | Maximum reflection iterations |
| `system_template` | âŒ | - | Custom system prompt |
| `tools` | âŒ | [] | List of tools |

### Step Fields Reference

| Field | Required | Default | Description |
|-------|:--------:|---------|-------------|
| `agent` | âœ…* | - | Agent to execute (*not needed for parallel/route) |
| `action` | âŒ | `{{input}}` | What the step does |
| `name` | âŒ | Auto-generated | Step identifier |
| `expected_output` | âŒ | - | Description of expected output |
| `output_file` | âŒ | - | Save output to file |
| `create_directory` | âŒ | false | Create output directory |
| `context` | âŒ | - | List of dependent step names |
| `output_json` | âŒ | - | JSON schema for structured output |
| `parallel` | âŒ | - | List of parallel sub-steps |
| `route` | âŒ | - | Routing configuration |
| `loop` | âŒ | - | Loop configuration (`over: variable`) |
| `repeat` | âŒ | - | Repeat configuration (`until`, `max_iterations`) |

### Models Fields Reference

| Field | Required | Default | Description |
|-------|:--------:|---------|-------------|
| `provider` | âœ… | - | Provider: `openai`, `anthropic`, `google`, `openrouter` |
| `complexity` | âœ… | - | List: `simple`, `moderate`, `complex`, `very_complex` |
| `cost_per_1k` | âœ… | - | Cost per 1,000 tokens in USD |
| `capabilities` | âŒ | `[text]` | List: `text`, `vision`, `function-calling`, `streaming` |
| `context_window` | âŒ | 128000 | Max context window in tokens |
| `supports_tools` | âŒ | true | Supports tool/function calling |
| `supports_streaming` | âŒ | true | Supports streaming responses |
| `strengths` | âŒ | - | List: `reasoning`, `code-generation`, `analysis`, etc. |

## Workflow Patterns

### Sequential (Default)

Agents execute one after another, passing context.

```yaml
name: Sequential Workflow
agents:
  researcher:
    name: Researcher
    role: Research Analyst
    goal: Research topics
    instructions: "Provide research findings"
  writer:
    name: Writer
    role: Content Writer
    goal: Write content
    instructions: "Write based on research"

steps:
  - agent: researcher
    action: "Research {{topic}}"
  - agent: writer
    action: "Write summary based on: {{previous_output}}"
```

### Parallel

Multiple agents work concurrently.

```yaml
name: Parallel Workflow
agents:
  market_analyst:
    name: MarketAnalyst
    role: Market Researcher
    goal: Research market trends
    instructions: "Provide market insights"
  tech_analyst:
    name: TechAnalyst
    role: Technology Researcher
    goal: Research technology
    instructions: "Provide tech insights"
  aggregator:
    name: Aggregator
    role: Synthesizer
    goal: Combine findings
    instructions: "Synthesize all research"

steps:
  - name: parallel_research
    parallel:
      - agent: market_analyst
        action: "Research market trends for {{topic}}"
      - agent: tech_analyst
        action: "Research technology trends for {{topic}}"
  - agent: aggregator
    action: "Combine all findings into a report"
```

### Routing

Classifier routes to specialized agents.

```yaml
name: Routing Workflow
agents:
  classifier:
    name: Classifier
    role: Request Classifier
    goal: Classify requests
    instructions: "Respond with ONLY: 'technical', 'creative', or 'general'"
  tech_expert:
    name: TechExpert
    role: Technical Expert
    goal: Handle technical questions
    instructions: "Provide technical answers"
  creative_expert:
    name: CreativeExpert
    role: Creative Expert
    goal: Handle creative requests
    instructions: "Provide creative responses"

steps:
  - agent: classifier
    action: "Classify: {{input}}"
  - name: routing
    route:
      technical: [tech_expert]
      creative: [creative_expert]
      default: [tech_expert]
```

### Loop

Iterate over a list of items.

```yaml
name: Loop Workflow
variables:
  topics:
    - Machine Learning
    - Natural Language Processing
    - Computer Vision

agents:
  researcher:
    name: Researcher
    role: Research Analyst
    goal: Research topics
    instructions: "Provide brief research on each topic"

steps:
  - agent: researcher
    action: "Research {{item}}"
    loop:
      over: topics
```

### Repeat (Evaluator-Optimizer)

Repeat until a condition is met.

```yaml
name: Repeat Workflow
agents:
  writer:
    name: Writer
    role: Content Writer
    goal: Write high-quality content
    instructions: "Write and improve content"
  evaluator:
    name: Evaluator
    role: Quality Checker
    goal: Evaluate content quality
    instructions: "Rate content 1-10. Say 'approved' if >= 8"

steps:
  - agent: writer
    action: "Write article about {{topic}}"
    repeat:
      until: "approved"
      max_iterations: 3
```

## Extended agents.yaml

Use workflow patterns in agents.yaml with `process: workflow`:

```yaml
# agents.yaml with workflow patterns
framework: praisonai
process: workflow  # Enables workflow mode
topic: "Research AI trends"

workflow:
  planning: true
  reasoning: true
  verbose: true

agents:  # Canonical: use 'agents' instead of 'roles'
  classifier:
    role: Request Classifier
    instructions:  # Canonical: use 'instructions' instead of 'backstory' "Classify requests into categories"
    goal: Classify requests
    
  researcher:
    role: Research Analyst
    instructions:  # Canonical: use 'instructions' instead of 'backstory' "Expert researcher"
    goal: Research topics
    tools:
      - tavily_search

steps:
  - agent: classifier
    action: "Classify: {{topic}}"
    
  - name: routing
    route:
      technical: [tech_expert]
      default: [researcher]
      
  - name: parallel_research
    parallel:
      - agent: researcher
        action: "Research market trends"
      - agent: researcher
        action: "Research competitors"
```

Run with:
```bash
praisonai agents.yaml
```

## Auto-Generate Workflows

Generate workflows automatically from a topic description:

```bash
# Sequential workflow (default)
praisonai workflow auto "Research AI trends"

# Parallel workflow
praisonai workflow auto "Research AI trends" --pattern parallel

# Routing workflow
praisonai workflow auto "Build a chatbot" --pattern routing

# Specify output file
praisonai workflow auto "Research AI" --output my_workflow.yaml
```

## CLI Commands

| Command | Description |
|---------|-------------|
| `praisonai workflow run <file.yaml>` | Run a YAML workflow |
| `praisonai workflow run <file.yaml> --var key=value` | Run with variables |
| `praisonai workflow validate <file.yaml>` | Validate a workflow |
| `praisonai workflow template <name>` | Create from template |
| `praisonai workflow auto "topic"` | Auto-generate workflow |
| `praisonai workflow list` | List workflows |
| `praisonai workflow help` | Show help |

## CLI Options

| Flag | Description |
|------|-------------|
| `--var key=value` | Set variable for YAML workflows |
| `--pattern <pattern>` | Pattern for auto-generation (sequential, parallel, routing, loop) |
| `--output <file>` | Output file for auto-generation |
| `--planning` | Enable planning mode |
| `--reasoning` | Enable reasoning mode |
| `--verbose` | Enable verbose output |
| `--save` | Save output to file |

## Progress Indicators

When running workflows, you'll see clear progress indicators:

```
Running YAML workflow: research.yaml
 Workflow: Research Workflow  
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Property  â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Steps     â”‚ 3     â”‚
â”‚ Planning  â”‚ True  â”‚
â”‚ Reasoning â”‚ False â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

Executing workflow...

ğŸ“‹ Execution Plan: [plan description]
âš¡ Running 2 steps in parallel...
âœ… Parallel complete: 2 results
ğŸ”€ Routing to: technical
âœ… AgentName: [output preview]

âœ… Workflow completed successfully!
```

## Debug Mode

Enable debug logging to see detailed execution:

```bash
LOGLEVEL=debug praisonai workflow run research.yaml
```

This shows:
- Agent parameters (prompt, temperature, tools)
- Messages sent to LLM
- HTTP requests to API
- Full agent/role/goal context
