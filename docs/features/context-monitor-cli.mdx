---
title: "Context Monitor CLI"
description: "CLI reference for context monitoring configuration"
icon: "eye"
---

Configure context monitoring via CLI flags and interactive commands.

## CLI Flags

### Enable Monitoring

```bash
praisonai chat --context-monitor
```

### Output Path

```bash
praisonai chat --context-monitor-path ./debug/context.json
```

### Output Format

```bash
# Human-readable (default)
praisonai chat --context-monitor-format human

# JSON format
praisonai chat --context-monitor-format json
```

### Update Frequency

```bash
# After each turn (default)
praisonai chat --context-monitor-frequency turn

# After each tool call
praisonai chat --context-monitor-frequency tool_call

# Manual only
praisonai chat --context-monitor-frequency manual

# On overflow detection
praisonai chat --context-monitor-frequency overflow
```

### Write Mode

```bash
# Synchronous (default)
praisonai chat --context-write-mode sync

# Asynchronous (better performance)
praisonai chat --context-write-mode async
```

### Redaction

```bash
# Enable redaction (default)
praisonai chat --context-redact

# Disable redaction (not recommended)
praisonai chat --no-context-redact
```

## Interactive Commands

### Enable Monitoring

```bash
> /context on
```

**Output:**
```
✓ Context monitoring enabled
Output: ./context.txt
```

### Disable Monitoring

```bash
> /context off
```

### Set Path

```bash
> /context path ./debug/context.json
```

### Set Format

```bash
> /context format json
```

### Set Frequency

```bash
> /context frequency overflow
```

### Manual Snapshot

```bash
> /context dump
```

**Output:**
```
✓ Context snapshot written to: ./context.txt
```

## Environment Variables

```bash
export PRAISONAI_CONTEXT_MONITOR=false
export PRAISONAI_CONTEXT_MONITOR_PATH=./context.txt
export PRAISONAI_CONTEXT_MONITOR_FORMAT=human
export PRAISONAI_CONTEXT_MONITOR_FREQUENCY=turn
export PRAISONAI_CONTEXT_REDACT=true
```

## config.yaml

```yaml
context:
  monitor:
    enabled: false
    path: ./context.txt
    format: human
    frequency: turn
    write_mode: sync
  redact_sensitive: true
```

## Output Formats

### Human Format

```
================================================================================
PRAISONAI CONTEXT SNAPSHOT
================================================================================
Timestamp: 2024-01-07T12:00:00Z
Session ID: abc123
Agent: Assistant
Model: gpt-4o-mini
Model Limit: 128,000 tokens
Output Reserve: 8,000 tokens
Usable Budget: 120,000 tokens

--------------------------------------------------------------------------------
TOKEN LEDGER
--------------------------------------------------------------------------------
Segment              Tokens     Budget     Used
system_prompt         1,200      2,000    60.0%
history              12,500     84,616    14.8%
...
```

### JSON Format

```json
{
  "timestamp": "2024-01-07T12:00:00Z",
  "session_id": "abc123",
  "agent_name": "Assistant",
  "model_name": "gpt-4o-mini",
  "budget": {
    "model_limit": 128000,
    "output_reserve": 8000,
    "usable": 120000
  },
  "ledger": {
    "segments": {
      "system_prompt": {"tokens": 1200, "budget": 2000}
    }
  }
}
```

## Frequency Options

| Frequency | When Snapshots Are Written |
|-----------|---------------------------|
| `turn` | After each user/assistant turn |
| `tool_call` | After each tool execution |
| `manual` | Only on `/context dump` |
| `overflow` | When approaching context limit |

## Troubleshooting

### Snapshots not appearing

```bash
# Check if monitoring is enabled
> /context config

# Enable monitoring
> /context on

# Force a snapshot
> /context dump
```

### Sensitive data in snapshots

```bash
# Ensure redaction is enabled
praisonai chat --context-redact

# Check redaction status
> /context config
```

### Performance issues

```bash
# Use async writes
praisonai chat --context-write-mode async

# Reduce frequency
praisonai chat --context-monitor-frequency overflow
```
