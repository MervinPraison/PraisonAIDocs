---
title: "Dynamic Context Discovery"
description: "Artifact-based storage for large tool outputs with queuing middleware"
icon: "box-archive"
---

Dynamic Context Discovery automatically queues large tool outputs to artifacts, preventing context flooding while enabling on-demand retrieval.

## Overview

When tools produce large outputs (e.g., API responses, file contents), they can flood the context window. Dynamic Context Discovery:

1. **Intercepts** tool outputs via middleware
2. **Evaluates** size against configurable threshold
3. **Queues** large outputs to artifact storage
4. **Returns** compact references in context
5. **Provides** tools for on-demand retrieval (tail, grep, chunk)

```
┌─────────────┐     ┌──────────────┐     ┌───────────────┐
│ Tool Output │────▶│ OutputQueue  │────▶│ ArtifactStore │
│  (large)    │     │ (middleware) │     │  (filesystem) │
└─────────────┘     └──────────────┘     └───────────────┘
                           │
                           ▼
                    ┌──────────────┐
                    │ ArtifactRef  │
                    │ (inline ref) │
                    └──────────────┘
```

## Quick Start

```python
from praisonaiagents import Agent
from praisonai.context import setup_dynamic_context

# Set up dynamic context with 16KB threshold
ctx = setup_dynamic_context(inline_max_kb=16)

# Create agent with artifact tools and middleware
agent = Agent(
    instructions="You are a data analyst.",
    tools=ctx.get_tools(),       # artifact_tail, artifact_grep, etc.
    hooks=[ctx.get_middleware()], # Auto-queues large outputs
)

# Large tool outputs are now automatically managed
response = agent.chat("Fetch and analyze the large dataset")
```

## Configuration

### Basic Setup

```python
from praisonai.context import setup_dynamic_context

ctx = setup_dynamic_context(
    base_dir="~/.praison/runs",  # Artifact storage location
    inline_max_kb=32,            # Outputs > 32KB get queued
    redact_secrets=True,         # Redact API keys, passwords
    history_enabled=True,        # Enable history persistence
    terminal_logging=False,      # Capture shell outputs
)
```

### Custom Configuration

```python
from praisonai.context import DynamicContextConfig, DynamicContextSetup

config = DynamicContextConfig(
    base_dir="./artifacts",
    queuing_enabled=True,
    inline_max_kb=16,
    redact_secrets=True,
    history_enabled=True,
    terminal_logging=True,
)

ctx = DynamicContextSetup(config=config)
```

### QueueConfig (Low-Level)

```python
from praisonaiagents.context.artifacts import QueueConfig

config = QueueConfig(
    enabled=True,
    inline_max_bytes=32 * 1024,  # 32KB
    redact_secrets=True,
    summary_max_chars=200,
)
```

## Artifact Tools

When you call `ctx.get_tools()`, these tools are provided to agents:

| Tool | Description |
|------|-------------|
| `artifact_tail` | Get last N lines of an artifact |
| `artifact_head` | Get first N lines of an artifact |
| `artifact_grep` | Search for pattern in artifact |
| `artifact_chunk` | Get specific line range |
| `artifact_list` | List available artifacts |

### Usage in Agent

```python
# Agent can use these tools naturally
agent.chat("Show me the last 50 lines of the API response artifact")
agent.chat("Search for 'error' in the log artifact")
```

## OutputQueue Middleware

The middleware intercepts tool calls and queues large outputs:

```python
from praisonai.context import OutputQueue, create_queue_middleware
from praisonaiagents.context.artifacts import QueueConfig

# Create middleware
middleware = create_queue_middleware(
    config=QueueConfig(inline_max_bytes=16*1024),
    run_id="my_run",
)

agent = Agent(
    instructions="...",
    hooks=[middleware],
)
```

### Direct Usage

```python
from praisonai.context import OutputQueue
from praisonaiagents.context.artifacts import ArtifactMetadata, QueueConfig

queue = OutputQueue(
    base_dir="./artifacts",
    config=QueueConfig(inline_max_bytes=1024),
)

# Small output - returned as-is
small = queue.process("Hello", ArtifactMetadata())
# Returns: "Hello"

# Large output - queued to artifact
large = queue.process("x" * 2000, ArtifactMetadata())
# Returns: ArtifactRef(path="...", summary="...", ...)
```

## ArtifactRef

When outputs are queued, they're replaced with an `ArtifactRef`:

```python
from praisonaiagents.context.artifacts import ArtifactRef

# Inline representation shown in context
ref.to_inline()
# "[Artifact from api_call: /path/to/artifact.json (48.5 KB) - Dict with keys: records, metadata]"

# Full attributes
ref.path          # Absolute path to file
ref.summary       # Brief description
ref.size_bytes    # Original size
ref.mime_type     # Content type
ref.checksum      # SHA256 hash
ref.tool_name     # Source tool
```

## History Persistence

Conversation history is saved to artifacts for loss recovery:

```python
from praisonai.context import HistoryStore

store = HistoryStore(base_dir="./history")

# Append messages
store.append(
    message={"role": "user", "content": "Hello"},
    agent_id="agent1",
    run_id="run1",
)

# Search history
results = store.search("error", agent_id="agent1", run_id="run1")

# Get artifact reference
ref = store.get_ref(agent_id="agent1", run_id="run1")
```

## Secret Redaction

Sensitive data is automatically redacted in artifacts:

```python
# Input with secrets
content = 'api_key="sk-1234567890abcdef" password="secret123"'

# Stored as
# api_key="[REDACTED]" password="[REDACTED]"
```

Patterns redacted:
- OpenAI keys (`sk-...`)
- API keys, passwords, tokens
- GitHub tokens (`ghp_...`, `gho_...`)
- Slack tokens (`xox...`)

## Environment Variables

```bash
PRAISONAI_ARTIFACT_DIR=~/.praison/runs
PRAISONAI_ARTIFACT_INLINE_MAX_KB=32
PRAISONAI_ARTIFACT_REDACT=true
PRAISONAI_TERMINAL_LOGGING=false
```

## Complete Example

```python
from praisonaiagents import Agent
from praisonai.context import setup_dynamic_context

# Setup with all features
ctx = setup_dynamic_context(
    inline_max_kb=16,
    redact_secrets=True,
    history_enabled=True,
)

# Create agent
agent = Agent(
    name="DataAnalyst",
    instructions="Analyze data and use artifact tools for large outputs.",
    tools=ctx.get_tools(),
    hooks=[ctx.get_middleware()],
)

# Use agent - large outputs automatically managed
response = agent.chat("Fetch the API data and show me a summary")

# Agent can retrieve artifact contents as needed
response = agent.chat("Show the last 20 lines of that artifact")
```

## API Reference

### setup_dynamic_context()

```python
def setup_dynamic_context(
    base_dir: str = "~/.praison/runs",
    inline_max_kb: int = 32,
    redact_secrets: bool = True,
    history_enabled: bool = True,
    terminal_logging: bool = False,
    run_id: Optional[str] = None,
) -> DynamicContextSetup
```

### DynamicContextSetup

| Property | Description |
|----------|-------------|
| `artifact_store` | FileSystemArtifactStore instance |
| `output_queue` | OutputQueue instance |
| `history_store` | HistoryStore instance |
| `terminal_logger` | TerminalLogger instance |
| `get_tools()` | Returns list of artifact tools |
| `get_middleware()` | Returns queue middleware |

### OutputQueue

| Method | Description |
|--------|-------------|
| `process(content, metadata)` | Queue if large, else return as-is |
| `should_queue(content)` | Check if content exceeds threshold |

## See Also

- [Middleware System](/docs/features/middleware) - Hook-based middleware
- [Context Security](/docs/features/context-security-redaction) - Secret redaction
- [Context Management](/docs/features/context-management) - Overview
