---
title: "Agentic Evaluator Optimizer"
sidebarTitle: "Evaluator Optimizer"
description: "Learn how to create AI agents that can generate and optimize solutions through iterative feedback."
icon: "arrows-rotate"
---

```mermaid
flowchart LR
    In[In] --> Generator[LLM Call Generator] 
    Generator -->|SOLUTION| Evaluator[LLM Call Evaluator] -->|ACCEPTED| Out[Out]
    Evaluator -->|REJECTED + FEEDBACK| Generator
    
    style In fill:#8B0000,color:#fff
    style Generator fill:#2E8B57,color:#fff
    style Evaluator fill:#2E8B57,color:#fff
    style Out fill:#8B0000,color:#fff
```

A feedback loop workflow where LLM-generated outputs are evaluated, refined, and optimized iteratively to improve accuracy and relevance.

## Quick Start

<Steps>
    <Step title="Install Package">
        First, install the PraisonAI Agents package:
        ```bash
        pip install praisonaiagents
        ```
    </Step>

    <Step title="Set API Key">
        Set your OpenAI API key as an environment variable in your terminal:
        ```bash
        export OPENAI_API_KEY=your_api_key_here
        ```
    </Step>

    <Step title="Create a file">
        Create a new file `app.py` with the basic setup:
        ```python
        from praisonaiagents import Workflow, WorkflowContext, StepResult
        from praisonaiagents.workflows import repeat

        # Simulated content generator that improves each iteration
        class ContentGenerator:
            def __init__(self):
                self.points = []
            
            def generate(self, ctx: WorkflowContext) -> StepResult:
                """Generate content, adding more each iteration."""
                # Add 2 new points each iteration
                iteration = len(self.points) // 2 + 1
                self.points.append(f"{len(self.points) + 1}. AI point from iteration {iteration}")
                self.points.append(f"{len(self.points) + 1}. Another AI insight from iteration {iteration}")
                
                return StepResult(
                    output=f"Generated {len(self.points)} points total",
                    variables={"points": self.points.copy(), "count": len(self.points)}
                )

        # Evaluator - checks if we have enough points
        def is_complete(ctx: WorkflowContext) -> bool:
            count = ctx.variables.get("count", 0)
            return count >= 10

        # Create generator instance
        generator = ContentGenerator()

        # Create workflow with repeat pattern
        workflow = Workflow(
            steps=[
                repeat(
                    generator.generate,
                    until=is_complete,
                    max_iterations=10
                )
            ]
        )

        # Run optimization workflow
        print("\nStarting Evaluator-Optimizer Workflow...")
        print("=" * 50)

        result = workflow.start("Generate 10 points about AI")

        print(f"\nFinal Result: {result['output']}")
        print(f"Total iterations: {result['variables'].get('repeat_iterations', 0)}")
        print(f"\nGenerated Points:")
        for point in result['variables'].get('points', []):
            print(f"  {point}")
        ```
    </Step>

    <Step title="Start Workflow">
        Type this in your terminal to run your workflow:
        ```bash
        python app.py
        ```
    </Step>
</Steps>

<Note>
  **Requirements**
  - Python 3.10 or higher
  - OpenAI API key. Generate OpenAI API key [here](https://platform.openai.com/api-keys). Use Other models using [this guide](/models).   
  - Basic understanding of Python
</Note>

## Understanding Evaluator-Optimizer

<Card title="What is Evaluator-Optimizer?" icon="question">
  Evaluator-Optimizer pattern enables:
  - Iterative solution generation and refinement
  - Automated quality evaluation
  - Feedback-driven optimization
  - Continuous improvement loops
</Card>

## Features

<CardGroup cols={2}>
  <Card title="Solution Generation" icon="wand-magic-sparkles">
    Generate solutions based on requirements and feedback.
  </Card>
  <Card title="Quality Evaluation" icon="magnifying-glass-chart">
    Automatically assess solution quality and completeness.
  </Card>
  <Card title="Feedback Loop" icon="rotate">
    Implement iterative improvement through feedback cycles.
  </Card>
  <Card title="Process Control" icon="sliders">
    Monitor and control the optimization process.
  </Card>
</CardGroup>

## Configuration Options

```python
# Create a generator agent
generator = Agent(
    name="Generator",
    role="Solution generator",
    goal="Generate and improve solutions",
    instructions="Step-by-step instructions for generation",
    verbose=True  # Enable detailed logging
)

# Create an evaluator agent
evaluator = Agent(
    name="Evaluator",
    role="Solution evaluator",
    goal="Evaluate and provide feedback",
    instructions="Evaluation criteria and feedback format"
)

# Create tasks with feedback loop
generate_task = Task(
    name="generate",
    description="Generate solution",
    agent=generator,
    is_start=True,
    task_type="decision",
    next_tasks=["evaluate"]
)

evaluate_task = Task(
    name="evaluate",
    description="Evaluate solution",
    agent=evaluator,
    context=[generate_task],
    task_type="decision",
    condition={
        "more": ["generate"],  # Continue optimization
        "done": [""]  # Exit when complete
    }
)
```

## Troubleshooting

<CardGroup cols={2}>
  <Card title="Generation Issues" icon="triangle-exclamation">
    If generation is not improving:
    - Review generator instructions
    - Check feedback integration
    - Enable verbose mode for debugging
  </Card>

  <Card title="Evaluation Flow" icon="diagram-project">
    If evaluation cycle is incorrect:
    - Verify evaluation criteria
    - Check condition mappings
    - Review feedback loop connections
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="AutoAgents" icon="robot" href="./autoagents">
    Learn about automatically created and managed AI agents
  </Card>
  <Card title="Mini Agents" icon="microchip" href="./mini">
    Explore lightweight, focused AI agents
  </Card>
</CardGroup>

<Note>
  For optimal results, ensure your generator instructions and evaluation criteria are clear and well-defined to achieve the desired optimization outcomes.
</Note>
