---
title: "Observability Overview"
description: "Comprehensive observability and tracing for PraisonAI agents with 20+ provider integrations"
icon: "chart-line"
---

# Observability Suite

PraisonAI provides a unified observability suite with support for 20+ observability providers. All integrations use lazy loading for zero performance impact when not in use.

## Quick Start

### Init-Only Auto-Instrumentation (Recommended)

The simplest way to add observability - just call `obs.init()` once and all agent operations are automatically traced:

```python
from praisonai_tools.observability import obs

# Auto-detect provider and auto-instrument all agents
obs.init()

# That's it! Everything below is now traced automatically
from praisonaiagents import Agent

agent = Agent(name="Assistant", instructions="You are helpful.")
agent.chat("Hello!")  # Auto-traced to your provider
```

<Note>
Auto-instrumentation patches `Agent.chat()`, `Agent.start()`, `Agent.run()`, and `Agents.start()` to create spans automatically. No explicit `obs.trace()` wrappers needed!
</Note>

### Explicit Provider Selection

```python
from praisonai_tools.observability import obs

# Specify provider explicitly
obs.init(provider="langfuse")

# Or disable auto-instrumentation for manual control
obs.init(auto_instrument=False)
```

## Supported Providers

| Provider | Environment Variables | Install |
|----------|----------------------|---------|
| [AgentOps](/observability/agentops) | `AGENTOPS_API_KEY` | `pip install agentops` |
| [Langfuse](/observability/langfuse) | `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY` | `pip install opentelemetry-sdk opentelemetry-exporter-otlp` |
| [LangSmith](/observability/langsmith) | `LANGSMITH_API_KEY` | `pip install opentelemetry-sdk opentelemetry-exporter-otlp` |
| [Traceloop](/observability/traceloop) | `TRACELOOP_API_KEY` | `pip install traceloop-sdk` |
| [Arize Phoenix](/observability/arize-phoenix) | `PHOENIX_API_KEY` | `pip install arize-phoenix` |
| [OpenLIT](/observability/openlit) | - | `pip install openlit` |
| [Langtrace](/observability/langtrace) | `LANGTRACE_API_KEY` | `pip install langtrace-python-sdk` |
| [LangWatch](/observability/langwatch) | `LANGWATCH_API_KEY` | `pip install langwatch` |
| [Datadog](/observability/datadog) | `DD_API_KEY` | `pip install ddtrace` |
| [MLflow](/observability/mlflow) | `MLFLOW_TRACKING_URI` | `pip install mlflow` |
| [Opik](/observability/opik) | `OPIK_API_KEY` | `pip install opik` |
| [Portkey](/observability/portkey) | `PORTKEY_API_KEY` | `pip install portkey-ai` |
| [Braintrust](/observability/braintrust) | `BRAINTRUST_API_KEY` | `pip install braintrust` |
| [Maxim](/observability/maxim) | `MAXIM_API_KEY` | `pip install maxim-py` |
| [Weave](/observability/weave) | `WANDB_API_KEY` | `pip install weave` |
| [Neatlogs](/observability/neatlogs) | `NEATLOGS_API_KEY` | - |
| [LangDB](/observability/langdb) | `LANGDB_API_KEY` | - |
| [Atla](/observability/atla) | `ATLA_API_KEY` | `pip install atla-insights` |
| [Patronus](/observability/patronus) | `PATRONUS_API_KEY` | `pip install patronus` |
| [TrueFoundry](/observability/truefoundry) | `TRUEFOUNDRY_API_KEY` | - |

## Core Concepts

### Traces and Spans

```python
from praisonai_tools.observability import obs
from praisonai_tools.observability.base import SpanKind

obs.init(provider="langfuse")

# Create a trace for a workflow
with obs.trace("my-workflow", session_id="user-123"):
    # Create spans for individual operations
    with obs.span("llm-call", kind=SpanKind.LLM) as span:
        span.model = "gpt-4o-mini"
        span.input_tokens = 100
        span.output_tokens = 50
        # ... your LLM call
    
    with obs.span("tool-call", kind=SpanKind.TOOL) as span:
        span.tool_name = "search"
        # ... your tool call
```

### Logging LLM Calls

```python
obs.log_llm_call(
    model="gpt-4o-mini",
    input_messages="What is 2+2?",
    output="4",
    input_tokens=10,
    output_tokens=1,
)
```

### Logging Tool Calls

```python
obs.log_tool_call(
    tool_name="search",
    tool_input={"query": "PraisonAI"},
    tool_output={"results": [...]},
)
```

### Decorators

```python
@obs.decorator("my-function", SpanKind.CUSTOM)
def my_function():
    return "result"
```

## Multi-Agent Tracing

```python
from praisonai_tools.observability import obs
from praisonai_tools.observability.base import SpanKind

obs.init(provider="langfuse")

with obs.trace("multi-agent-workflow"):
    # Agent 1
    with obs.span("agent-1", kind=SpanKind.AGENT) as span:
        span.attributes["agent_name"] = "Researcher"
        # ... agent 1 work
    
    # Agent 2 (child of same trace)
    with obs.span("agent-2", kind=SpanKind.AGENT) as span:
        span.attributes["agent_name"] = "Writer"
        # ... agent 2 work
```

## CLI Commands

```bash
# List available providers
praisonai obs list

# Check provider connectivity
praisonai obs doctor

# Initialize a provider
praisonai obs init langfuse
```

## Diagnostics

```python
# Check observability status
print(obs.doctor())
# Output: {'enabled': True, 'provider': 'langfuse', 'connection_status': True, ...}
```
