---
title: "Traceloop"
description: "Integrate Traceloop observability with PraisonAI agents"
icon: "circle-nodes"
---

# Traceloop Integration

[Traceloop](https://traceloop.com/) provides LLM observability with OpenTelemetry.

## Setup

### 1. Install Dependencies

```bash
pip install traceloop-sdk
```

### 2. Set Environment Variables

```bash
export TRACELOOP_API_KEY=xxx
```

### 3. Initialize

```python
from praisonai_tools.observability import obs

obs.init(provider="traceloop")
```

## Usage

### Auto-Instrumentation (Recommended)

```python
from praisonai_tools.observability import obs
from praisonaiagents import Agent

obs.init(provider="traceloop")

# Everything is auto-traced!
agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant.",
    model="gpt-4o-mini",
)

response = agent.chat("Hello!")
print(response)
```

### Explicit Tracing (For Fine Control)

```python
from praisonai_tools.observability import obs
from praisonaiagents import Agent

obs.init(provider="traceloop", auto_instrument=False)

agent = Agent(
    instructions="You are a helpful assistant.",
    model="gpt-4o-mini",
)

with obs.trace("workflow"):
    response = agent.chat("Hello!")
    print(response)
```

## Workflow Decorator

```python
from praisonai_tools.observability.providers.traceloop_provider import TraceloopProvider

provider = TraceloopProvider()
provider.init()

@provider.workflow("my-workflow")
def my_workflow():
    # Your workflow code
    pass
```

## Configuration Options

| Option | Environment Variable | Description |
|--------|---------------------|-------------|
| `api_key` | `TRACELOOP_API_KEY` | Your Traceloop API key |
| `app_name` | - | Application name |
| `disable_batch` | - | Disable batching (default: False) |
